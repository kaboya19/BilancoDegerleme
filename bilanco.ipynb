{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from isyatirimhisse import StockData, Financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to financials_20240830\n"
     ]
    }
   ],
   "source": [
    "financials = Financials()\n",
    "df = financials.get_data(\n",
    "    symbols='TAVHL',\n",
    "    start_year='2010',\n",
    "    save_to_excel=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilanco=pd.read_excel(\"financials_20240830.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=bilanco[bilanco[\"itemDescTr\"]==\"Satış Gelirleri\"].iloc[:,3:].T[::4]\n",
    "satışlar=bilanco[bilanco[\"itemDescTr\"]==\"Satış Gelirleri\"].iloc[:,3:].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_liabilities=bilanco[bilanco['itemDescTr'].str.contains('yükümlülük', case=False, na=False)].iloc[:4,3:].sum(axis=0)\n",
    "total_liabilities=bilanco[bilanco['itemDescTr'].str.contains('yükümlülük', case=False, na=False)].iloc[:,3:].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_assets = bilanco.loc[bilanco['itemDescEng'] == 'CURRENT ASSETS'].values[0][3:]\n",
    "total_assets = bilanco.loc[bilanco['itemDescEng'] == 'TOTAL ASSETS'].values[0][3:]\n",
    "shareholders_equity = bilanco.loc[bilanco['itemDescEng'] == 'SHAREHOLDERS EQUITY'].values[0][3:]\n",
    "net_profit_after_taxes = bilanco.loc[bilanco['itemDescEng'] == 'NET PROFIT AFTER TAXES'].values[0][3:]\n",
    "domestic_sales = bilanco.loc[bilanco['itemDescEng'] == 'Domestic Sales'].values[0][3:]\n",
    "export_sales = bilanco.loc[bilanco['itemDescEng'] == 'Export Sales'].values[0][3:]\n",
    "netkar=bilanco.loc[bilanco['itemDescTr'] == 'Dönem Net Kar/Zararı'].values[0][3:]\n",
    "özkaynaklar=bilanco.loc[bilanco['itemDescTr'] == 'Özkaynaklar'].values[0][3:]\n",
    "satışlar=bilanco.loc[bilanco['itemDescTr'] == 'Satış Gelirleri'].values[0][3:]\n",
    "brütkar=bilanco.loc[bilanco['itemDescTr'] == 'BRÜT KAR (ZARAR)'].values[0][3:]\n",
    "faaliyetkarı=bilanco.loc[bilanco['itemDescTr'] == 'FAALİYET KARI (ZARARI)'].values[0][3:]\n",
    "# Calculate the ratios\n",
    "current_ratio = current_assets / current_liabilities\n",
    "debt_to_equity_ratio = total_liabilities / shareholders_equity\n",
    "return_on_equity = net_profit_after_taxes / shareholders_equity\n",
    "net_profit_margin = net_profit_after_taxes / satışlar\n",
    "roe=netkar/özkaynaklar\n",
    "asset_turnover=satışlar/total_assets\n",
    "brütkarmarjı=brütkar/satışlar\n",
    "faaliyetkarmarj=faaliyetkarı/satışlar\n",
    "\n",
    "def tolist(array):\n",
    "    array=pd.DataFrame(array).reset_index()\n",
    "    del array[\"index\"]\n",
    "    return array\n",
    "current_ratio=tolist(current_ratio)\n",
    "debt_to_equity_ratio=tolist(debt_to_equity_ratio)\n",
    "return_on_equity=tolist(return_on_equity)\n",
    "net_profit_margin=tolist(net_profit_margin)\n",
    "roe=tolist(roe)\n",
    "asset_turnover=tolist(asset_turnover)\n",
    "brütkarmarjı=tolist(brütkarmarjı)\n",
    "faaliyetkarmarj=tolist(faaliyetkarmarj)\n",
    "satışlar=tolist(satışlar)\n",
    "netkar=tolist(netkar)\n",
    "current_assets=tolist(current_assets)\n",
    "total_assets=tolist(total_assets)\n",
    "net_profit_after_taxes=tolist(net_profit_after_taxes)\n",
    "özkaynaklar=tolist(özkaynaklar)\n",
    "brütkar=tolist(brütkar)\n",
    "faaliyetkarı=tolist(faaliyetkarı)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "C:\\Users\\Bora\\AppData\\Local\\Temp\\ipykernel_18284\\167308702.py:2: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
      "  hisse = hisse.resample('Q').agg({'Open': 'first',\n"
     ]
    }
   ],
   "source": [
    "hisse=yf.download(tickers=\"TAVHL.IS\",start=\"2010-01-01\",interval=\"1mo\")\n",
    "hisse = hisse.resample('Q').agg({'Open': 'first',\n",
    "    'High': 'max',\n",
    "    'Low': 'min',\n",
    "    'Close': 'mean',\n",
    "    'Volume': 'sum'\n",
    "})\n",
    "hisse[\"Return\"]=((hisse[\"Close\"].shift(-2)/hisse[\"Close\"])-1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bora\\AppData\\Local\\Temp\\ipykernel_18284\\785113168.py:5: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
      "  rasyo=rasyo.set_index(pd.date_range(start=\"2010-03-31\",freq=\"Q\",periods=len(rasyo)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cari Oran</th>\n",
       "      <th>Borçluluk Oranı</th>\n",
       "      <th>Return On Equity</th>\n",
       "      <th>Net Kar Marjı</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Devir Hızı</th>\n",
       "      <th>Brüt Kar Marjı</th>\n",
       "      <th>Faaliyet Kar Marjı</th>\n",
       "      <th>s</th>\n",
       "      <th>n</th>\n",
       "      <th>c</th>\n",
       "      <th>t</th>\n",
       "      <th>favök</th>\n",
       "      <th>özkaynak</th>\n",
       "      <th>brütkar</th>\n",
       "      <th>faaliyetkarı</th>\n",
       "      <th>Fiyat</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-09-30</th>\n",
       "      <td>1.187166</td>\n",
       "      <td>3.325149</td>\n",
       "      <td>0.07777</td>\n",
       "      <td>0.071396</td>\n",
       "      <td>0.066045</td>\n",
       "      <td>0.273261</td>\n",
       "      <td>0.322807</td>\n",
       "      <td>0.188458</td>\n",
       "      <td>1099765894.0</td>\n",
       "      <td>66682069.0</td>\n",
       "      <td>1331276755.0</td>\n",
       "      <td>4024606068.0</td>\n",
       "      <td>78519345.0</td>\n",
       "      <td>1009639635.0</td>\n",
       "      <td>355012154.0</td>\n",
       "      <td>207260126.0</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>2.541967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-31</th>\n",
       "      <td>1.201104</td>\n",
       "      <td>3.025843</td>\n",
       "      <td>0.09274</td>\n",
       "      <td>0.068406</td>\n",
       "      <td>0.089401</td>\n",
       "      <td>0.359219</td>\n",
       "      <td>0.293102</td>\n",
       "      <td>0.159954</td>\n",
       "      <td>1501207066.0</td>\n",
       "      <td>98993553.0</td>\n",
       "      <td>1367891599.0</td>\n",
       "      <td>4179087055.0</td>\n",
       "      <td>102691163.0</td>\n",
       "      <td>1107303831.0</td>\n",
       "      <td>440006424.0</td>\n",
       "      <td>240124457.0</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>9.549549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-31</th>\n",
       "      <td>1.135096</td>\n",
       "      <td>2.995258</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>-0.093195</td>\n",
       "      <td>-0.026796</td>\n",
       "      <td>0.088836</td>\n",
       "      <td>0.212573</td>\n",
       "      <td>0.073757</td>\n",
       "      <td>387326000.0</td>\n",
       "      <td>-31066472.0</td>\n",
       "      <td>1215548199.0</td>\n",
       "      <td>4360035822.0</td>\n",
       "      <td>-36097000.0</td>\n",
       "      <td>1159361913.0</td>\n",
       "      <td>82335000.0</td>\n",
       "      <td>28568000.0</td>\n",
       "      <td>7.126667</td>\n",
       "      <td>5.332088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-30</th>\n",
       "      <td>1.104006</td>\n",
       "      <td>3.105842</td>\n",
       "      <td>-0.011279</td>\n",
       "      <td>-0.015091</td>\n",
       "      <td>-0.008101</td>\n",
       "      <td>0.194418</td>\n",
       "      <td>0.263063</td>\n",
       "      <td>0.138244</td>\n",
       "      <td>922421000.0</td>\n",
       "      <td>-9998851.0</td>\n",
       "      <td>1387997432.0</td>\n",
       "      <td>4744524905.0</td>\n",
       "      <td>-13920000.0</td>\n",
       "      <td>1234204036.0</td>\n",
       "      <td>242655000.0</td>\n",
       "      <td>127519000.0</td>\n",
       "      <td>8.106667</td>\n",
       "      <td>0.411186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-30</th>\n",
       "      <td>1.089602</td>\n",
       "      <td>3.08818</td>\n",
       "      <td>0.062213</td>\n",
       "      <td>0.055017</td>\n",
       "      <td>0.058894</td>\n",
       "      <td>0.298796</td>\n",
       "      <td>0.305648</td>\n",
       "      <td>0.18942</td>\n",
       "      <td>1538630000.0</td>\n",
       "      <td>80135771.0</td>\n",
       "      <td>1616743346.0</td>\n",
       "      <td>5149439512.0</td>\n",
       "      <td>84651000.0</td>\n",
       "      <td>1360671737.0</td>\n",
       "      <td>470279000.0</td>\n",
       "      <td>291448000.0</td>\n",
       "      <td>7.506667</td>\n",
       "      <td>14.831257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31</th>\n",
       "      <td>1.220157</td>\n",
       "      <td>2.985869</td>\n",
       "      <td>0.087672</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.089228</td>\n",
       "      <td>0.400611</td>\n",
       "      <td>0.307215</td>\n",
       "      <td>0.180943</td>\n",
       "      <td>2037572000.0</td>\n",
       "      <td>122639000.0</td>\n",
       "      <td>1724774000.0</td>\n",
       "      <td>5086155000.0</td>\n",
       "      <td>120501000.0</td>\n",
       "      <td>1374450000.0</td>\n",
       "      <td>625972000.0</td>\n",
       "      <td>368684000.0</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>14.578216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-31</th>\n",
       "      <td>1.013363</td>\n",
       "      <td>2.975923</td>\n",
       "      <td>0.01628</td>\n",
       "      <td>0.062123</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>0.071363</td>\n",
       "      <td>0.288383</td>\n",
       "      <td>0.153111</td>\n",
       "      <td>348661000.0</td>\n",
       "      <td>28071000.0</td>\n",
       "      <td>1401485000.0</td>\n",
       "      <td>4885763000.0</td>\n",
       "      <td>21660000.0</td>\n",
       "      <td>1330500000.0</td>\n",
       "      <td>100548000.0</td>\n",
       "      <td>53384000.0</td>\n",
       "      <td>8.620000</td>\n",
       "      <td>9.048725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>1.068539</td>\n",
       "      <td>2.982578</td>\n",
       "      <td>0.083897</td>\n",
       "      <td>0.136005</td>\n",
       "      <td>0.087131</td>\n",
       "      <td>0.16817</td>\n",
       "      <td>0.346903</td>\n",
       "      <td>0.21385</td>\n",
       "      <td>798745000.0</td>\n",
       "      <td>112820000.0</td>\n",
       "      <td>1500835000.0</td>\n",
       "      <td>4749624000.0</td>\n",
       "      <td>108633000.0</td>\n",
       "      <td>1294835000.0</td>\n",
       "      <td>277087000.0</td>\n",
       "      <td>170812000.0</td>\n",
       "      <td>9.326667</td>\n",
       "      <td>-3.859903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>1.297161</td>\n",
       "      <td>3.028346</td>\n",
       "      <td>0.178848</td>\n",
       "      <td>0.190672</td>\n",
       "      <td>0.166539</td>\n",
       "      <td>0.25253</td>\n",
       "      <td>0.399607</td>\n",
       "      <td>0.274847</td>\n",
       "      <td>1326075000.0</td>\n",
       "      <td>235442000.0</td>\n",
       "      <td>1978112000.0</td>\n",
       "      <td>5251165000.0</td>\n",
       "      <td>252845000.0</td>\n",
       "      <td>1413739000.0</td>\n",
       "      <td>529909000.0</td>\n",
       "      <td>364468000.0</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>21.985815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>2.10816</td>\n",
       "      <td>3.34708</td>\n",
       "      <td>0.240638</td>\n",
       "      <td>0.163388</td>\n",
       "      <td>0.234851</td>\n",
       "      <td>0.374182</td>\n",
       "      <td>0.380484</td>\n",
       "      <td>0.259872</td>\n",
       "      <td>1863616000.0</td>\n",
       "      <td>297170000.0</td>\n",
       "      <td>1701346000.0</td>\n",
       "      <td>4980503000.0</td>\n",
       "      <td>304493000.0</td>\n",
       "      <td>1265355000.0</td>\n",
       "      <td>709076000.0</td>\n",
       "      <td>484302000.0</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>33.085504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-31</th>\n",
       "      <td>0.890429</td>\n",
       "      <td>3.388629</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.059511</td>\n",
       "      <td>0.02859</td>\n",
       "      <td>0.105176</td>\n",
       "      <td>0.228198</td>\n",
       "      <td>0.113101</td>\n",
       "      <td>515369000</td>\n",
       "      <td>37473000</td>\n",
       "      <td>1369005000</td>\n",
       "      <td>4900066000</td>\n",
       "      <td>30670000</td>\n",
       "      <td>1310683000</td>\n",
       "      <td>117606000</td>\n",
       "      <td>58289000</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>8.866280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>0.902441</td>\n",
       "      <td>3.287789</td>\n",
       "      <td>0.086754</td>\n",
       "      <td>0.10241</td>\n",
       "      <td>0.090179</td>\n",
       "      <td>0.220493</td>\n",
       "      <td>0.287868</td>\n",
       "      <td>0.187268</td>\n",
       "      <td>1186722000</td>\n",
       "      <td>126329000</td>\n",
       "      <td>1509778000</td>\n",
       "      <td>5382141000</td>\n",
       "      <td>121532000</td>\n",
       "      <td>1400873000</td>\n",
       "      <td>341619000</td>\n",
       "      <td>222235000</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>25.698323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-30</th>\n",
       "      <td>0.985673</td>\n",
       "      <td>3.191762</td>\n",
       "      <td>0.17076</td>\n",
       "      <td>0.148437</td>\n",
       "      <td>0.16549</td>\n",
       "      <td>0.306754</td>\n",
       "      <td>0.333643</td>\n",
       "      <td>0.240695</td>\n",
       "      <td>1942659000.0</td>\n",
       "      <td>279462000.0</td>\n",
       "      <td>2108330000.0</td>\n",
       "      <td>6332951000.0</td>\n",
       "      <td>288362000.0</td>\n",
       "      <td>1688695000.0</td>\n",
       "      <td>648154000.0</td>\n",
       "      <td>467588000.0</td>\n",
       "      <td>12.483333</td>\n",
       "      <td>32.843797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>1.880259</td>\n",
       "      <td>3.19461</td>\n",
       "      <td>0.182428</td>\n",
       "      <td>0.129288</td>\n",
       "      <td>0.182753</td>\n",
       "      <td>0.373438</td>\n",
       "      <td>0.331512</td>\n",
       "      <td>0.239411</td>\n",
       "      <td>2594925000.0</td>\n",
       "      <td>336088000.0</td>\n",
       "      <td>2291645000.0</td>\n",
       "      <td>6948741000.0</td>\n",
       "      <td>335492000.0</td>\n",
       "      <td>1839033000.0</td>\n",
       "      <td>860250000.0</td>\n",
       "      <td>621253000.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.111113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>1.598755</td>\n",
       "      <td>3.107638</td>\n",
       "      <td>0.029232</td>\n",
       "      <td>0.084922</td>\n",
       "      <td>0.036195</td>\n",
       "      <td>0.089398</td>\n",
       "      <td>0.295214</td>\n",
       "      <td>0.171904</td>\n",
       "      <td>586466000</td>\n",
       "      <td>61668000</td>\n",
       "      <td>1670534000</td>\n",
       "      <td>6560164000</td>\n",
       "      <td>49804000</td>\n",
       "      <td>1703755000</td>\n",
       "      <td>173133000</td>\n",
       "      <td>100816000</td>\n",
       "      <td>16.583334</td>\n",
       "      <td>8.341704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-30</th>\n",
       "      <td>2.038426</td>\n",
       "      <td>3.133394</td>\n",
       "      <td>0.135559</td>\n",
       "      <td>0.189924</td>\n",
       "      <td>0.141196</td>\n",
       "      <td>0.184167</td>\n",
       "      <td>0.352719</td>\n",
       "      <td>0.270911</td>\n",
       "      <td>1276661000</td>\n",
       "      <td>252550000</td>\n",
       "      <td>2240138000</td>\n",
       "      <td>6932095000</td>\n",
       "      <td>242468000</td>\n",
       "      <td>1788647000</td>\n",
       "      <td>450303000</td>\n",
       "      <td>345861000</td>\n",
       "      <td>16.816667</td>\n",
       "      <td>12.487610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-30</th>\n",
       "      <td>2.261604</td>\n",
       "      <td>2.59847</td>\n",
       "      <td>0.248563</td>\n",
       "      <td>0.25379</td>\n",
       "      <td>0.246379</td>\n",
       "      <td>0.289978</td>\n",
       "      <td>0.408327</td>\n",
       "      <td>0.332459</td>\n",
       "      <td>2024296000</td>\n",
       "      <td>509234000</td>\n",
       "      <td>1987511000</td>\n",
       "      <td>6980855000</td>\n",
       "      <td>513747000</td>\n",
       "      <td>2066872000</td>\n",
       "      <td>826574000</td>\n",
       "      <td>672996000</td>\n",
       "      <td>17.966667</td>\n",
       "      <td>11.224488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>2.481515</td>\n",
       "      <td>2.760496</td>\n",
       "      <td>0.295052</td>\n",
       "      <td>0.234366</td>\n",
       "      <td>0.301525</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.414557</td>\n",
       "      <td>0.325945</td>\n",
       "      <td>2648050000</td>\n",
       "      <td>634228000</td>\n",
       "      <td>2562216000</td>\n",
       "      <td>7465541000</td>\n",
       "      <td>620614000</td>\n",
       "      <td>2103403000</td>\n",
       "      <td>1097767000</td>\n",
       "      <td>863119000</td>\n",
       "      <td>18.916667</td>\n",
       "      <td>20.440529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>1.702005</td>\n",
       "      <td>3.035986</td>\n",
       "      <td>0.033304</td>\n",
       "      <td>0.128705</td>\n",
       "      <td>0.038615</td>\n",
       "      <td>0.069333</td>\n",
       "      <td>0.35123</td>\n",
       "      <td>0.241307</td>\n",
       "      <td>568938000.0</td>\n",
       "      <td>84904000.0</td>\n",
       "      <td>2226892000.0</td>\n",
       "      <td>8205819000.0</td>\n",
       "      <td>73225000.0</td>\n",
       "      <td>2198707000.0</td>\n",
       "      <td>199828000.0</td>\n",
       "      <td>137289000.0</td>\n",
       "      <td>19.983333</td>\n",
       "      <td>14.011679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-30</th>\n",
       "      <td>0.988604</td>\n",
       "      <td>3.137667</td>\n",
       "      <td>0.108227</td>\n",
       "      <td>0.176796</td>\n",
       "      <td>0.115881</td>\n",
       "      <td>0.158332</td>\n",
       "      <td>0.435774</td>\n",
       "      <td>0.347581</td>\n",
       "      <td>1335551000.0</td>\n",
       "      <td>252819000.0</td>\n",
       "      <td>2352098000.0</td>\n",
       "      <td>8435154000.0</td>\n",
       "      <td>236120000.0</td>\n",
       "      <td>2181718000.0</td>\n",
       "      <td>581999000.0</td>\n",
       "      <td>464212000.0</td>\n",
       "      <td>22.783333</td>\n",
       "      <td>-9.100218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-30</th>\n",
       "      <td>0.937966</td>\n",
       "      <td>3.147641</td>\n",
       "      <td>0.176944</td>\n",
       "      <td>0.214902</td>\n",
       "      <td>0.182682</td>\n",
       "      <td>0.228048</td>\n",
       "      <td>0.475845</td>\n",
       "      <td>0.407904</td>\n",
       "      <td>2247468000</td>\n",
       "      <td>498647000</td>\n",
       "      <td>3060669000</td>\n",
       "      <td>9855244000</td>\n",
       "      <td>482985000</td>\n",
       "      <td>2729587000</td>\n",
       "      <td>1069447000</td>\n",
       "      <td>916751000</td>\n",
       "      <td>22.783333</td>\n",
       "      <td>-24.272129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>0.982448</td>\n",
       "      <td>3.463618</td>\n",
       "      <td>0.233957</td>\n",
       "      <td>0.199833</td>\n",
       "      <td>0.244859</td>\n",
       "      <td>0.288033</td>\n",
       "      <td>0.44881</td>\n",
       "      <td>0.411339</td>\n",
       "      <td>3026180000</td>\n",
       "      <td>632912000</td>\n",
       "      <td>2921040000</td>\n",
       "      <td>10506371000</td>\n",
       "      <td>604732000</td>\n",
       "      <td>2584800000</td>\n",
       "      <td>1358180000</td>\n",
       "      <td>1244787000</td>\n",
       "      <td>20.710000</td>\n",
       "      <td>-29.534848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>0.759721</td>\n",
       "      <td>3.69183</td>\n",
       "      <td>0.017424</td>\n",
       "      <td>0.057732</td>\n",
       "      <td>0.020924</td>\n",
       "      <td>0.068733</td>\n",
       "      <td>0.350339</td>\n",
       "      <td>0.272721</td>\n",
       "      <td>684737000</td>\n",
       "      <td>47471000</td>\n",
       "      <td>2215148000</td>\n",
       "      <td>9962277000</td>\n",
       "      <td>39531000</td>\n",
       "      <td>2268748000</td>\n",
       "      <td>239890000</td>\n",
       "      <td>186742000</td>\n",
       "      <td>17.253333</td>\n",
       "      <td>-32.670017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30</th>\n",
       "      <td>0.78445</td>\n",
       "      <td>3.66199</td>\n",
       "      <td>0.030507</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>0.044795</td>\n",
       "      <td>0.15226</td>\n",
       "      <td>0.392934</td>\n",
       "      <td>0.322853</td>\n",
       "      <td>1506721000</td>\n",
       "      <td>102728000</td>\n",
       "      <td>2373470000</td>\n",
       "      <td>9895743000</td>\n",
       "      <td>69962000</td>\n",
       "      <td>2293314000</td>\n",
       "      <td>592042000</td>\n",
       "      <td>486449000</td>\n",
       "      <td>14.593333</td>\n",
       "      <td>-9.365006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-30</th>\n",
       "      <td>0.878303</td>\n",
       "      <td>3.2944</td>\n",
       "      <td>0.126963</td>\n",
       "      <td>0.137526</td>\n",
       "      <td>0.134934</td>\n",
       "      <td>0.23449</td>\n",
       "      <td>0.423584</td>\n",
       "      <td>0.355441</td>\n",
       "      <td>2458050000</td>\n",
       "      <td>359268000</td>\n",
       "      <td>2636521000</td>\n",
       "      <td>10482540000</td>\n",
       "      <td>338046000</td>\n",
       "      <td>2662549000</td>\n",
       "      <td>1041190000</td>\n",
       "      <td>873692000</td>\n",
       "      <td>11.616666</td>\n",
       "      <td>29.670015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>0.844305</td>\n",
       "      <td>3.205883</td>\n",
       "      <td>0.133383</td>\n",
       "      <td>0.107303</td>\n",
       "      <td>0.14172</td>\n",
       "      <td>0.323497</td>\n",
       "      <td>0.445073</td>\n",
       "      <td>0.314956</td>\n",
       "      <td>3721986000</td>\n",
       "      <td>424341000</td>\n",
       "      <td>2941922000</td>\n",
       "      <td>11505470000</td>\n",
       "      <td>399379000</td>\n",
       "      <td>2994224000</td>\n",
       "      <td>1656555000</td>\n",
       "      <td>1172260000</td>\n",
       "      <td>13.226667</td>\n",
       "      <td>28.427423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>0.760138</td>\n",
       "      <td>3.200859</td>\n",
       "      <td>0.013034</td>\n",
       "      <td>0.042964</td>\n",
       "      <td>0.01551</td>\n",
       "      <td>0.076915</td>\n",
       "      <td>0.368883</td>\n",
       "      <td>0.256388</td>\n",
       "      <td>899940000</td>\n",
       "      <td>46011000</td>\n",
       "      <td>2698693000</td>\n",
       "      <td>11700426000</td>\n",
       "      <td>38665000</td>\n",
       "      <td>2966506000</td>\n",
       "      <td>331973000</td>\n",
       "      <td>230734000</td>\n",
       "      <td>15.063333</td>\n",
       "      <td>33.193183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>0.738968</td>\n",
       "      <td>3.023695</td>\n",
       "      <td>0.075094</td>\n",
       "      <td>0.118057</td>\n",
       "      <td>0.073214</td>\n",
       "      <td>0.170985</td>\n",
       "      <td>0.414695</td>\n",
       "      <td>0.314074</td>\n",
       "      <td>2049219000</td>\n",
       "      <td>235868000</td>\n",
       "      <td>2993290000</td>\n",
       "      <td>11984801000</td>\n",
       "      <td>241924000</td>\n",
       "      <td>3221619000</td>\n",
       "      <td>849800000</td>\n",
       "      <td>643606000</td>\n",
       "      <td>16.986667</td>\n",
       "      <td>19.407375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>0.866361</td>\n",
       "      <td>2.740676</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>0.202884</td>\n",
       "      <td>0.172563</td>\n",
       "      <td>0.267418</td>\n",
       "      <td>0.465464</td>\n",
       "      <td>0.368717</td>\n",
       "      <td>3459141000</td>\n",
       "      <td>652959000</td>\n",
       "      <td>3611697000</td>\n",
       "      <td>12935336000</td>\n",
       "      <td>701806000</td>\n",
       "      <td>3783879000</td>\n",
       "      <td>1610106000</td>\n",
       "      <td>1275443000</td>\n",
       "      <td>20.063333</td>\n",
       "      <td>14.636986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>0.861784</td>\n",
       "      <td>2.805818</td>\n",
       "      <td>0.189929</td>\n",
       "      <td>0.162755</td>\n",
       "      <td>0.178863</td>\n",
       "      <td>0.343533</td>\n",
       "      <td>0.439533</td>\n",
       "      <td>0.332883</td>\n",
       "      <td>4686016000.0</td>\n",
       "      <td>718234000.0</td>\n",
       "      <td>3733491000.0</td>\n",
       "      <td>13640645000.0</td>\n",
       "      <td>762673000.0</td>\n",
       "      <td>4015560000.0</td>\n",
       "      <td>2059658000.0</td>\n",
       "      <td>1559893000.0</td>\n",
       "      <td>20.283333</td>\n",
       "      <td>8.069022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>0.768141</td>\n",
       "      <td>2.918173</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.042745</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>0.043601</td>\n",
       "      <td>0.36514</td>\n",
       "      <td>0.169283</td>\n",
       "      <td>619187000</td>\n",
       "      <td>33609000</td>\n",
       "      <td>3606381000</td>\n",
       "      <td>14201105000</td>\n",
       "      <td>26467000</td>\n",
       "      <td>3985337000</td>\n",
       "      <td>226090000</td>\n",
       "      <td>104818000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>34.811595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>0.870852</td>\n",
       "      <td>2.924797</td>\n",
       "      <td>0.097416</td>\n",
       "      <td>0.305065</td>\n",
       "      <td>0.095057</td>\n",
       "      <td>0.08718</td>\n",
       "      <td>0.457995</td>\n",
       "      <td>0.230939</td>\n",
       "      <td>1545233000</td>\n",
       "      <td>459981000</td>\n",
       "      <td>4291430000</td>\n",
       "      <td>17724568000</td>\n",
       "      <td>471397000</td>\n",
       "      <td>4838997000</td>\n",
       "      <td>707709000</td>\n",
       "      <td>356854000</td>\n",
       "      <td>21.920000</td>\n",
       "      <td>6.599757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>0.906595</td>\n",
       "      <td>2.921245</td>\n",
       "      <td>0.17058</td>\n",
       "      <td>0.404272</td>\n",
       "      <td>0.162472</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>0.507885</td>\n",
       "      <td>0.25745</td>\n",
       "      <td>2938094000</td>\n",
       "      <td>1131334000</td>\n",
       "      <td>5609253000</td>\n",
       "      <td>23581223000</td>\n",
       "      <td>1187788000</td>\n",
       "      <td>6963245000</td>\n",
       "      <td>1492213000</td>\n",
       "      <td>756413000</td>\n",
       "      <td>31.006667</td>\n",
       "      <td>-14.491507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>1.052197</td>\n",
       "      <td>2.458703</td>\n",
       "      <td>0.24396</td>\n",
       "      <td>0.381669</td>\n",
       "      <td>0.233899</td>\n",
       "      <td>0.19109</td>\n",
       "      <td>0.492479</td>\n",
       "      <td>0.229498</td>\n",
       "      <td>3975497000</td>\n",
       "      <td>1454747000</td>\n",
       "      <td>5462462000</td>\n",
       "      <td>20804281000</td>\n",
       "      <td>1517324000</td>\n",
       "      <td>6219550000</td>\n",
       "      <td>1957847000</td>\n",
       "      <td>912370000</td>\n",
       "      <td>23.366667</td>\n",
       "      <td>10.356631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>1.001828</td>\n",
       "      <td>2.825003</td>\n",
       "      <td>0.023771</td>\n",
       "      <td>0.151421</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.043372</td>\n",
       "      <td>0.425831</td>\n",
       "      <td>0.096785</td>\n",
       "      <td>919583000</td>\n",
       "      <td>145644000</td>\n",
       "      <td>5509450000</td>\n",
       "      <td>21202423000</td>\n",
       "      <td>139244000</td>\n",
       "      <td>5857735000</td>\n",
       "      <td>391587000</td>\n",
       "      <td>89002000</td>\n",
       "      <td>26.513334</td>\n",
       "      <td>-9.001760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-30</th>\n",
       "      <td>1.02088</td>\n",
       "      <td>2.77394</td>\n",
       "      <td>0.06478</td>\n",
       "      <td>0.184816</td>\n",
       "      <td>0.063254</td>\n",
       "      <td>0.09729</td>\n",
       "      <td>0.453801</td>\n",
       "      <td>0.261949</td>\n",
       "      <td>2154343000</td>\n",
       "      <td>388778000</td>\n",
       "      <td>5579776000</td>\n",
       "      <td>22143460000</td>\n",
       "      <td>398157000</td>\n",
       "      <td>6146334000</td>\n",
       "      <td>977642000</td>\n",
       "      <td>564329000</td>\n",
       "      <td>25.786666</td>\n",
       "      <td>6.256466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-30</th>\n",
       "      <td>1.161425</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.149165</td>\n",
       "      <td>0.265084</td>\n",
       "      <td>0.144667</td>\n",
       "      <td>0.167957</td>\n",
       "      <td>0.494208</td>\n",
       "      <td>0.314422</td>\n",
       "      <td>3694766000</td>\n",
       "      <td>949894000</td>\n",
       "      <td>6271887000</td>\n",
       "      <td>21998272000</td>\n",
       "      <td>979423000</td>\n",
       "      <td>6566059000</td>\n",
       "      <td>1825983000</td>\n",
       "      <td>1161715000</td>\n",
       "      <td>24.126667</td>\n",
       "      <td>-11.094226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>1.183624</td>\n",
       "      <td>2.026137</td>\n",
       "      <td>0.277335</td>\n",
       "      <td>0.507845</td>\n",
       "      <td>0.271948</td>\n",
       "      <td>0.186103</td>\n",
       "      <td>0.472265</td>\n",
       "      <td>0.274938</td>\n",
       "      <td>4756204000</td>\n",
       "      <td>2368497000</td>\n",
       "      <td>7169674000</td>\n",
       "      <td>25556843000</td>\n",
       "      <td>2415416000</td>\n",
       "      <td>8709369000</td>\n",
       "      <td>2246191000</td>\n",
       "      <td>1307662000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>-29.501216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>1.242737</td>\n",
       "      <td>2.369019</td>\n",
       "      <td>-0.043282</td>\n",
       "      <td>-0.46019</td>\n",
       "      <td>-0.044498</td>\n",
       "      <td>0.02871</td>\n",
       "      <td>0.332943</td>\n",
       "      <td>0.01935</td>\n",
       "      <td>796208000</td>\n",
       "      <td>-376696000</td>\n",
       "      <td>9536913000</td>\n",
       "      <td>27733129000</td>\n",
       "      <td>-366407000</td>\n",
       "      <td>8465546000</td>\n",
       "      <td>265092000</td>\n",
       "      <td>15407000</td>\n",
       "      <td>21.450000</td>\n",
       "      <td>-26.386947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>1.14963</td>\n",
       "      <td>2.458993</td>\n",
       "      <td>-0.128316</td>\n",
       "      <td>-1.053561</td>\n",
       "      <td>-0.128872</td>\n",
       "      <td>0.036068</td>\n",
       "      <td>0.249404</td>\n",
       "      <td>-0.174582</td>\n",
       "      <td>1011974000</td>\n",
       "      <td>-1070796000</td>\n",
       "      <td>8846984000</td>\n",
       "      <td>28057419000</td>\n",
       "      <td>-1066176000</td>\n",
       "      <td>8309013000</td>\n",
       "      <td>252390000</td>\n",
       "      <td>-176672000</td>\n",
       "      <td>19.316667</td>\n",
       "      <td>-6.678172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>1.215598</td>\n",
       "      <td>2.797274</td>\n",
       "      <td>-0.163494</td>\n",
       "      <td>-0.876096</td>\n",
       "      <td>-0.163827</td>\n",
       "      <td>0.051331</td>\n",
       "      <td>0.278496</td>\n",
       "      <td>-0.063597</td>\n",
       "      <td>1726526000</td>\n",
       "      <td>-1515678000</td>\n",
       "      <td>11184890000</td>\n",
       "      <td>33634895000</td>\n",
       "      <td>-1512602000</td>\n",
       "      <td>9251721000</td>\n",
       "      <td>480831000</td>\n",
       "      <td>-109802000</td>\n",
       "      <td>15.790000</td>\n",
       "      <td>41.144186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.838265</td>\n",
       "      <td>3.138572</td>\n",
       "      <td>-0.271187</td>\n",
       "      <td>-0.945289</td>\n",
       "      <td>-0.271184</td>\n",
       "      <td>0.075426</td>\n",
       "      <td>0.154921</td>\n",
       "      <td>-0.207541</td>\n",
       "      <td>2415468000</td>\n",
       "      <td>-2283284000</td>\n",
       "      <td>9770948000</td>\n",
       "      <td>32024208000</td>\n",
       "      <td>-2283316000</td>\n",
       "      <td>8419698000</td>\n",
       "      <td>374206000</td>\n",
       "      <td>-501308000</td>\n",
       "      <td>18.026667</td>\n",
       "      <td>27.995561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <td>1.521508</td>\n",
       "      <td>2.638008</td>\n",
       "      <td>0.054686</td>\n",
       "      <td>1.017421</td>\n",
       "      <td>0.055178</td>\n",
       "      <td>0.01578</td>\n",
       "      <td>0.278887</td>\n",
       "      <td>-0.266247</td>\n",
       "      <td>538541000</td>\n",
       "      <td>552858000</td>\n",
       "      <td>9740644000</td>\n",
       "      <td>34128244000</td>\n",
       "      <td>547923000</td>\n",
       "      <td>10019470000</td>\n",
       "      <td>150192000</td>\n",
       "      <td>-143385000</td>\n",
       "      <td>22.286667</td>\n",
       "      <td>8.226144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>1.668071</td>\n",
       "      <td>2.327475</td>\n",
       "      <td>0.021998</td>\n",
       "      <td>0.154419</td>\n",
       "      <td>0.02124</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.322163</td>\n",
       "      <td>-0.061572</td>\n",
       "      <td>1479095000</td>\n",
       "      <td>220527000</td>\n",
       "      <td>5458568000</td>\n",
       "      <td>34558660000</td>\n",
       "      <td>228400000</td>\n",
       "      <td>10382597000</td>\n",
       "      <td>476509000</td>\n",
       "      <td>-91071000</td>\n",
       "      <td>23.073333</td>\n",
       "      <td>24.443805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>1.492592</td>\n",
       "      <td>2.247204</td>\n",
       "      <td>0.07985</td>\n",
       "      <td>0.257628</td>\n",
       "      <td>0.076776</td>\n",
       "      <td>0.096857</td>\n",
       "      <td>0.427647</td>\n",
       "      <td>0.149261</td>\n",
       "      <td>3442981000</td>\n",
       "      <td>852863000</td>\n",
       "      <td>6337804000</td>\n",
       "      <td>35547215000</td>\n",
       "      <td>887009000</td>\n",
       "      <td>11108509000</td>\n",
       "      <td>1472380000</td>\n",
       "      <td>513902000</td>\n",
       "      <td>24.120000</td>\n",
       "      <td>53.565508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>0.899295</td>\n",
       "      <td>2.364385</td>\n",
       "      <td>0.034262</td>\n",
       "      <td>0.095692</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.105049</td>\n",
       "      <td>0.404858</td>\n",
       "      <td>0.110363</td>\n",
       "      <td>5459329000</td>\n",
       "      <td>467689000</td>\n",
       "      <td>6747366000</td>\n",
       "      <td>51969566000</td>\n",
       "      <td>522412000</td>\n",
       "      <td>15247512000</td>\n",
       "      <td>2210255000</td>\n",
       "      <td>602509000</td>\n",
       "      <td>28.713334</td>\n",
       "      <td>60.668674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>1.08665</td>\n",
       "      <td>2.721862</td>\n",
       "      <td>-0.019051</td>\n",
       "      <td>-0.134922</td>\n",
       "      <td>-0.020325</td>\n",
       "      <td>0.036966</td>\n",
       "      <td>0.363175</td>\n",
       "      <td>0.099009</td>\n",
       "      <td>2332361000</td>\n",
       "      <td>-335732000</td>\n",
       "      <td>8984952000</td>\n",
       "      <td>63094629000</td>\n",
       "      <td>-314686000</td>\n",
       "      <td>16518472000</td>\n",
       "      <td>847055000</td>\n",
       "      <td>230925000</td>\n",
       "      <td>37.040001</td>\n",
       "      <td>63.606907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>0.893805</td>\n",
       "      <td>2.578829</td>\n",
       "      <td>0.018043</td>\n",
       "      <td>0.052587</td>\n",
       "      <td>0.015302</td>\n",
       "      <td>0.093802</td>\n",
       "      <td>0.404873</td>\n",
       "      <td>0.233026</td>\n",
       "      <td>6608701000</td>\n",
       "      <td>294734000</td>\n",
       "      <td>10971945000</td>\n",
       "      <td>70453570000</td>\n",
       "      <td>347530000</td>\n",
       "      <td>19261186000</td>\n",
       "      <td>2675684000</td>\n",
       "      <td>1539999000</td>\n",
       "      <td>46.133333</td>\n",
       "      <td>87.608386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>1.008325</td>\n",
       "      <td>2.316143</td>\n",
       "      <td>0.086354</td>\n",
       "      <td>0.158293</td>\n",
       "      <td>0.081355</td>\n",
       "      <td>0.159707</td>\n",
       "      <td>0.440019</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>12533881000</td>\n",
       "      <td>1869175000</td>\n",
       "      <td>14322765000</td>\n",
       "      <td>78480272000</td>\n",
       "      <td>1984030000</td>\n",
       "      <td>22975476000</td>\n",
       "      <td>5515143000</td>\n",
       "      <td>3282683000</td>\n",
       "      <td>60.600000</td>\n",
       "      <td>27.337734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>1.00773</td>\n",
       "      <td>2.497601</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>0.111789</td>\n",
       "      <td>0.080589</td>\n",
       "      <td>0.217089</td>\n",
       "      <td>0.42086</td>\n",
       "      <td>0.216016</td>\n",
       "      <td>18308307000</td>\n",
       "      <td>1899087000</td>\n",
       "      <td>14985806000</td>\n",
       "      <td>84335435000</td>\n",
       "      <td>2046662000</td>\n",
       "      <td>23564987000</td>\n",
       "      <td>7705233000</td>\n",
       "      <td>3954880000</td>\n",
       "      <td>86.550001</td>\n",
       "      <td>-7.009438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>1.209919</td>\n",
       "      <td>2.609891</td>\n",
       "      <td>-0.037729</td>\n",
       "      <td>-0.175575</td>\n",
       "      <td>-0.039033</td>\n",
       "      <td>0.057878</td>\n",
       "      <td>0.302783</td>\n",
       "      <td>0.100422</td>\n",
       "      <td>5059550000</td>\n",
       "      <td>-919035000</td>\n",
       "      <td>16195644000</td>\n",
       "      <td>87416771000</td>\n",
       "      <td>-888333000</td>\n",
       "      <td>23545163000</td>\n",
       "      <td>1531948000</td>\n",
       "      <td>508088000</td>\n",
       "      <td>77.166667</td>\n",
       "      <td>55.637150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>0.915477</td>\n",
       "      <td>2.722779</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>0.098832</td>\n",
       "      <td>0.362662</td>\n",
       "      <td>0.181849</td>\n",
       "      <td>11985064000</td>\n",
       "      <td>-31638000</td>\n",
       "      <td>21516364000</td>\n",
       "      <td>121267603000</td>\n",
       "      <td>51153000</td>\n",
       "      <td>32256292000</td>\n",
       "      <td>4346523000</td>\n",
       "      <td>2179473000</td>\n",
       "      <td>80.483332</td>\n",
       "      <td>40.028993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30</th>\n",
       "      <td>1.166289</td>\n",
       "      <td>2.451894</td>\n",
       "      <td>0.141127</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>0.136411</td>\n",
       "      <td>0.176688</td>\n",
       "      <td>0.410375</td>\n",
       "      <td>0.247121</td>\n",
       "      <td>23817499000</td>\n",
       "      <td>5370141000</td>\n",
       "      <td>29706699000</td>\n",
       "      <td>134799506000</td>\n",
       "      <td>5555784000</td>\n",
       "      <td>39367235000</td>\n",
       "      <td>9774110000</td>\n",
       "      <td>5885809000</td>\n",
       "      <td>120.100001</td>\n",
       "      <td>37.635305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>1.138563</td>\n",
       "      <td>2.112817</td>\n",
       "      <td>0.167383</td>\n",
       "      <td>0.225871</td>\n",
       "      <td>0.16206</td>\n",
       "      <td>0.222397</td>\n",
       "      <td>0.385956</td>\n",
       "      <td>0.18884</td>\n",
       "      <td>34433068000</td>\n",
       "      <td>7530074000</td>\n",
       "      <td>33605578000</td>\n",
       "      <td>154826945000</td>\n",
       "      <td>7777419000</td>\n",
       "      <td>46464702000</td>\n",
       "      <td>13289634000</td>\n",
       "      <td>6502355000</td>\n",
       "      <td>112.699999</td>\n",
       "      <td>112.984322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-31</th>\n",
       "      <td>1.078088</td>\n",
       "      <td>2.07013</td>\n",
       "      <td>0.007172</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>0.00588</td>\n",
       "      <td>0.064692</td>\n",
       "      <td>0.361055</td>\n",
       "      <td>0.17187</td>\n",
       "      <td>10763165000</td>\n",
       "      <td>298268000</td>\n",
       "      <td>32727740000</td>\n",
       "      <td>166376256000</td>\n",
       "      <td>363801000</td>\n",
       "      <td>50727786000</td>\n",
       "      <td>3886092000</td>\n",
       "      <td>1849862000</td>\n",
       "      <td>165.300003</td>\n",
       "      <td>53.856620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-30</th>\n",
       "      <td>0.929254</td>\n",
       "      <td>1.984263</td>\n",
       "      <td>0.055899</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>0.052243</td>\n",
       "      <td>0.145719</td>\n",
       "      <td>0.384351</td>\n",
       "      <td>0.200054</td>\n",
       "      <td>25075467000</td>\n",
       "      <td>2805790000</td>\n",
       "      <td>34672407000</td>\n",
       "      <td>172081539000</td>\n",
       "      <td>3002142000</td>\n",
       "      <td>53706956000</td>\n",
       "      <td>9637786000</td>\n",
       "      <td>5016455000</td>\n",
       "      <td>240.033330</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cari Oran Borçluluk Oranı Return On Equity Net Kar Marjı       ROE  \\\n",
       "2010-09-30  1.187166        3.325149          0.07777      0.071396  0.066045   \n",
       "2010-12-31  1.201104        3.025843          0.09274      0.068406  0.089401   \n",
       "2011-03-31  1.135096        2.995258        -0.031135     -0.093195 -0.026796   \n",
       "2011-06-30  1.104006        3.105842        -0.011279     -0.015091 -0.008101   \n",
       "2011-09-30  1.089602         3.08818         0.062213      0.055017  0.058894   \n",
       "2011-12-31  1.220157        2.985869         0.087672       0.05914  0.089228   \n",
       "2012-03-31  1.013363        2.975923          0.01628      0.062123  0.021098   \n",
       "2012-06-30  1.068539        2.982578         0.083897      0.136005  0.087131   \n",
       "2012-09-30  1.297161        3.028346         0.178848      0.190672  0.166539   \n",
       "2012-12-31   2.10816         3.34708         0.240638      0.163388  0.234851   \n",
       "2013-03-31  0.890429        3.388629           0.0234      0.059511   0.02859   \n",
       "2013-06-30  0.902441        3.287789         0.086754       0.10241  0.090179   \n",
       "2013-09-30  0.985673        3.191762          0.17076      0.148437   0.16549   \n",
       "2013-12-31  1.880259         3.19461         0.182428      0.129288  0.182753   \n",
       "2014-03-31  1.598755        3.107638         0.029232      0.084922  0.036195   \n",
       "2014-06-30  2.038426        3.133394         0.135559      0.189924  0.141196   \n",
       "2014-09-30  2.261604         2.59847         0.248563       0.25379  0.246379   \n",
       "2014-12-31  2.481515        2.760496         0.295052      0.234366  0.301525   \n",
       "2015-03-31  1.702005        3.035986         0.033304      0.128705  0.038615   \n",
       "2015-06-30  0.988604        3.137667         0.108227      0.176796  0.115881   \n",
       "2015-09-30  0.937966        3.147641         0.176944      0.214902  0.182682   \n",
       "2015-12-31  0.982448        3.463618         0.233957      0.199833  0.244859   \n",
       "2016-03-31  0.759721         3.69183         0.017424      0.057732  0.020924   \n",
       "2016-06-30   0.78445         3.66199         0.030507      0.046433  0.044795   \n",
       "2016-09-30  0.878303          3.2944         0.126963      0.137526  0.134934   \n",
       "2016-12-31  0.844305        3.205883         0.133383      0.107303   0.14172   \n",
       "2017-03-31  0.760138        3.200859         0.013034      0.042964   0.01551   \n",
       "2017-06-30  0.738968        3.023695         0.075094      0.118057  0.073214   \n",
       "2017-09-30  0.866361        2.740676         0.185473      0.202884  0.172563   \n",
       "2017-12-31  0.861784        2.805818         0.189929      0.162755  0.178863   \n",
       "2018-03-31  0.768141        2.918173         0.006641      0.042745  0.008433   \n",
       "2018-06-30  0.870852        2.924797         0.097416      0.305065  0.095057   \n",
       "2018-09-30  0.906595        2.921245          0.17058      0.404272  0.162472   \n",
       "2018-12-31  1.052197        2.458703          0.24396      0.381669  0.233899   \n",
       "2019-03-31  1.001828        2.825003         0.023771      0.151421  0.024864   \n",
       "2019-06-30   1.02088         2.77394          0.06478      0.184816  0.063254   \n",
       "2019-09-30  1.161425        2.538806         0.149165      0.265084  0.144667   \n",
       "2019-12-31  1.183624        2.026137         0.277335      0.507845  0.271948   \n",
       "2020-03-31  1.242737        2.369019        -0.043282      -0.46019 -0.044498   \n",
       "2020-06-30   1.14963        2.458993        -0.128316     -1.053561 -0.128872   \n",
       "2020-09-30  1.215598        2.797274        -0.163494     -0.876096 -0.163827   \n",
       "2020-12-31  0.838265        3.138572        -0.271187     -0.945289 -0.271184   \n",
       "2021-03-31  1.521508        2.638008         0.054686      1.017421  0.055178   \n",
       "2021-06-30  1.668071        2.327475         0.021998      0.154419   0.02124   \n",
       "2021-09-30  1.492592        2.247204          0.07985      0.257628  0.076776   \n",
       "2021-12-31  0.899295        2.364385         0.034262      0.095692  0.030673   \n",
       "2022-03-31   1.08665        2.721862        -0.019051     -0.134922 -0.020325   \n",
       "2022-06-30  0.893805        2.578829         0.018043      0.052587  0.015302   \n",
       "2022-09-30  1.008325        2.316143         0.086354      0.158293  0.081355   \n",
       "2022-12-31   1.00773        2.497601         0.086852      0.111789  0.080589   \n",
       "2023-03-31  1.209919        2.609891        -0.037729     -0.175575 -0.039033   \n",
       "2023-06-30  0.915477        2.722779         0.001586      0.004268 -0.000981   \n",
       "2023-09-30  1.166289        2.451894         0.141127      0.233265  0.136411   \n",
       "2023-12-31  1.138563        2.112817         0.167383      0.225871   0.16206   \n",
       "2024-03-31  1.078088         2.07013         0.007172      0.033801   0.00588   \n",
       "2024-06-30  0.929254        1.984263         0.055899      0.119724  0.052243   \n",
       "\n",
       "           Devir Hızı Brüt Kar Marjı Faaliyet Kar Marjı             s  \\\n",
       "2010-09-30   0.273261       0.322807           0.188458  1099765894.0   \n",
       "2010-12-31   0.359219       0.293102           0.159954  1501207066.0   \n",
       "2011-03-31   0.088836       0.212573           0.073757   387326000.0   \n",
       "2011-06-30   0.194418       0.263063           0.138244   922421000.0   \n",
       "2011-09-30   0.298796       0.305648            0.18942  1538630000.0   \n",
       "2011-12-31   0.400611       0.307215           0.180943  2037572000.0   \n",
       "2012-03-31   0.071363       0.288383           0.153111   348661000.0   \n",
       "2012-06-30    0.16817       0.346903            0.21385   798745000.0   \n",
       "2012-09-30    0.25253       0.399607           0.274847  1326075000.0   \n",
       "2012-12-31   0.374182       0.380484           0.259872  1863616000.0   \n",
       "2013-03-31   0.105176       0.228198           0.113101     515369000   \n",
       "2013-06-30   0.220493       0.287868           0.187268    1186722000   \n",
       "2013-09-30   0.306754       0.333643           0.240695  1942659000.0   \n",
       "2013-12-31   0.373438       0.331512           0.239411  2594925000.0   \n",
       "2014-03-31   0.089398       0.295214           0.171904     586466000   \n",
       "2014-06-30   0.184167       0.352719           0.270911    1276661000   \n",
       "2014-09-30   0.289978       0.408327           0.332459    2024296000   \n",
       "2014-12-31   0.354703       0.414557           0.325945    2648050000   \n",
       "2015-03-31   0.069333        0.35123           0.241307   568938000.0   \n",
       "2015-06-30   0.158332       0.435774           0.347581  1335551000.0   \n",
       "2015-09-30   0.228048       0.475845           0.407904    2247468000   \n",
       "2015-12-31   0.288033        0.44881           0.411339    3026180000   \n",
       "2016-03-31   0.068733       0.350339           0.272721     684737000   \n",
       "2016-06-30    0.15226       0.392934           0.322853    1506721000   \n",
       "2016-09-30    0.23449       0.423584           0.355441    2458050000   \n",
       "2016-12-31   0.323497       0.445073           0.314956    3721986000   \n",
       "2017-03-31   0.076915       0.368883           0.256388     899940000   \n",
       "2017-06-30   0.170985       0.414695           0.314074    2049219000   \n",
       "2017-09-30   0.267418       0.465464           0.368717    3459141000   \n",
       "2017-12-31   0.343533       0.439533           0.332883  4686016000.0   \n",
       "2018-03-31   0.043601        0.36514           0.169283     619187000   \n",
       "2018-06-30    0.08718       0.457995           0.230939    1545233000   \n",
       "2018-09-30   0.124595       0.507885            0.25745    2938094000   \n",
       "2018-12-31    0.19109       0.492479           0.229498    3975497000   \n",
       "2019-03-31   0.043372       0.425831           0.096785     919583000   \n",
       "2019-06-30    0.09729       0.453801           0.261949    2154343000   \n",
       "2019-09-30   0.167957       0.494208           0.314422    3694766000   \n",
       "2019-12-31   0.186103       0.472265           0.274938    4756204000   \n",
       "2020-03-31    0.02871       0.332943            0.01935     796208000   \n",
       "2020-06-30   0.036068       0.249404          -0.174582    1011974000   \n",
       "2020-09-30   0.051331       0.278496          -0.063597    1726526000   \n",
       "2020-12-31   0.075426       0.154921          -0.207541    2415468000   \n",
       "2021-03-31    0.01578       0.278887          -0.266247     538541000   \n",
       "2021-06-30     0.0428       0.322163          -0.061572    1479095000   \n",
       "2021-09-30   0.096857       0.427647           0.149261    3442981000   \n",
       "2021-12-31   0.105049       0.404858           0.110363    5459329000   \n",
       "2022-03-31   0.036966       0.363175           0.099009    2332361000   \n",
       "2022-06-30   0.093802       0.404873           0.233026    6608701000   \n",
       "2022-09-30   0.159707       0.440019           0.261905   12533881000   \n",
       "2022-12-31   0.217089        0.42086           0.216016   18308307000   \n",
       "2023-03-31   0.057878       0.302783           0.100422    5059550000   \n",
       "2023-06-30   0.098832       0.362662           0.181849   11985064000   \n",
       "2023-09-30   0.176688       0.410375           0.247121   23817499000   \n",
       "2023-12-31   0.222397       0.385956            0.18884   34433068000   \n",
       "2024-03-31   0.064692       0.361055            0.17187   10763165000   \n",
       "2024-06-30   0.145719       0.384351           0.200054   25075467000   \n",
       "\n",
       "                      n             c              t        favök  \\\n",
       "2010-09-30   66682069.0  1331276755.0   4024606068.0   78519345.0   \n",
       "2010-12-31   98993553.0  1367891599.0   4179087055.0  102691163.0   \n",
       "2011-03-31  -31066472.0  1215548199.0   4360035822.0  -36097000.0   \n",
       "2011-06-30   -9998851.0  1387997432.0   4744524905.0  -13920000.0   \n",
       "2011-09-30   80135771.0  1616743346.0   5149439512.0   84651000.0   \n",
       "2011-12-31  122639000.0  1724774000.0   5086155000.0  120501000.0   \n",
       "2012-03-31   28071000.0  1401485000.0   4885763000.0   21660000.0   \n",
       "2012-06-30  112820000.0  1500835000.0   4749624000.0  108633000.0   \n",
       "2012-09-30  235442000.0  1978112000.0   5251165000.0  252845000.0   \n",
       "2012-12-31  297170000.0  1701346000.0   4980503000.0  304493000.0   \n",
       "2013-03-31     37473000    1369005000     4900066000     30670000   \n",
       "2013-06-30    126329000    1509778000     5382141000    121532000   \n",
       "2013-09-30  279462000.0  2108330000.0   6332951000.0  288362000.0   \n",
       "2013-12-31  336088000.0  2291645000.0   6948741000.0  335492000.0   \n",
       "2014-03-31     61668000    1670534000     6560164000     49804000   \n",
       "2014-06-30    252550000    2240138000     6932095000    242468000   \n",
       "2014-09-30    509234000    1987511000     6980855000    513747000   \n",
       "2014-12-31    634228000    2562216000     7465541000    620614000   \n",
       "2015-03-31   84904000.0  2226892000.0   8205819000.0   73225000.0   \n",
       "2015-06-30  252819000.0  2352098000.0   8435154000.0  236120000.0   \n",
       "2015-09-30    498647000    3060669000     9855244000    482985000   \n",
       "2015-12-31    632912000    2921040000    10506371000    604732000   \n",
       "2016-03-31     47471000    2215148000     9962277000     39531000   \n",
       "2016-06-30    102728000    2373470000     9895743000     69962000   \n",
       "2016-09-30    359268000    2636521000    10482540000    338046000   \n",
       "2016-12-31    424341000    2941922000    11505470000    399379000   \n",
       "2017-03-31     46011000    2698693000    11700426000     38665000   \n",
       "2017-06-30    235868000    2993290000    11984801000    241924000   \n",
       "2017-09-30    652959000    3611697000    12935336000    701806000   \n",
       "2017-12-31  718234000.0  3733491000.0  13640645000.0  762673000.0   \n",
       "2018-03-31     33609000    3606381000    14201105000     26467000   \n",
       "2018-06-30    459981000    4291430000    17724568000    471397000   \n",
       "2018-09-30   1131334000    5609253000    23581223000   1187788000   \n",
       "2018-12-31   1454747000    5462462000    20804281000   1517324000   \n",
       "2019-03-31    145644000    5509450000    21202423000    139244000   \n",
       "2019-06-30    388778000    5579776000    22143460000    398157000   \n",
       "2019-09-30    949894000    6271887000    21998272000    979423000   \n",
       "2019-12-31   2368497000    7169674000    25556843000   2415416000   \n",
       "2020-03-31   -376696000    9536913000    27733129000   -366407000   \n",
       "2020-06-30  -1070796000    8846984000    28057419000  -1066176000   \n",
       "2020-09-30  -1515678000   11184890000    33634895000  -1512602000   \n",
       "2020-12-31  -2283284000    9770948000    32024208000  -2283316000   \n",
       "2021-03-31    552858000    9740644000    34128244000    547923000   \n",
       "2021-06-30    220527000    5458568000    34558660000    228400000   \n",
       "2021-09-30    852863000    6337804000    35547215000    887009000   \n",
       "2021-12-31    467689000    6747366000    51969566000    522412000   \n",
       "2022-03-31   -335732000    8984952000    63094629000   -314686000   \n",
       "2022-06-30    294734000   10971945000    70453570000    347530000   \n",
       "2022-09-30   1869175000   14322765000    78480272000   1984030000   \n",
       "2022-12-31   1899087000   14985806000    84335435000   2046662000   \n",
       "2023-03-31   -919035000   16195644000    87416771000   -888333000   \n",
       "2023-06-30    -31638000   21516364000   121267603000     51153000   \n",
       "2023-09-30   5370141000   29706699000   134799506000   5555784000   \n",
       "2023-12-31   7530074000   33605578000   154826945000   7777419000   \n",
       "2024-03-31    298268000   32727740000   166376256000    363801000   \n",
       "2024-06-30   2805790000   34672407000   172081539000   3002142000   \n",
       "\n",
       "                özkaynak       brütkar  faaliyetkarı       Fiyat      Return  \n",
       "2010-09-30  1009639635.0   355012154.0   207260126.0    6.950000    2.541967  \n",
       "2010-12-31  1107303831.0   440006424.0   240124457.0    7.400000    9.549549  \n",
       "2011-03-31  1159361913.0    82335000.0    28568000.0    7.126667    5.332088  \n",
       "2011-06-30  1234204036.0   242655000.0   127519000.0    8.106667    0.411186  \n",
       "2011-09-30  1360671737.0   470279000.0   291448000.0    7.506667   14.831257  \n",
       "2011-12-31  1374450000.0   625972000.0   368684000.0    8.140000   14.578216  \n",
       "2012-03-31  1330500000.0   100548000.0    53384000.0    8.620000    9.048725  \n",
       "2012-06-30  1294835000.0   277087000.0   170812000.0    9.326667   -3.859903  \n",
       "2012-09-30  1413739000.0   529909000.0   364468000.0    9.400000   21.985815  \n",
       "2012-12-31  1265355000.0   709076000.0   484302000.0    8.966667   33.085504  \n",
       "2013-03-31    1310683000     117606000      58289000   11.466667    8.866280  \n",
       "2013-06-30    1400873000     341619000     222235000   11.933333   25.698323  \n",
       "2013-09-30  1688695000.0   648154000.0   467588000.0   12.483333   32.843797  \n",
       "2013-12-31  1839033000.0   860250000.0   621253000.0   15.000000   12.111113  \n",
       "2014-03-31    1703755000     173133000     100816000   16.583334    8.341704  \n",
       "2014-06-30    1788647000     450303000     345861000   16.816667   12.487610  \n",
       "2014-09-30    2066872000     826574000     672996000   17.966667   11.224488  \n",
       "2014-12-31    2103403000    1097767000     863119000   18.916667   20.440529  \n",
       "2015-03-31  2198707000.0   199828000.0   137289000.0   19.983333   14.011679  \n",
       "2015-06-30  2181718000.0   581999000.0   464212000.0   22.783333   -9.100218  \n",
       "2015-09-30    2729587000    1069447000     916751000   22.783333  -24.272129  \n",
       "2015-12-31    2584800000    1358180000    1244787000   20.710000  -29.534848  \n",
       "2016-03-31    2268748000     239890000     186742000   17.253333  -32.670017  \n",
       "2016-06-30    2293314000     592042000     486449000   14.593333   -9.365006  \n",
       "2016-09-30    2662549000    1041190000     873692000   11.616666   29.670015  \n",
       "2016-12-31    2994224000    1656555000    1172260000   13.226667   28.427423  \n",
       "2017-03-31    2966506000     331973000     230734000   15.063333   33.193183  \n",
       "2017-06-30    3221619000     849800000     643606000   16.986667   19.407375  \n",
       "2017-09-30    3783879000    1610106000    1275443000   20.063333   14.636986  \n",
       "2017-12-31  4015560000.0  2059658000.0  1559893000.0   20.283333    8.069022  \n",
       "2018-03-31    3985337000     226090000     104818000   23.000000   34.811595  \n",
       "2018-06-30    4838997000     707709000     356854000   21.920000    6.599757  \n",
       "2018-09-30    6963245000    1492213000     756413000   31.006667  -14.491507  \n",
       "2018-12-31    6219550000    1957847000     912370000   23.366667   10.356631  \n",
       "2019-03-31    5857735000     391587000      89002000   26.513334   -9.001760  \n",
       "2019-06-30    6146334000     977642000     564329000   25.786666    6.256466  \n",
       "2019-09-30    6566059000    1825983000    1161715000   24.126667  -11.094226  \n",
       "2019-12-31    8709369000    2246191000    1307662000   27.400000  -29.501216  \n",
       "2020-03-31    8465546000     265092000      15407000   21.450000  -26.386947  \n",
       "2020-06-30    8309013000     252390000    -176672000   19.316667   -6.678172  \n",
       "2020-09-30    9251721000     480831000    -109802000   15.790000   41.144186  \n",
       "2020-12-31    8419698000     374206000    -501308000   18.026667   27.995561  \n",
       "2021-03-31   10019470000     150192000    -143385000   22.286667    8.226144  \n",
       "2021-06-30   10382597000     476509000     -91071000   23.073333   24.443805  \n",
       "2021-09-30   11108509000    1472380000     513902000   24.120000   53.565508  \n",
       "2021-12-31   15247512000    2210255000     602509000   28.713334   60.668674  \n",
       "2022-03-31   16518472000     847055000     230925000   37.040001   63.606907  \n",
       "2022-06-30   19261186000    2675684000    1539999000   46.133333   87.608386  \n",
       "2022-09-30   22975476000    5515143000    3282683000   60.600000   27.337734  \n",
       "2022-12-31   23564987000    7705233000    3954880000   86.550001   -7.009438  \n",
       "2023-03-31   23545163000    1531948000     508088000   77.166667   55.637150  \n",
       "2023-06-30   32256292000    4346523000    2179473000   80.483332   40.028993  \n",
       "2023-09-30   39367235000    9774110000    5885809000  120.100001   37.635305  \n",
       "2023-12-31   46464702000   13289634000    6502355000  112.699999  112.984322  \n",
       "2024-03-31   50727786000    3886092000    1849862000  165.300003   53.856620  \n",
       "2024-06-30   53706956000    9637786000    5016455000  240.033330    0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasyo=pd.concat([current_ratio,debt_to_equity_ratio,return_on_equity,net_profit_margin,roe,asset_turnover,brütkarmarjı,faaliyetkarmarj,satışlar,netkar,current_assets,total_assets,net_profit_after_taxes,özkaynaklar,brütkar,faaliyetkarı],axis=1)\n",
    "rasyo.columns=[\"Cari Oran\",\"Borçluluk Oranı\",\"Return On Equity\",\"Net Kar Marjı\",\"ROE\",\"Devir Hızı\",\"Brüt Kar Marjı\",\"Faaliyet Kar Marjı\",\"s\",\"n\",\"c\",\"t\",\"favök\",\"özkaynak\",\"brütkar\",\"faaliyetkarı\"]\n",
    "rasyo[\"Fiyat\"]=hisse[\"Close\"].values[:-1]\n",
    "rasyo[\"Return\"]=hisse[\"Return\"].values[:-1]\n",
    "rasyo=rasyo.set_index(pd.date_range(start=\"2010-03-31\",freq=\"Q\",periods=len(rasyo)))\n",
    "rasyo=rasyo.iloc[2:,:]\n",
    "rasyo[\"Return\"]=rasyo[\"Return\"].fillna(0)\n",
    "rasyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasyo=rasyo.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cari Oran</th>\n",
       "      <th>Borçluluk Oranı</th>\n",
       "      <th>Return On Equity</th>\n",
       "      <th>Net Kar Marjı</th>\n",
       "      <th>ROE</th>\n",
       "      <th>Devir Hızı</th>\n",
       "      <th>Brüt Kar Marjı</th>\n",
       "      <th>Faaliyet Kar Marjı</th>\n",
       "      <th>s</th>\n",
       "      <th>n</th>\n",
       "      <th>c</th>\n",
       "      <th>t</th>\n",
       "      <th>favök</th>\n",
       "      <th>özkaynak</th>\n",
       "      <th>brütkar</th>\n",
       "      <th>faaliyetkarı</th>\n",
       "      <th>Fiyat</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069087</td>\n",
       "      <td>1.174497</td>\n",
       "      <td>-0.010878</td>\n",
       "      <td>-0.032442</td>\n",
       "      <td>-0.117855</td>\n",
       "      <td>0.982258</td>\n",
       "      <td>-0.622929</td>\n",
       "      <td>-0.044544</td>\n",
       "      <td>-0.483007</td>\n",
       "      <td>-0.333876</td>\n",
       "      <td>-0.684847</td>\n",
       "      <td>-0.663463</td>\n",
       "      <td>-0.332235</td>\n",
       "      <td>-0.651988</td>\n",
       "      <td>-0.510240</td>\n",
       "      <td>-0.502738</td>\n",
       "      <td>-0.618247</td>\n",
       "      <td>2.541967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105389</td>\n",
       "      <td>0.431112</td>\n",
       "      <td>0.130878</td>\n",
       "      <td>-0.042141</td>\n",
       "      <td>0.105474</td>\n",
       "      <td>1.790711</td>\n",
       "      <td>-1.012226</td>\n",
       "      <td>-0.249182</td>\n",
       "      <td>-0.422021</td>\n",
       "      <td>-0.310748</td>\n",
       "      <td>-0.680445</td>\n",
       "      <td>-0.659832</td>\n",
       "      <td>-0.315477</td>\n",
       "      <td>-0.644282</td>\n",
       "      <td>-0.477761</td>\n",
       "      <td>-0.479366</td>\n",
       "      <td>-0.607358</td>\n",
       "      <td>9.549549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.066531</td>\n",
       "      <td>0.355150</td>\n",
       "      <td>-1.042124</td>\n",
       "      <td>-0.566189</td>\n",
       "      <td>-1.005633</td>\n",
       "      <td>-0.752288</td>\n",
       "      <td>-2.067583</td>\n",
       "      <td>-0.868012</td>\n",
       "      <td>-0.591239</td>\n",
       "      <td>-0.403844</td>\n",
       "      <td>-0.698761</td>\n",
       "      <td>-0.655578</td>\n",
       "      <td>-0.411695</td>\n",
       "      <td>-0.640174</td>\n",
       "      <td>-0.614437</td>\n",
       "      <td>-0.629818</td>\n",
       "      <td>-0.613972</td>\n",
       "      <td>5.332088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.147505</td>\n",
       "      <td>0.629805</td>\n",
       "      <td>-0.854096</td>\n",
       "      <td>-0.312907</td>\n",
       "      <td>-0.826869</td>\n",
       "      <td>0.240732</td>\n",
       "      <td>-1.405891</td>\n",
       "      <td>-0.405046</td>\n",
       "      <td>-0.509948</td>\n",
       "      <td>-0.388764</td>\n",
       "      <td>-0.678028</td>\n",
       "      <td>-0.646541</td>\n",
       "      <td>-0.396320</td>\n",
       "      <td>-0.634268</td>\n",
       "      <td>-0.553174</td>\n",
       "      <td>-0.559447</td>\n",
       "      <td>-0.590259</td>\n",
       "      <td>0.411186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.185021</td>\n",
       "      <td>0.585940</td>\n",
       "      <td>-0.158191</td>\n",
       "      <td>-0.085558</td>\n",
       "      <td>-0.186236</td>\n",
       "      <td>1.222420</td>\n",
       "      <td>-0.847805</td>\n",
       "      <td>-0.037637</td>\n",
       "      <td>-0.416335</td>\n",
       "      <td>-0.324246</td>\n",
       "      <td>-0.650527</td>\n",
       "      <td>-0.637023</td>\n",
       "      <td>-0.327984</td>\n",
       "      <td>-0.624288</td>\n",
       "      <td>-0.466193</td>\n",
       "      <td>-0.442866</td>\n",
       "      <td>-0.604777</td>\n",
       "      <td>14.831257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.155014</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>0.082891</td>\n",
       "      <td>-0.072190</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>2.180014</td>\n",
       "      <td>-0.827272</td>\n",
       "      <td>-0.098500</td>\n",
       "      <td>-0.340537</td>\n",
       "      <td>-0.293822</td>\n",
       "      <td>-0.637539</td>\n",
       "      <td>-0.638511</td>\n",
       "      <td>-0.303130</td>\n",
       "      <td>-0.623201</td>\n",
       "      <td>-0.406698</td>\n",
       "      <td>-0.387938</td>\n",
       "      <td>-0.589453</td>\n",
       "      <td>14.578216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.383587</td>\n",
       "      <td>0.307128</td>\n",
       "      <td>-0.593142</td>\n",
       "      <td>-0.062513</td>\n",
       "      <td>-0.547654</td>\n",
       "      <td>-0.916623</td>\n",
       "      <td>-1.074063</td>\n",
       "      <td>-0.298308</td>\n",
       "      <td>-0.597113</td>\n",
       "      <td>-0.361514</td>\n",
       "      <td>-0.676407</td>\n",
       "      <td>-0.643221</td>\n",
       "      <td>-0.371654</td>\n",
       "      <td>-0.626669</td>\n",
       "      <td>-0.607477</td>\n",
       "      <td>-0.612170</td>\n",
       "      <td>-0.577839</td>\n",
       "      <td>9.048725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.239881</td>\n",
       "      <td>0.323656</td>\n",
       "      <td>0.047145</td>\n",
       "      <td>0.177072</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>-0.307144</td>\n",
       "      <td>0.137751</td>\n",
       "      <td>-0.528737</td>\n",
       "      <td>-0.300851</td>\n",
       "      <td>-0.664462</td>\n",
       "      <td>-0.646421</td>\n",
       "      <td>-0.311358</td>\n",
       "      <td>-0.629483</td>\n",
       "      <td>-0.540017</td>\n",
       "      <td>-0.528658</td>\n",
       "      <td>-0.560740</td>\n",
       "      <td>-3.859903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.355571</td>\n",
       "      <td>0.437331</td>\n",
       "      <td>0.946260</td>\n",
       "      <td>0.354349</td>\n",
       "      <td>0.843090</td>\n",
       "      <td>0.787281</td>\n",
       "      <td>0.383560</td>\n",
       "      <td>0.575661</td>\n",
       "      <td>-0.448626</td>\n",
       "      <td>-0.213079</td>\n",
       "      <td>-0.607081</td>\n",
       "      <td>-0.634632</td>\n",
       "      <td>-0.211379</td>\n",
       "      <td>-0.620101</td>\n",
       "      <td>-0.443407</td>\n",
       "      <td>-0.390936</td>\n",
       "      <td>-0.558965</td>\n",
       "      <td>21.985815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.467835</td>\n",
       "      <td>1.228967</td>\n",
       "      <td>1.531364</td>\n",
       "      <td>0.265873</td>\n",
       "      <td>1.496315</td>\n",
       "      <td>1.931444</td>\n",
       "      <td>0.132945</td>\n",
       "      <td>0.468152</td>\n",
       "      <td>-0.366964</td>\n",
       "      <td>-0.168894</td>\n",
       "      <td>-0.640355</td>\n",
       "      <td>-0.640994</td>\n",
       "      <td>-0.175573</td>\n",
       "      <td>-0.631810</td>\n",
       "      <td>-0.374942</td>\n",
       "      <td>-0.305714</td>\n",
       "      <td>-0.569450</td>\n",
       "      <td>33.085504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.703771</td>\n",
       "      <td>1.332162</td>\n",
       "      <td>-0.525717</td>\n",
       "      <td>-0.070986</td>\n",
       "      <td>-0.476010</td>\n",
       "      <td>-0.598604</td>\n",
       "      <td>-1.862815</td>\n",
       "      <td>-0.585549</td>\n",
       "      <td>-0.571787</td>\n",
       "      <td>-0.354784</td>\n",
       "      <td>-0.680312</td>\n",
       "      <td>-0.642885</td>\n",
       "      <td>-0.365407</td>\n",
       "      <td>-0.628233</td>\n",
       "      <td>-0.600959</td>\n",
       "      <td>-0.608682</td>\n",
       "      <td>-0.508959</td>\n",
       "      <td>8.866280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.672486</td>\n",
       "      <td>1.081707</td>\n",
       "      <td>0.074201</td>\n",
       "      <td>0.068129</td>\n",
       "      <td>0.112915</td>\n",
       "      <td>0.485967</td>\n",
       "      <td>-1.080819</td>\n",
       "      <td>-0.053091</td>\n",
       "      <td>-0.469796</td>\n",
       "      <td>-0.291181</td>\n",
       "      <td>-0.663387</td>\n",
       "      <td>-0.631553</td>\n",
       "      <td>-0.302415</td>\n",
       "      <td>-0.621116</td>\n",
       "      <td>-0.515358</td>\n",
       "      <td>-0.492088</td>\n",
       "      <td>-0.497667</td>\n",
       "      <td>25.698323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.455706</td>\n",
       "      <td>0.843206</td>\n",
       "      <td>0.869671</td>\n",
       "      <td>0.217388</td>\n",
       "      <td>0.833063</td>\n",
       "      <td>1.297271</td>\n",
       "      <td>-0.480924</td>\n",
       "      <td>0.330473</td>\n",
       "      <td>-0.354956</td>\n",
       "      <td>-0.181569</td>\n",
       "      <td>-0.591425</td>\n",
       "      <td>-0.609204</td>\n",
       "      <td>-0.186756</td>\n",
       "      <td>-0.598404</td>\n",
       "      <td>-0.398222</td>\n",
       "      <td>-0.317600</td>\n",
       "      <td>-0.484359</td>\n",
       "      <td>32.843797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.874264</td>\n",
       "      <td>0.850279</td>\n",
       "      <td>0.980161</td>\n",
       "      <td>0.155290</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>1.924445</td>\n",
       "      <td>-0.508842</td>\n",
       "      <td>0.321255</td>\n",
       "      <td>-0.255866</td>\n",
       "      <td>-0.141037</td>\n",
       "      <td>-0.569386</td>\n",
       "      <td>-0.594729</td>\n",
       "      <td>-0.154082</td>\n",
       "      <td>-0.586540</td>\n",
       "      <td>-0.317174</td>\n",
       "      <td>-0.208318</td>\n",
       "      <td>-0.423465</td>\n",
       "      <td>12.111113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.141079</td>\n",
       "      <td>0.634266</td>\n",
       "      <td>-0.470493</td>\n",
       "      <td>0.011420</td>\n",
       "      <td>-0.403290</td>\n",
       "      <td>-0.746997</td>\n",
       "      <td>-0.984544</td>\n",
       "      <td>-0.163390</td>\n",
       "      <td>-0.560986</td>\n",
       "      <td>-0.337465</td>\n",
       "      <td>-0.644060</td>\n",
       "      <td>-0.603863</td>\n",
       "      <td>-0.352142</td>\n",
       "      <td>-0.597215</td>\n",
       "      <td>-0.579741</td>\n",
       "      <td>-0.578438</td>\n",
       "      <td>-0.385154</td>\n",
       "      <td>8.341704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.286211</td>\n",
       "      <td>0.698238</td>\n",
       "      <td>0.536347</td>\n",
       "      <td>0.351923</td>\n",
       "      <td>0.600758</td>\n",
       "      <td>0.144317</td>\n",
       "      <td>-0.230919</td>\n",
       "      <td>0.547399</td>\n",
       "      <td>-0.456133</td>\n",
       "      <td>-0.200833</td>\n",
       "      <td>-0.575578</td>\n",
       "      <td>-0.595121</td>\n",
       "      <td>-0.218573</td>\n",
       "      <td>-0.590516</td>\n",
       "      <td>-0.473826</td>\n",
       "      <td>-0.404169</td>\n",
       "      <td>-0.379508</td>\n",
       "      <td>12.487610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.867484</td>\n",
       "      <td>-0.630349</td>\n",
       "      <td>1.606399</td>\n",
       "      <td>0.559034</td>\n",
       "      <td>1.606549</td>\n",
       "      <td>1.139491</td>\n",
       "      <td>0.497833</td>\n",
       "      <td>0.989271</td>\n",
       "      <td>-0.342554</td>\n",
       "      <td>-0.017100</td>\n",
       "      <td>-0.605951</td>\n",
       "      <td>-0.593975</td>\n",
       "      <td>-0.030502</td>\n",
       "      <td>-0.568561</td>\n",
       "      <td>-0.330043</td>\n",
       "      <td>-0.171520</td>\n",
       "      <td>-0.351682</td>\n",
       "      <td>11.224488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.440247</td>\n",
       "      <td>-0.227927</td>\n",
       "      <td>2.046622</td>\n",
       "      <td>0.496045</td>\n",
       "      <td>2.133867</td>\n",
       "      <td>1.748238</td>\n",
       "      <td>0.579480</td>\n",
       "      <td>0.942505</td>\n",
       "      <td>-0.247795</td>\n",
       "      <td>0.072370</td>\n",
       "      <td>-0.536856</td>\n",
       "      <td>-0.582582</td>\n",
       "      <td>0.043586</td>\n",
       "      <td>-0.565679</td>\n",
       "      <td>-0.226413</td>\n",
       "      <td>-0.036310</td>\n",
       "      <td>-0.328695</td>\n",
       "      <td>20.440529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.409998</td>\n",
       "      <td>0.456305</td>\n",
       "      <td>-0.431937</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>-0.380148</td>\n",
       "      <td>-0.935708</td>\n",
       "      <td>-0.250439</td>\n",
       "      <td>0.334872</td>\n",
       "      <td>-0.563649</td>\n",
       "      <td>-0.320833</td>\n",
       "      <td>-0.577171</td>\n",
       "      <td>-0.565181</td>\n",
       "      <td>-0.335905</td>\n",
       "      <td>-0.558158</td>\n",
       "      <td>-0.569540</td>\n",
       "      <td>-0.552499</td>\n",
       "      <td>-0.302886</td>\n",
       "      <td>14.011679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.448072</td>\n",
       "      <td>0.708849</td>\n",
       "      <td>0.277526</td>\n",
       "      <td>0.309352</td>\n",
       "      <td>0.358685</td>\n",
       "      <td>-0.098667</td>\n",
       "      <td>0.857545</td>\n",
       "      <td>1.097833</td>\n",
       "      <td>-0.447187</td>\n",
       "      <td>-0.200640</td>\n",
       "      <td>-0.562118</td>\n",
       "      <td>-0.559790</td>\n",
       "      <td>-0.222974</td>\n",
       "      <td>-0.559499</td>\n",
       "      <td>-0.423502</td>\n",
       "      <td>-0.320001</td>\n",
       "      <td>-0.235135</td>\n",
       "      <td>-9.100218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.579960</td>\n",
       "      <td>0.733622</td>\n",
       "      <td>0.928230</td>\n",
       "      <td>0.432924</td>\n",
       "      <td>0.997461</td>\n",
       "      <td>0.557027</td>\n",
       "      <td>1.382685</td>\n",
       "      <td>1.530906</td>\n",
       "      <td>-0.308650</td>\n",
       "      <td>-0.024678</td>\n",
       "      <td>-0.476928</td>\n",
       "      <td>-0.526410</td>\n",
       "      <td>-0.051829</td>\n",
       "      <td>-0.516266</td>\n",
       "      <td>-0.237235</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>-0.235135</td>\n",
       "      <td>-24.272129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.464105</td>\n",
       "      <td>1.518412</td>\n",
       "      <td>1.468096</td>\n",
       "      <td>0.384060</td>\n",
       "      <td>1.592015</td>\n",
       "      <td>1.121195</td>\n",
       "      <td>1.028380</td>\n",
       "      <td>1.555570</td>\n",
       "      <td>-0.190350</td>\n",
       "      <td>0.071428</td>\n",
       "      <td>-0.493716</td>\n",
       "      <td>-0.511105</td>\n",
       "      <td>0.032575</td>\n",
       "      <td>-0.527691</td>\n",
       "      <td>-0.126902</td>\n",
       "      <td>0.235121</td>\n",
       "      <td>-0.285303</td>\n",
       "      <td>-29.534848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.044202</td>\n",
       "      <td>2.085222</td>\n",
       "      <td>-0.582304</td>\n",
       "      <td>-0.076755</td>\n",
       "      <td>-0.549320</td>\n",
       "      <td>-0.941356</td>\n",
       "      <td>-0.262115</td>\n",
       "      <td>0.560395</td>\n",
       "      <td>-0.546057</td>\n",
       "      <td>-0.347627</td>\n",
       "      <td>-0.578583</td>\n",
       "      <td>-0.523895</td>\n",
       "      <td>-0.359264</td>\n",
       "      <td>-0.552631</td>\n",
       "      <td>-0.554231</td>\n",
       "      <td>-0.517330</td>\n",
       "      <td>-0.368942</td>\n",
       "      <td>-32.670017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.979796</td>\n",
       "      <td>2.011107</td>\n",
       "      <td>-0.458420</td>\n",
       "      <td>-0.113394</td>\n",
       "      <td>-0.321062</td>\n",
       "      <td>-0.155775</td>\n",
       "      <td>0.296108</td>\n",
       "      <td>0.920304</td>\n",
       "      <td>-0.421183</td>\n",
       "      <td>-0.308075</td>\n",
       "      <td>-0.559548</td>\n",
       "      <td>-0.525458</td>\n",
       "      <td>-0.338167</td>\n",
       "      <td>-0.550693</td>\n",
       "      <td>-0.419664</td>\n",
       "      <td>-0.304187</td>\n",
       "      <td>-0.433305</td>\n",
       "      <td>-9.365006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.735353</td>\n",
       "      <td>1.098126</td>\n",
       "      <td>0.454948</td>\n",
       "      <td>0.182006</td>\n",
       "      <td>0.540877</td>\n",
       "      <td>0.617615</td>\n",
       "      <td>0.697782</td>\n",
       "      <td>1.154263</td>\n",
       "      <td>-0.276659</td>\n",
       "      <td>-0.124445</td>\n",
       "      <td>-0.527922</td>\n",
       "      <td>-0.511665</td>\n",
       "      <td>-0.152311</td>\n",
       "      <td>-0.521556</td>\n",
       "      <td>-0.248032</td>\n",
       "      <td>-0.028791</td>\n",
       "      <td>-0.505330</td>\n",
       "      <td>29.670015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.823902</td>\n",
       "      <td>0.878277</td>\n",
       "      <td>0.515739</td>\n",
       "      <td>0.083996</td>\n",
       "      <td>0.605767</td>\n",
       "      <td>1.454741</td>\n",
       "      <td>0.979404</td>\n",
       "      <td>0.863608</td>\n",
       "      <td>-0.084645</td>\n",
       "      <td>-0.077866</td>\n",
       "      <td>-0.491205</td>\n",
       "      <td>-0.487621</td>\n",
       "      <td>-0.109791</td>\n",
       "      <td>-0.495383</td>\n",
       "      <td>-0.012885</td>\n",
       "      <td>0.183542</td>\n",
       "      <td>-0.466373</td>\n",
       "      <td>28.427423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.043115</td>\n",
       "      <td>0.865801</td>\n",
       "      <td>-0.623877</td>\n",
       "      <td>-0.124644</td>\n",
       "      <td>-0.601088</td>\n",
       "      <td>-0.864401</td>\n",
       "      <td>-0.019083</td>\n",
       "      <td>0.443139</td>\n",
       "      <td>-0.513364</td>\n",
       "      <td>-0.348672</td>\n",
       "      <td>-0.520448</td>\n",
       "      <td>-0.483038</td>\n",
       "      <td>-0.359865</td>\n",
       "      <td>-0.497571</td>\n",
       "      <td>-0.519044</td>\n",
       "      <td>-0.486044</td>\n",
       "      <td>-0.421932</td>\n",
       "      <td>33.193183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.098254</td>\n",
       "      <td>0.425779</td>\n",
       "      <td>-0.036215</td>\n",
       "      <td>0.118870</td>\n",
       "      <td>-0.049305</td>\n",
       "      <td>0.020339</td>\n",
       "      <td>0.581286</td>\n",
       "      <td>0.857278</td>\n",
       "      <td>-0.338768</td>\n",
       "      <td>-0.212774</td>\n",
       "      <td>-0.485029</td>\n",
       "      <td>-0.476354</td>\n",
       "      <td>-0.218950</td>\n",
       "      <td>-0.477440</td>\n",
       "      <td>-0.321168</td>\n",
       "      <td>-0.192421</td>\n",
       "      <td>-0.375394</td>\n",
       "      <td>19.407375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.766456</td>\n",
       "      <td>-0.277155</td>\n",
       "      <td>1.008986</td>\n",
       "      <td>0.393954</td>\n",
       "      <td>0.900701</td>\n",
       "      <td>0.927308</td>\n",
       "      <td>1.246637</td>\n",
       "      <td>1.249572</td>\n",
       "      <td>-0.124576</td>\n",
       "      <td>0.085778</td>\n",
       "      <td>-0.410680</td>\n",
       "      <td>-0.454011</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>-0.433071</td>\n",
       "      <td>-0.030634</td>\n",
       "      <td>0.256922</td>\n",
       "      <td>-0.300950</td>\n",
       "      <td>14.636986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.778378</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>1.051189</td>\n",
       "      <td>0.263820</td>\n",
       "      <td>0.960937</td>\n",
       "      <td>1.643185</td>\n",
       "      <td>0.906800</td>\n",
       "      <td>0.992310</td>\n",
       "      <td>0.061808</td>\n",
       "      <td>0.132501</td>\n",
       "      <td>-0.396037</td>\n",
       "      <td>-0.437432</td>\n",
       "      <td>0.142072</td>\n",
       "      <td>-0.414789</td>\n",
       "      <td>0.141152</td>\n",
       "      <td>0.459215</td>\n",
       "      <td>-0.295627</td>\n",
       "      <td>8.069022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1.022273</td>\n",
       "      <td>0.163693</td>\n",
       "      <td>-0.684411</td>\n",
       "      <td>-0.125355</td>\n",
       "      <td>-0.668760</td>\n",
       "      <td>-1.177723</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>-0.182207</td>\n",
       "      <td>-0.556015</td>\n",
       "      <td>-0.357550</td>\n",
       "      <td>-0.411319</td>\n",
       "      <td>-0.424258</td>\n",
       "      <td>-0.368321</td>\n",
       "      <td>-0.417174</td>\n",
       "      <td>-0.559504</td>\n",
       "      <td>-0.575591</td>\n",
       "      <td>-0.229893</td>\n",
       "      <td>34.811595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.754760</td>\n",
       "      <td>0.180146</td>\n",
       "      <td>0.175160</td>\n",
       "      <td>0.725311</td>\n",
       "      <td>0.159563</td>\n",
       "      <td>-0.767856</td>\n",
       "      <td>1.148752</td>\n",
       "      <td>0.260431</td>\n",
       "      <td>-0.415332</td>\n",
       "      <td>-0.052355</td>\n",
       "      <td>-0.328958</td>\n",
       "      <td>-0.341437</td>\n",
       "      <td>-0.059862</td>\n",
       "      <td>-0.349811</td>\n",
       "      <td>-0.375465</td>\n",
       "      <td>-0.396351</td>\n",
       "      <td>-0.256025</td>\n",
       "      <td>6.599757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.661667</td>\n",
       "      <td>0.171324</td>\n",
       "      <td>0.867961</td>\n",
       "      <td>1.047022</td>\n",
       "      <td>0.804207</td>\n",
       "      <td>-0.415968</td>\n",
       "      <td>1.802572</td>\n",
       "      <td>0.450764</td>\n",
       "      <td>-0.203732</td>\n",
       "      <td>0.428196</td>\n",
       "      <td>-0.170521</td>\n",
       "      <td>-0.203773</td>\n",
       "      <td>0.436794</td>\n",
       "      <td>-0.182186</td>\n",
       "      <td>-0.075684</td>\n",
       "      <td>-0.112196</td>\n",
       "      <td>-0.036159</td>\n",
       "      <td>-14.491507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.282441</td>\n",
       "      <td>-0.977488</td>\n",
       "      <td>1.562821</td>\n",
       "      <td>0.973725</td>\n",
       "      <td>1.487211</td>\n",
       "      <td>0.209435</td>\n",
       "      <td>1.600670</td>\n",
       "      <td>0.250091</td>\n",
       "      <td>-0.046132</td>\n",
       "      <td>0.659693</td>\n",
       "      <td>-0.188169</td>\n",
       "      <td>-0.269047</td>\n",
       "      <td>0.665253</td>\n",
       "      <td>-0.240871</td>\n",
       "      <td>0.102247</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>-0.221021</td>\n",
       "      <td>10.356631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.413631</td>\n",
       "      <td>-0.067712</td>\n",
       "      <td>-0.522204</td>\n",
       "      <td>0.227065</td>\n",
       "      <td>-0.511648</td>\n",
       "      <td>-1.179884</td>\n",
       "      <td>0.727233</td>\n",
       "      <td>-0.702688</td>\n",
       "      <td>-0.510380</td>\n",
       "      <td>-0.277356</td>\n",
       "      <td>-0.182520</td>\n",
       "      <td>-0.259689</td>\n",
       "      <td>-0.290136</td>\n",
       "      <td>-0.269422</td>\n",
       "      <td>-0.496263</td>\n",
       "      <td>-0.586839</td>\n",
       "      <td>-0.144882</td>\n",
       "      <td>-9.001760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.364008</td>\n",
       "      <td>-0.194536</td>\n",
       "      <td>-0.133884</td>\n",
       "      <td>0.335360</td>\n",
       "      <td>-0.144550</td>\n",
       "      <td>-0.672770</td>\n",
       "      <td>1.093782</td>\n",
       "      <td>0.483065</td>\n",
       "      <td>-0.322798</td>\n",
       "      <td>-0.103322</td>\n",
       "      <td>-0.174065</td>\n",
       "      <td>-0.237569</td>\n",
       "      <td>-0.110638</td>\n",
       "      <td>-0.246649</td>\n",
       "      <td>-0.272316</td>\n",
       "      <td>-0.248801</td>\n",
       "      <td>-0.162465</td>\n",
       "      <td>6.256466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002045</td>\n",
       "      <td>-0.778535</td>\n",
       "      <td>0.665176</td>\n",
       "      <td>0.595657</td>\n",
       "      <td>0.633951</td>\n",
       "      <td>-0.008137</td>\n",
       "      <td>1.623335</td>\n",
       "      <td>0.859776</td>\n",
       "      <td>-0.088780</td>\n",
       "      <td>0.298322</td>\n",
       "      <td>-0.090854</td>\n",
       "      <td>-0.240982</td>\n",
       "      <td>0.292339</td>\n",
       "      <td>-0.213528</td>\n",
       "      <td>0.051859</td>\n",
       "      <td>0.176042</td>\n",
       "      <td>-0.202631</td>\n",
       "      <td>-11.094226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.059861</td>\n",
       "      <td>-2.051848</td>\n",
       "      <td>1.878856</td>\n",
       "      <td>1.382895</td>\n",
       "      <td>1.851048</td>\n",
       "      <td>0.162528</td>\n",
       "      <td>1.335771</td>\n",
       "      <td>0.576314</td>\n",
       "      <td>0.072471</td>\n",
       "      <td>1.313750</td>\n",
       "      <td>0.017084</td>\n",
       "      <td>-0.157335</td>\n",
       "      <td>1.287877</td>\n",
       "      <td>-0.044398</td>\n",
       "      <td>0.212432</td>\n",
       "      <td>0.279836</td>\n",
       "      <td>-0.123428</td>\n",
       "      <td>-29.501216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.213823</td>\n",
       "      <td>-1.200235</td>\n",
       "      <td>-1.157146</td>\n",
       "      <td>-1.756297</td>\n",
       "      <td>-1.174899</td>\n",
       "      <td>-1.317782</td>\n",
       "      <td>-0.490092</td>\n",
       "      <td>-1.258609</td>\n",
       "      <td>-0.529122</td>\n",
       "      <td>-0.651244</td>\n",
       "      <td>0.301689</td>\n",
       "      <td>-0.106181</td>\n",
       "      <td>-0.640691</td>\n",
       "      <td>-0.063638</td>\n",
       "      <td>-0.544601</td>\n",
       "      <td>-0.639178</td>\n",
       "      <td>-0.267397</td>\n",
       "      <td>-26.386947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.028675</td>\n",
       "      <td>-0.976767</td>\n",
       "      <td>-1.962347</td>\n",
       "      <td>-3.680508</td>\n",
       "      <td>-1.981709</td>\n",
       "      <td>-1.248575</td>\n",
       "      <td>-1.584904</td>\n",
       "      <td>-2.650892</td>\n",
       "      <td>-0.496344</td>\n",
       "      <td>-1.148076</td>\n",
       "      <td>0.218741</td>\n",
       "      <td>-0.098558</td>\n",
       "      <td>-1.125823</td>\n",
       "      <td>-0.075990</td>\n",
       "      <td>-0.549454</td>\n",
       "      <td>-0.775779</td>\n",
       "      <td>-0.319017</td>\n",
       "      <td>-6.678172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.143139</td>\n",
       "      <td>-0.136583</td>\n",
       "      <td>-2.295461</td>\n",
       "      <td>-3.105016</td>\n",
       "      <td>-2.315958</td>\n",
       "      <td>-1.105020</td>\n",
       "      <td>-1.203636</td>\n",
       "      <td>-1.854109</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-1.466520</td>\n",
       "      <td>0.499820</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>-1.435319</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>-0.462161</td>\n",
       "      <td>-0.728223</td>\n",
       "      <td>-0.404350</td>\n",
       "      <td>41.144186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.839634</td>\n",
       "      <td>0.711098</td>\n",
       "      <td>-3.315233</td>\n",
       "      <td>-3.329400</td>\n",
       "      <td>-3.342537</td>\n",
       "      <td>-0.878404</td>\n",
       "      <td>-2.823133</td>\n",
       "      <td>-2.887514</td>\n",
       "      <td>-0.283128</td>\n",
       "      <td>-2.015968</td>\n",
       "      <td>0.329826</td>\n",
       "      <td>-0.005316</td>\n",
       "      <td>-1.969636</td>\n",
       "      <td>-0.067256</td>\n",
       "      <td>-0.502905</td>\n",
       "      <td>-1.006650</td>\n",
       "      <td>-0.350230</td>\n",
       "      <td>27.995561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.939888</td>\n",
       "      <td>-0.532150</td>\n",
       "      <td>-0.229464</td>\n",
       "      <td>3.035373</td>\n",
       "      <td>-0.221769</td>\n",
       "      <td>-1.439388</td>\n",
       "      <td>-1.198517</td>\n",
       "      <td>-3.308980</td>\n",
       "      <td>-0.568267</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>0.326183</td>\n",
       "      <td>0.044140</td>\n",
       "      <td>-0.006809</td>\n",
       "      <td>0.058983</td>\n",
       "      <td>-0.588507</td>\n",
       "      <td>-0.752106</td>\n",
       "      <td>-0.247153</td>\n",
       "      <td>8.226144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.321615</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>-0.538990</td>\n",
       "      <td>0.236787</td>\n",
       "      <td>-0.546297</td>\n",
       "      <td>-1.185264</td>\n",
       "      <td>-0.631375</td>\n",
       "      <td>-1.839571</td>\n",
       "      <td>-0.425380</td>\n",
       "      <td>-0.223755</td>\n",
       "      <td>-0.188637</td>\n",
       "      <td>0.054257</td>\n",
       "      <td>-0.228326</td>\n",
       "      <td>0.087638</td>\n",
       "      <td>-0.463812</td>\n",
       "      <td>-0.714902</td>\n",
       "      <td>-0.228118</td>\n",
       "      <td>24.443805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.864577</td>\n",
       "      <td>-1.502787</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.571479</td>\n",
       "      <td>-0.015249</td>\n",
       "      <td>-0.676849</td>\n",
       "      <td>0.751030</td>\n",
       "      <td>-0.325953</td>\n",
       "      <td>-0.127031</td>\n",
       "      <td>0.228868</td>\n",
       "      <td>-0.082929</td>\n",
       "      <td>0.077494</td>\n",
       "      <td>0.228271</td>\n",
       "      <td>0.144920</td>\n",
       "      <td>-0.083263</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.202793</td>\n",
       "      <td>53.565508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.680678</td>\n",
       "      <td>-1.211746</td>\n",
       "      <td>-0.422861</td>\n",
       "      <td>0.046343</td>\n",
       "      <td>-0.456095</td>\n",
       "      <td>-0.599802</td>\n",
       "      <td>0.452380</td>\n",
       "      <td>-0.605208</td>\n",
       "      <td>0.179288</td>\n",
       "      <td>-0.046838</td>\n",
       "      <td>-0.033689</td>\n",
       "      <td>0.463511</td>\n",
       "      <td>-0.024495</td>\n",
       "      <td>0.471531</td>\n",
       "      <td>0.198699</td>\n",
       "      <td>-0.221648</td>\n",
       "      <td>-0.091650</td>\n",
       "      <td>60.668674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.192710</td>\n",
       "      <td>-0.323883</td>\n",
       "      <td>-0.927691</td>\n",
       "      <td>-0.701501</td>\n",
       "      <td>-0.943750</td>\n",
       "      <td>-1.240128</td>\n",
       "      <td>-0.093895</td>\n",
       "      <td>-0.686721</td>\n",
       "      <td>-0.295754</td>\n",
       "      <td>-0.621922</td>\n",
       "      <td>0.235328</td>\n",
       "      <td>0.725012</td>\n",
       "      <td>-0.604834</td>\n",
       "      <td>0.571823</td>\n",
       "      <td>-0.322217</td>\n",
       "      <td>-0.485908</td>\n",
       "      <td>0.109826</td>\n",
       "      <td>63.606907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.694977</td>\n",
       "      <td>-0.679132</td>\n",
       "      <td>-0.576444</td>\n",
       "      <td>-0.093439</td>\n",
       "      <td>-0.603078</td>\n",
       "      <td>-0.705576</td>\n",
       "      <td>0.452570</td>\n",
       "      <td>0.275417</td>\n",
       "      <td>0.353898</td>\n",
       "      <td>-0.170638</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.897988</td>\n",
       "      <td>-0.145736</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>0.376553</td>\n",
       "      <td>0.445067</td>\n",
       "      <td>0.329853</td>\n",
       "      <td>87.608386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.396708</td>\n",
       "      <td>-1.331563</td>\n",
       "      <td>0.070411</td>\n",
       "      <td>0.249351</td>\n",
       "      <td>0.028542</td>\n",
       "      <td>-0.085727</td>\n",
       "      <td>0.913168</td>\n",
       "      <td>0.482744</td>\n",
       "      <td>1.254037</td>\n",
       "      <td>0.956338</td>\n",
       "      <td>0.877076</td>\n",
       "      <td>1.086660</td>\n",
       "      <td>0.988808</td>\n",
       "      <td>1.081350</td>\n",
       "      <td>1.461588</td>\n",
       "      <td>1.684412</td>\n",
       "      <td>0.679896</td>\n",
       "      <td>27.337734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.398259</td>\n",
       "      <td>-0.880877</td>\n",
       "      <td>0.075123</td>\n",
       "      <td>0.098544</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>0.453958</td>\n",
       "      <td>0.662085</td>\n",
       "      <td>0.153295</td>\n",
       "      <td>2.131274</td>\n",
       "      <td>0.977749</td>\n",
       "      <td>0.956791</td>\n",
       "      <td>1.224289</td>\n",
       "      <td>1.032229</td>\n",
       "      <td>1.127868</td>\n",
       "      <td>2.298481</td>\n",
       "      <td>2.162459</td>\n",
       "      <td>1.307795</td>\n",
       "      <td>-7.009438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.128349</td>\n",
       "      <td>-0.601983</td>\n",
       "      <td>-1.104561</td>\n",
       "      <td>-0.833335</td>\n",
       "      <td>-1.122644</td>\n",
       "      <td>-1.043444</td>\n",
       "      <td>-0.885344</td>\n",
       "      <td>-0.676581</td>\n",
       "      <td>0.118554</td>\n",
       "      <td>-1.039447</td>\n",
       "      <td>1.102246</td>\n",
       "      <td>1.296717</td>\n",
       "      <td>-1.002529</td>\n",
       "      <td>1.126304</td>\n",
       "      <td>-0.060500</td>\n",
       "      <td>-0.288798</td>\n",
       "      <td>1.080751</td>\n",
       "      <td>55.637150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.638532</td>\n",
       "      <td>-0.321603</td>\n",
       "      <td>-0.732281</td>\n",
       "      <td>-0.250129</td>\n",
       "      <td>-0.758779</td>\n",
       "      <td>-0.658274</td>\n",
       "      <td>-0.100622</td>\n",
       "      <td>-0.091994</td>\n",
       "      <td>1.170662</td>\n",
       "      <td>-0.404253</td>\n",
       "      <td>1.741938</td>\n",
       "      <td>2.092400</td>\n",
       "      <td>-0.351207</td>\n",
       "      <td>1.813705</td>\n",
       "      <td>1.015026</td>\n",
       "      <td>0.899842</td>\n",
       "      <td>1.161003</td>\n",
       "      <td>40.028993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.014714</td>\n",
       "      <td>-0.994398</td>\n",
       "      <td>0.589068</td>\n",
       "      <td>0.492472</td>\n",
       "      <td>0.555006</td>\n",
       "      <td>0.073982</td>\n",
       "      <td>0.524679</td>\n",
       "      <td>0.376610</td>\n",
       "      <td>2.968217</td>\n",
       "      <td>3.462310</td>\n",
       "      <td>2.726635</td>\n",
       "      <td>2.410475</td>\n",
       "      <td>3.465016</td>\n",
       "      <td>2.374833</td>\n",
       "      <td>3.089055</td>\n",
       "      <td>3.535678</td>\n",
       "      <td>2.119588</td>\n",
       "      <td>37.635305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.057500</td>\n",
       "      <td>-1.836563</td>\n",
       "      <td>0.837695</td>\n",
       "      <td>0.468494</td>\n",
       "      <td>0.800266</td>\n",
       "      <td>0.503880</td>\n",
       "      <td>0.204652</td>\n",
       "      <td>-0.041802</td>\n",
       "      <td>4.580908</td>\n",
       "      <td>5.008377</td>\n",
       "      <td>3.195384</td>\n",
       "      <td>2.881232</td>\n",
       "      <td>5.005220</td>\n",
       "      <td>2.934899</td>\n",
       "      <td>4.432433</td>\n",
       "      <td>3.974148</td>\n",
       "      <td>1.940534</td>\n",
       "      <td>112.984322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.215008</td>\n",
       "      <td>-1.942584</td>\n",
       "      <td>-0.679387</td>\n",
       "      <td>-0.154360</td>\n",
       "      <td>-0.693176</td>\n",
       "      <td>-0.979364</td>\n",
       "      <td>-0.121680</td>\n",
       "      <td>-0.163638</td>\n",
       "      <td>0.985034</td>\n",
       "      <td>-0.168108</td>\n",
       "      <td>3.089845</td>\n",
       "      <td>3.152705</td>\n",
       "      <td>-0.134456</td>\n",
       "      <td>3.271302</td>\n",
       "      <td>0.839083</td>\n",
       "      <td>0.665432</td>\n",
       "      <td>3.213270</td>\n",
       "      <td>53.856620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.602651</td>\n",
       "      <td>-2.155852</td>\n",
       "      <td>-0.217981</td>\n",
       "      <td>0.124278</td>\n",
       "      <td>-0.249841</td>\n",
       "      <td>-0.217294</td>\n",
       "      <td>0.183627</td>\n",
       "      <td>0.038705</td>\n",
       "      <td>3.159324</td>\n",
       "      <td>1.626762</td>\n",
       "      <td>3.323646</td>\n",
       "      <td>3.286811</td>\n",
       "      <td>1.694640</td>\n",
       "      <td>3.506390</td>\n",
       "      <td>3.036962</td>\n",
       "      <td>2.917419</td>\n",
       "      <td>5.021556</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cari Oran  Borçluluk Oranı  Return On Equity  Net Kar Marjı       ROE  \\\n",
       "0    0.069087         1.174497         -0.010878      -0.032442 -0.117855   \n",
       "1    0.105389         0.431112          0.130878      -0.042141  0.105474   \n",
       "2   -0.066531         0.355150         -1.042124      -0.566189 -1.005633   \n",
       "3   -0.147505         0.629805         -0.854096      -0.312907 -0.826869   \n",
       "4   -0.185021         0.585940         -0.158191      -0.085558 -0.186236   \n",
       "5    0.155014         0.331831          0.082891      -0.072190  0.103821   \n",
       "6   -0.383587         0.307128         -0.593142      -0.062513 -0.547654   \n",
       "7   -0.239881         0.323656          0.047145       0.177072  0.083770   \n",
       "8    0.355571         0.437331          0.946260       0.354349  0.843090   \n",
       "9    2.467835         1.228967          1.531364       0.265873  1.496315   \n",
       "10  -0.703771         1.332162         -0.525717      -0.070986 -0.476010   \n",
       "11  -0.672486         1.081707          0.074201       0.068129  0.112915   \n",
       "12  -0.455706         0.843206          0.869671       0.217388  0.833063   \n",
       "13   1.874264         0.850279          0.980161       0.155290  0.998133   \n",
       "14   1.141079         0.634266         -0.470493       0.011420 -0.403290   \n",
       "15   2.286211         0.698238          0.536347       0.351923  0.600758   \n",
       "16   2.867484        -0.630349          1.606399       0.559034  1.606549   \n",
       "17   3.440247        -0.227927          2.046622       0.496045  2.133867   \n",
       "18   1.409998         0.456305         -0.431937       0.153400 -0.380148   \n",
       "19  -0.448072         0.708849          0.277526       0.309352  0.358685   \n",
       "20  -0.579960         0.733622          0.928230       0.432924  0.997461   \n",
       "21  -0.464105         1.518412          1.468096       0.384060  1.592015   \n",
       "22  -1.044202         2.085222         -0.582304      -0.076755 -0.549320   \n",
       "23  -0.979796         2.011107         -0.458420      -0.113394 -0.321062   \n",
       "24  -0.735353         1.098126          0.454948       0.182006  0.540877   \n",
       "25  -0.823902         0.878277          0.515739       0.083996  0.605767   \n",
       "26  -1.043115         0.865801         -0.623877      -0.124644 -0.601088   \n",
       "27  -1.098254         0.425779         -0.036215       0.118870 -0.049305   \n",
       "28  -0.766456        -0.277155          1.008986       0.393954  0.900701   \n",
       "29  -0.778378        -0.115362          1.051189       0.263820  0.960937   \n",
       "30  -1.022273         0.163693         -0.684411      -0.125355 -0.668760   \n",
       "31  -0.754760         0.180146          0.175160       0.725311  0.159563   \n",
       "32  -0.661667         0.171324          0.867961       1.047022  0.804207   \n",
       "33  -0.282441        -0.977488          1.562821       0.973725  1.487211   \n",
       "34  -0.413631        -0.067712         -0.522204       0.227065 -0.511648   \n",
       "35  -0.364008        -0.194536         -0.133884       0.335360 -0.144550   \n",
       "36   0.002045        -0.778535          0.665176       0.595657  0.633951   \n",
       "37   0.059861        -2.051848          1.878856       1.382895  1.851048   \n",
       "38   0.213823        -1.200235         -1.157146      -1.756297 -1.174899   \n",
       "39  -0.028675        -0.976767         -1.962347      -3.680508 -1.981709   \n",
       "40   0.143139        -0.136583         -2.295461      -3.105016 -2.315958   \n",
       "41  -0.839634         0.711098         -3.315233      -3.329400 -3.342537   \n",
       "42   0.939888        -0.532150         -0.229464       3.035373 -0.221769   \n",
       "43   1.321615        -1.303419         -0.538990       0.236787 -0.546297   \n",
       "44   0.864577        -1.502787          0.008816       0.571479 -0.015249   \n",
       "45  -0.680678        -1.211746         -0.422861       0.046343 -0.456095   \n",
       "46  -0.192710        -0.323883         -0.927691      -0.701501 -0.943750   \n",
       "47  -0.694977        -0.679132         -0.576444      -0.093439 -0.603078   \n",
       "48  -0.396708        -1.331563          0.070411       0.249351  0.028542   \n",
       "49  -0.398259        -0.880877          0.075123       0.098544  0.021219   \n",
       "50   0.128349        -0.601983         -1.104561      -0.833335 -1.122644   \n",
       "51  -0.638532        -0.321603         -0.732281      -0.250129 -0.758779   \n",
       "52   0.014714        -0.994398          0.589068       0.492472  0.555006   \n",
       "53  -0.057500        -1.836563          0.837695       0.468494  0.800266   \n",
       "54  -0.215008        -1.942584         -0.679387      -0.154360 -0.693176   \n",
       "55  -0.602651        -2.155852         -0.217981       0.124278 -0.249841   \n",
       "\n",
       "    Devir Hızı  Brüt Kar Marjı  Faaliyet Kar Marjı         s         n  \\\n",
       "0     0.982258       -0.622929           -0.044544 -0.483007 -0.333876   \n",
       "1     1.790711       -1.012226           -0.249182 -0.422021 -0.310748   \n",
       "2    -0.752288       -2.067583           -0.868012 -0.591239 -0.403844   \n",
       "3     0.240732       -1.405891           -0.405046 -0.509948 -0.388764   \n",
       "4     1.222420       -0.847805           -0.037637 -0.416335 -0.324246   \n",
       "5     2.180014       -0.827272           -0.098500 -0.340537 -0.293822   \n",
       "6    -0.916623       -1.074063           -0.298308 -0.597113 -0.361514   \n",
       "7    -0.006133       -0.307144            0.137751 -0.528737 -0.300851   \n",
       "8     0.787281        0.383560            0.575661 -0.448626 -0.213079   \n",
       "9     1.931444        0.132945            0.468152 -0.366964 -0.168894   \n",
       "10   -0.598604       -1.862815           -0.585549 -0.571787 -0.354784   \n",
       "11    0.485967       -1.080819           -0.053091 -0.469796 -0.291181   \n",
       "12    1.297271       -0.480924            0.330473 -0.354956 -0.181569   \n",
       "13    1.924445       -0.508842            0.321255 -0.255866 -0.141037   \n",
       "14   -0.746997       -0.984544           -0.163390 -0.560986 -0.337465   \n",
       "15    0.144317       -0.230919            0.547399 -0.456133 -0.200833   \n",
       "16    1.139491        0.497833            0.989271 -0.342554 -0.017100   \n",
       "17    1.748238        0.579480            0.942505 -0.247795  0.072370   \n",
       "18   -0.935708       -0.250439            0.334872 -0.563649 -0.320833   \n",
       "19   -0.098667        0.857545            1.097833 -0.447187 -0.200640   \n",
       "20    0.557027        1.382685            1.530906 -0.308650 -0.024678   \n",
       "21    1.121195        1.028380            1.555570 -0.190350  0.071428   \n",
       "22   -0.941356       -0.262115            0.560395 -0.546057 -0.347627   \n",
       "23   -0.155775        0.296108            0.920304 -0.421183 -0.308075   \n",
       "24    0.617615        0.697782            1.154263 -0.276659 -0.124445   \n",
       "25    1.454741        0.979404            0.863608 -0.084645 -0.077866   \n",
       "26   -0.864401       -0.019083            0.443139 -0.513364 -0.348672   \n",
       "27    0.020339        0.581286            0.857278 -0.338768 -0.212774   \n",
       "28    0.927308        1.246637            1.249572 -0.124576  0.085778   \n",
       "29    1.643185        0.906800            0.992310  0.061808  0.132501   \n",
       "30   -1.177723       -0.068141           -0.182207 -0.556015 -0.357550   \n",
       "31   -0.767856        1.148752            0.260431 -0.415332 -0.052355   \n",
       "32   -0.415968        1.802572            0.450764 -0.203732  0.428196   \n",
       "33    0.209435        1.600670            0.250091 -0.046132  0.659693   \n",
       "34   -1.179884        0.727233           -0.702688 -0.510380 -0.277356   \n",
       "35   -0.672770        1.093782            0.483065 -0.322798 -0.103322   \n",
       "36   -0.008137        1.623335            0.859776 -0.088780  0.298322   \n",
       "37    0.162528        1.335771            0.576314  0.072471  1.313750   \n",
       "38   -1.317782       -0.490092           -1.258609 -0.529122 -0.651244   \n",
       "39   -1.248575       -1.584904           -2.650892 -0.496344 -1.148076   \n",
       "40   -1.105020       -1.203636           -1.854109 -0.387791 -1.466520   \n",
       "41   -0.878404       -2.823133           -2.887514 -0.283128 -2.015968   \n",
       "42   -1.439388       -1.198517           -3.308980 -0.568267  0.014126   \n",
       "43   -1.185264       -0.631375           -1.839571 -0.425380 -0.223755   \n",
       "44   -0.676849        0.751030           -0.325953 -0.127031  0.228868   \n",
       "45   -0.599802        0.452380           -0.605208  0.179288 -0.046838   \n",
       "46   -1.240128       -0.093895           -0.686721 -0.295754 -0.621922   \n",
       "47   -0.705576        0.452570            0.275417  0.353898 -0.170638   \n",
       "48   -0.085727        0.913168            0.482744  1.254037  0.956338   \n",
       "49    0.453958        0.662085            0.153295  2.131274  0.977749   \n",
       "50   -1.043444       -0.885344           -0.676581  0.118554 -1.039447   \n",
       "51   -0.658274       -0.100622           -0.091994  1.170662 -0.404253   \n",
       "52    0.073982        0.524679            0.376610  2.968217  3.462310   \n",
       "53    0.503880        0.204652           -0.041802  4.580908  5.008377   \n",
       "54   -0.979364       -0.121680           -0.163638  0.985034 -0.168108   \n",
       "55   -0.217294        0.183627            0.038705  3.159324  1.626762   \n",
       "\n",
       "           c         t     favök  özkaynak   brütkar  faaliyetkarı     Fiyat  \\\n",
       "0  -0.684847 -0.663463 -0.332235 -0.651988 -0.510240     -0.502738 -0.618247   \n",
       "1  -0.680445 -0.659832 -0.315477 -0.644282 -0.477761     -0.479366 -0.607358   \n",
       "2  -0.698761 -0.655578 -0.411695 -0.640174 -0.614437     -0.629818 -0.613972   \n",
       "3  -0.678028 -0.646541 -0.396320 -0.634268 -0.553174     -0.559447 -0.590259   \n",
       "4  -0.650527 -0.637023 -0.327984 -0.624288 -0.466193     -0.442866 -0.604777   \n",
       "5  -0.637539 -0.638511 -0.303130 -0.623201 -0.406698     -0.387938 -0.589453   \n",
       "6  -0.676407 -0.643221 -0.371654 -0.626669 -0.607477     -0.612170 -0.577839   \n",
       "7  -0.664462 -0.646421 -0.311358 -0.629483 -0.540017     -0.528658 -0.560740   \n",
       "8  -0.607081 -0.634632 -0.211379 -0.620101 -0.443407     -0.390936 -0.558965   \n",
       "9  -0.640355 -0.640994 -0.175573 -0.631810 -0.374942     -0.305714 -0.569450   \n",
       "10 -0.680312 -0.642885 -0.365407 -0.628233 -0.600959     -0.608682 -0.508959   \n",
       "11 -0.663387 -0.631553 -0.302415 -0.621116 -0.515358     -0.492088 -0.497667   \n",
       "12 -0.591425 -0.609204 -0.186756 -0.598404 -0.398222     -0.317600 -0.484359   \n",
       "13 -0.569386 -0.594729 -0.154082 -0.586540 -0.317174     -0.208318 -0.423465   \n",
       "14 -0.644060 -0.603863 -0.352142 -0.597215 -0.579741     -0.578438 -0.385154   \n",
       "15 -0.575578 -0.595121 -0.218573 -0.590516 -0.473826     -0.404169 -0.379508   \n",
       "16 -0.605951 -0.593975 -0.030502 -0.568561 -0.330043     -0.171520 -0.351682   \n",
       "17 -0.536856 -0.582582  0.043586 -0.565679 -0.226413     -0.036310 -0.328695   \n",
       "18 -0.577171 -0.565181 -0.335905 -0.558158 -0.569540     -0.552499 -0.302886   \n",
       "19 -0.562118 -0.559790 -0.222974 -0.559499 -0.423502     -0.320001 -0.235135   \n",
       "20 -0.476928 -0.526410 -0.051829 -0.516266 -0.237235      0.001831 -0.235135   \n",
       "21 -0.493716 -0.511105  0.032575 -0.527691 -0.126902      0.235121 -0.285303   \n",
       "22 -0.578583 -0.523895 -0.359264 -0.552631 -0.554231     -0.517330 -0.368942   \n",
       "23 -0.559548 -0.525458 -0.338167 -0.550693 -0.419664     -0.304187 -0.433305   \n",
       "24 -0.527922 -0.511665 -0.152311 -0.521556 -0.248032     -0.028791 -0.505330   \n",
       "25 -0.491205 -0.487621 -0.109791 -0.495383 -0.012885      0.183542 -0.466373   \n",
       "26 -0.520448 -0.483038 -0.359865 -0.497571 -0.519044     -0.486044 -0.421932   \n",
       "27 -0.485029 -0.476354 -0.218950 -0.477440 -0.321168     -0.192421 -0.375394   \n",
       "28 -0.410680 -0.454011  0.099874 -0.433071 -0.030634      0.256922 -0.300950   \n",
       "29 -0.396037 -0.437432  0.142072 -0.414789  0.141152      0.459215 -0.295627   \n",
       "30 -0.411319 -0.424258 -0.368321 -0.417174 -0.559504     -0.575591 -0.229893   \n",
       "31 -0.328958 -0.341437 -0.059862 -0.349811 -0.375465     -0.396351 -0.256025   \n",
       "32 -0.170521 -0.203773  0.436794 -0.182186 -0.075684     -0.112196 -0.036159   \n",
       "33 -0.188169 -0.269047  0.665253 -0.240871  0.102247     -0.001284 -0.221021   \n",
       "34 -0.182520 -0.259689 -0.290136 -0.269422 -0.496263     -0.586839 -0.144882   \n",
       "35 -0.174065 -0.237569 -0.110638 -0.246649 -0.272316     -0.248801 -0.162465   \n",
       "36 -0.090854 -0.240982  0.292339 -0.213528  0.051859      0.176042 -0.202631   \n",
       "37  0.017084 -0.157335  1.287877 -0.044398  0.212432      0.279836 -0.123428   \n",
       "38  0.301689 -0.106181 -0.640691 -0.063638 -0.544601     -0.639178 -0.267397   \n",
       "39  0.218741 -0.098558 -1.125823 -0.075990 -0.549454     -0.775779 -0.319017   \n",
       "40  0.499820  0.032544 -1.435319 -0.001600 -0.462161     -0.728223 -0.404350   \n",
       "41  0.329826 -0.005316 -1.969636 -0.067256 -0.502905     -1.006650 -0.350230   \n",
       "42  0.326183  0.044140 -0.006809  0.058983 -0.588507     -0.752106 -0.247153   \n",
       "43 -0.188637  0.054257 -0.228326  0.087638 -0.463812     -0.714902 -0.228118   \n",
       "44 -0.082929  0.077494  0.228271  0.144920 -0.083263     -0.284663 -0.202793   \n",
       "45 -0.033689  0.463511 -0.024495  0.471531  0.198699     -0.221648 -0.091650   \n",
       "46  0.235328  0.725012 -0.604834  0.571823 -0.322217     -0.485908  0.109826   \n",
       "47  0.474218  0.897988 -0.145736  0.788253  0.376553      0.445067  0.329853   \n",
       "48  0.877076  1.086660  0.988808  1.081350  1.461588      1.684412  0.679896   \n",
       "49  0.956791  1.224289  1.032229  1.127868  2.298481      2.162459  1.307795   \n",
       "50  1.102246  1.296717 -1.002529  1.126304 -0.060500     -0.288798  1.080751   \n",
       "51  1.741938  2.092400 -0.351207  1.813705  1.015026      0.899842  1.161003   \n",
       "52  2.726635  2.410475  3.465016  2.374833  3.089055      3.535678  2.119588   \n",
       "53  3.195384  2.881232  5.005220  2.934899  4.432433      3.974148  1.940534   \n",
       "54  3.089845  3.152705 -0.134456  3.271302  0.839083      0.665432  3.213270   \n",
       "55  3.323646  3.286811  1.694640  3.506390  3.036962      2.917419  5.021556   \n",
       "\n",
       "        Return  \n",
       "0     2.541967  \n",
       "1     9.549549  \n",
       "2     5.332088  \n",
       "3     0.411186  \n",
       "4    14.831257  \n",
       "5    14.578216  \n",
       "6     9.048725  \n",
       "7    -3.859903  \n",
       "8    21.985815  \n",
       "9    33.085504  \n",
       "10    8.866280  \n",
       "11   25.698323  \n",
       "12   32.843797  \n",
       "13   12.111113  \n",
       "14    8.341704  \n",
       "15   12.487610  \n",
       "16   11.224488  \n",
       "17   20.440529  \n",
       "18   14.011679  \n",
       "19   -9.100218  \n",
       "20  -24.272129  \n",
       "21  -29.534848  \n",
       "22  -32.670017  \n",
       "23   -9.365006  \n",
       "24   29.670015  \n",
       "25   28.427423  \n",
       "26   33.193183  \n",
       "27   19.407375  \n",
       "28   14.636986  \n",
       "29    8.069022  \n",
       "30   34.811595  \n",
       "31    6.599757  \n",
       "32  -14.491507  \n",
       "33   10.356631  \n",
       "34   -9.001760  \n",
       "35    6.256466  \n",
       "36  -11.094226  \n",
       "37  -29.501216  \n",
       "38  -26.386947  \n",
       "39   -6.678172  \n",
       "40   41.144186  \n",
       "41   27.995561  \n",
       "42    8.226144  \n",
       "43   24.443805  \n",
       "44   53.565508  \n",
       "45   60.668674  \n",
       "46   63.606907  \n",
       "47   87.608386  \n",
       "48   27.337734  \n",
       "49   -7.009438  \n",
       "50   55.637150  \n",
       "51   40.028993  \n",
       "52   37.635305  \n",
       "53  112.984322  \n",
       "54   53.856620  \n",
       "55    0.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "rasyo_scaled=scaler.fit_transform(rasyo.iloc[:,:-1])\n",
    "rasyo_scaled=pd.DataFrame(rasyo_scaled,columns=rasyo.columns[:-1])\n",
    "rasyo_scaled[\"Return\"]=rasyo[\"Return\"].values\n",
    "rasyo_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=rasyo_scaled.drop(\"Return\",axis=1)\n",
    "y=rasyo_scaled[\"Return\"]\n",
    "X_train, y_train = X[:-12], y[:-12]\n",
    "X_test, y_test = X[-12:], y[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/42 [00:00<00:01, 25.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GammaRegressor model failed to execute\n",
      "Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 33/42 [00:01<00:00, 22.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoissonRegressor model failed to execute\n",
      "Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:02<00:00, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 278\n",
      "[LightGBM] [Info] Number of data points in the train set: 44, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 7.833455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "reg = LazyRegressor(verbose=0,ignore_warnings=False, custom_metric=None )\n",
    "models,predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>259797.01</td>\n",
       "      <td>-141705.91</td>\n",
       "      <td>12022.12</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANSACRegressor</th>\n",
       "      <td>97.33</td>\n",
       "      <td>-51.54</td>\n",
       "      <td>231.50</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>36.19</td>\n",
       "      <td>-18.20</td>\n",
       "      <td>139.93</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>36.19</td>\n",
       "      <td>-18.20</td>\n",
       "      <td>139.93</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>35.12</td>\n",
       "      <td>-17.61</td>\n",
       "      <td>137.78</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>35.12</td>\n",
       "      <td>-17.61</td>\n",
       "      <td>137.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>34.94</td>\n",
       "      <td>-17.52</td>\n",
       "      <td>137.42</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>32.31</td>\n",
       "      <td>-16.08</td>\n",
       "      <td>131.97</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>32.01</td>\n",
       "      <td>-15.92</td>\n",
       "      <td>131.35</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>32.01</td>\n",
       "      <td>-15.92</td>\n",
       "      <td>131.35</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>28.45</td>\n",
       "      <td>-13.97</td>\n",
       "      <td>123.57</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>21.12</td>\n",
       "      <td>-9.97</td>\n",
       "      <td>105.79</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>19.99</td>\n",
       "      <td>-9.36</td>\n",
       "      <td>102.79</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>19.99</td>\n",
       "      <td>-9.36</td>\n",
       "      <td>102.79</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>15.68</td>\n",
       "      <td>-7.01</td>\n",
       "      <td>90.36</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>14.44</td>\n",
       "      <td>-6.33</td>\n",
       "      <td>86.48</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>13.93</td>\n",
       "      <td>-6.05</td>\n",
       "      <td>84.80</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>13.42</td>\n",
       "      <td>-5.78</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>11.25</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>75.52</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>11.12</td>\n",
       "      <td>-4.52</td>\n",
       "      <td>75.05</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>7.63</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>60.72</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>7.53</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>60.29</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>7.44</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>59.86</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>7.37</td>\n",
       "      <td>-2.48</td>\n",
       "      <td>59.54</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>7.12</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>58.34</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>6.75</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>56.57</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>6.62</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>55.92</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>6.27</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>54.15</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>6.02</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>52.83</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>6.00</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>52.73</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>5.94</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>52.43</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>5.94</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>52.41</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>5.85</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>51.97</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>5.85</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>51.97</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>5.85</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>51.97</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>5.85</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>51.97</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>5.73</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>51.28</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuantileRegressor</th>\n",
       "      <td>5.61</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>50.62</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>5.43</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>49.65</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>4.61</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>44.80</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Adjusted R-Squared  R-Squared     RMSE  \\\n",
       "Model                                                                   \n",
       "Lars                                    259797.01 -141705.91 12022.12   \n",
       "RANSACRegressor                             97.33     -51.54   231.50   \n",
       "LinearRegression                            36.19     -18.20   139.93   \n",
       "TransformedTargetRegressor                  36.19     -18.20   139.93   \n",
       "OrthogonalMatchingPursuit                   35.12     -17.61   137.78   \n",
       "OrthogonalMatchingPursuitCV                 35.12     -17.61   137.78   \n",
       "KernelRidge                                 34.94     -17.52   137.42   \n",
       "SGDRegressor                                32.31     -16.08   131.97   \n",
       "Ridge                                       32.01     -15.92   131.35   \n",
       "RidgeCV                                     32.01     -15.92   131.35   \n",
       "HuberRegressor                              28.45     -13.97   123.57   \n",
       "LassoLarsIC                                 21.12      -9.97   105.79   \n",
       "Lasso                                       19.99      -9.36   102.79   \n",
       "LassoLars                                   19.99      -9.36   102.79   \n",
       "ElasticNet                                  15.68      -7.01    90.36   \n",
       "LinearSVR                                   14.44      -6.33    86.48   \n",
       "PassiveAggressiveRegressor                  13.93      -6.05    84.80   \n",
       "TweedieRegressor                            13.42      -5.78    83.14   \n",
       "MLPRegressor                                11.25      -4.59    75.52   \n",
       "BayesianRidge                               11.12      -4.52    75.05   \n",
       "ExtraTreeRegressor                           7.63      -2.61    60.72   \n",
       "KNeighborsRegressor                          7.53      -2.56    60.29   \n",
       "RandomForestRegressor                        7.44      -2.51    59.86   \n",
       "ExtraTreesRegressor                          7.37      -2.48    59.54   \n",
       "GaussianProcessRegressor                     7.12      -2.34    58.34   \n",
       "XGBRegressor                                 6.75      -2.14    56.57   \n",
       "AdaBoostRegressor                            6.62      -2.07    55.92   \n",
       "BaggingRegressor                             6.27      -1.88    54.15   \n",
       "NuSVR                                        6.02      -1.74    52.83   \n",
       "HistGradientBoostingRegressor                6.00      -1.73    52.73   \n",
       "LGBMRegressor                                5.94      -1.70    52.43   \n",
       "ElasticNetCV                                 5.94      -1.69    52.41   \n",
       "LassoLarsCV                                  5.85      -1.65    51.97   \n",
       "DummyRegressor                               5.85      -1.65    51.97   \n",
       "LarsCV                                       5.85      -1.65    51.97   \n",
       "LassoCV                                      5.85      -1.65    51.97   \n",
       "SVR                                          5.73      -1.58    51.28   \n",
       "QuantileRegressor                            5.61      -1.51    50.62   \n",
       "GradientBoostingRegressor                    5.43      -1.42    49.65   \n",
       "DecisionTreeRegressor                        4.61      -0.97    44.80   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "Lars                                 0.01  \n",
       "RANSACRegressor                      0.10  \n",
       "LinearRegression                     0.01  \n",
       "TransformedTargetRegressor           0.02  \n",
       "OrthogonalMatchingPursuit            0.01  \n",
       "OrthogonalMatchingPursuitCV          0.02  \n",
       "KernelRidge                          0.01  \n",
       "SGDRegressor                         0.01  \n",
       "Ridge                                0.01  \n",
       "RidgeCV                              0.01  \n",
       "HuberRegressor                       0.06  \n",
       "LassoLarsIC                          0.01  \n",
       "Lasso                                0.01  \n",
       "LassoLars                            0.01  \n",
       "ElasticNet                           0.01  \n",
       "LinearSVR                            0.01  \n",
       "PassiveAggressiveRegressor           0.01  \n",
       "TweedieRegressor                     0.01  \n",
       "MLPRegressor                         0.09  \n",
       "BayesianRidge                        0.01  \n",
       "ExtraTreeRegressor                   0.01  \n",
       "KNeighborsRegressor                  0.39  \n",
       "RandomForestRegressor                0.17  \n",
       "ExtraTreesRegressor                  0.11  \n",
       "GaussianProcessRegressor             0.01  \n",
       "XGBRegressor                         0.64  \n",
       "AdaBoostRegressor                    0.10  \n",
       "BaggingRegressor                     0.03  \n",
       "NuSVR                                0.01  \n",
       "HistGradientBoostingRegressor        0.19  \n",
       "LGBMRegressor                        0.04  \n",
       "ElasticNetCV                         0.10  \n",
       "LassoLarsCV                          0.04  \n",
       "DummyRegressor                       0.01  \n",
       "LarsCV                               0.03  \n",
       "LassoCV                              0.27  \n",
       "SVR                                  0.01  \n",
       "QuantileRegressor                    0.02  \n",
       "GradientBoostingRegressor            0.08  \n",
       "DecisionTreeRegressor                0.01  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 22:43:33,333] A new study created in memory with name: no-name-1ebc5147-d580-4ef3-a7d5-bcae86210397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-30 22:43:33,979] Trial 0 finished with value: 46.544707938810824 and parameters: {'n_estimators': 968, 'max_depth': 22, 'learning_rate': 0.0012193412912650092, 'min_samples_split': 2, 'min_samples_leaf': 15, 'subsample': 0.7728200391172724}. Best is trial 0 with value: 46.544707938810824.\n",
      "[I 2024-08-30 22:43:34,622] Trial 1 finished with value: 47.38295935449645 and parameters: {'n_estimators': 827, 'max_depth': 25, 'learning_rate': 0.007195781359801884, 'min_samples_split': 13, 'min_samples_leaf': 4, 'subsample': 0.6908750802064697}. Best is trial 0 with value: 46.544707938810824.\n",
      "[I 2024-08-30 22:43:35,309] Trial 2 finished with value: 49.06735820015611 and parameters: {'n_estimators': 703, 'max_depth': 26, 'learning_rate': 0.004147857649195339, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.732377818772881}. Best is trial 0 with value: 46.544707938810824.\n",
      "[I 2024-08-30 22:43:35,677] Trial 3 finished with value: 44.50131555310306 and parameters: {'n_estimators': 633, 'max_depth': 4, 'learning_rate': 0.006638225915190711, 'min_samples_split': 19, 'min_samples_leaf': 20, 'subsample': 0.8945093092159209}. Best is trial 3 with value: 44.50131555310306.\n",
      "[I 2024-08-30 22:43:36,025] Trial 4 finished with value: 44.43382593653521 and parameters: {'n_estimators': 569, 'max_depth': 31, 'learning_rate': 0.0269770866046793, 'min_samples_split': 19, 'min_samples_leaf': 12, 'subsample': 0.5525378435752584}. Best is trial 4 with value: 44.43382593653521.\n",
      "[I 2024-08-30 22:43:36,629] Trial 5 finished with value: 46.42790537865731 and parameters: {'n_estimators': 808, 'max_depth': 10, 'learning_rate': 0.0735404487600291, 'min_samples_split': 18, 'min_samples_leaf': 10, 'subsample': 0.9687282095596194}. Best is trial 4 with value: 44.43382593653521.\n",
      "[I 2024-08-30 22:43:37,184] Trial 6 finished with value: 44.41272415118644 and parameters: {'n_estimators': 930, 'max_depth': 9, 'learning_rate': 0.034270169315495126, 'min_samples_split': 8, 'min_samples_leaf': 17, 'subsample': 0.6203159713121827}. Best is trial 6 with value: 44.41272415118644.\n",
      "[I 2024-08-30 22:43:37,473] Trial 7 finished with value: 41.76219105983521 and parameters: {'n_estimators': 454, 'max_depth': 25, 'learning_rate': 0.14173257281725793, 'min_samples_split': 3, 'min_samples_leaf': 10, 'subsample': 0.8118546969444013}. Best is trial 7 with value: 41.76219105983521.\n",
      "[I 2024-08-30 22:43:37,869] Trial 8 finished with value: 45.797817702860755 and parameters: {'n_estimators': 506, 'max_depth': 32, 'learning_rate': 0.22512351005483774, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.8615702665744341}. Best is trial 7 with value: 41.76219105983521.\n",
      "[I 2024-08-30 22:43:38,091] Trial 9 finished with value: 44.99769143460814 and parameters: {'n_estimators': 353, 'max_depth': 12, 'learning_rate': 0.001176570143550178, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6499993038963798}. Best is trial 7 with value: 41.76219105983521.\n",
      "[I 2024-08-30 22:43:38,225] Trial 10 finished with value: 52.69572453972168 and parameters: {'n_estimators': 143, 'max_depth': 17, 'learning_rate': 0.8592904101774157, 'min_samples_split': 13, 'min_samples_leaf': 8, 'subsample': 0.8251665447620619}. Best is trial 7 with value: 41.76219105983521.\n",
      "[I 2024-08-30 22:43:38,440] Trial 11 finished with value: 44.204319774091736 and parameters: {'n_estimators': 309, 'max_depth': 3, 'learning_rate': 0.06430844864432425, 'min_samples_split': 8, 'min_samples_leaf': 16, 'subsample': 0.5834042119528379}. Best is trial 7 with value: 41.76219105983521.\n",
      "[I 2024-08-30 22:43:38,645] Trial 12 finished with value: 44.81080503459043 and parameters: {'n_estimators': 293, 'max_depth': 18, 'learning_rate': 0.27063279928773554, 'min_samples_split': 8, 'min_samples_leaf': 13, 'subsample': 0.5157776907479193}. Best is trial 7 with value: 41.76219105983521.\n",
      "[I 2024-08-30 22:43:38,905] Trial 13 finished with value: 44.41751499362823 and parameters: {'n_estimators': 405, 'max_depth': 2, 'learning_rate': 0.11603313095130385, 'min_samples_split': 2, 'min_samples_leaf': 18, 'subsample': 0.5850847690442315}. Best is trial 7 with value: 41.76219105983521.\n",
      "[I 2024-08-30 22:43:39,066] Trial 14 finished with value: 43.36817458261005 and parameters: {'n_estimators': 179, 'max_depth': 18, 'learning_rate': 0.8452881913571109, 'min_samples_split': 6, 'min_samples_leaf': 10, 'subsample': 0.7620970072606299}. Best is trial 7 with value: 41.76219105983521.\n",
      "[I 2024-08-30 22:43:39,174] Trial 15 finished with value: 40.07539982121767 and parameters: {'n_estimators': 106, 'max_depth': 18, 'learning_rate': 0.8191106373581188, 'min_samples_split': 5, 'min_samples_leaf': 9, 'subsample': 0.7847206498564591}. Best is trial 15 with value: 40.07539982121767.\n",
      "[I 2024-08-30 22:43:39,561] Trial 16 finished with value: 47.18952849325486 and parameters: {'n_estimators': 465, 'max_depth': 23, 'learning_rate': 0.3397541426090817, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.9709268616308604}. Best is trial 15 with value: 40.07539982121767.\n",
      "[I 2024-08-30 22:43:39,741] Trial 17 finished with value: 43.6948342947318 and parameters: {'n_estimators': 235, 'max_depth': 28, 'learning_rate': 0.5428466703299981, 'min_samples_split': 4, 'min_samples_leaf': 13, 'subsample': 0.8149832065487523}. Best is trial 15 with value: 40.07539982121767.\n",
      "[I 2024-08-30 22:43:39,875] Trial 18 finished with value: 42.29858714223484 and parameters: {'n_estimators': 131, 'max_depth': 14, 'learning_rate': 0.1685629528597469, 'min_samples_split': 16, 'min_samples_leaf': 9, 'subsample': 0.9109293569815198}. Best is trial 15 with value: 40.07539982121767.\n",
      "[I 2024-08-30 22:43:40,210] Trial 19 finished with value: 40.047331983662716 and parameters: {'n_estimators': 415, 'max_depth': 20, 'learning_rate': 0.4463122790906603, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.6999218095729518}. Best is trial 19 with value: 40.047331983662716.\n",
      "[I 2024-08-30 22:43:40,400] Trial 20 finished with value: 40.28745330377304 and parameters: {'n_estimators': 220, 'max_depth': 15, 'learning_rate': 0.42825975631086566, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.7044571536562246}. Best is trial 19 with value: 40.047331983662716.\n",
      "[I 2024-08-30 22:43:40,599] Trial 21 finished with value: 37.15148833824067 and parameters: {'n_estimators': 234, 'max_depth': 20, 'learning_rate': 0.4193286780867567, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.7024058948030341}. Best is trial 21 with value: 37.15148833824067.\n",
      "[I 2024-08-30 22:43:40,715] Trial 22 finished with value: 32.731617100784746 and parameters: {'n_estimators': 116, 'max_depth': 19, 'learning_rate': 0.9571552694298486, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.6666952147057695}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:41,015] Trial 23 finished with value: 39.31546909309071 and parameters: {'n_estimators': 255, 'max_depth': 21, 'learning_rate': 0.505967026282073, 'min_samples_split': 10, 'min_samples_leaf': 1, 'subsample': 0.6761854083691272}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:41,226] Trial 24 finished with value: 37.5728170748572 and parameters: {'n_estimators': 264, 'max_depth': 20, 'learning_rate': 0.9745063877365432, 'min_samples_split': 15, 'min_samples_leaf': 1, 'subsample': 0.6519920654450069}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:41,500] Trial 25 finished with value: 38.72378449475035 and parameters: {'n_estimators': 348, 'max_depth': 15, 'learning_rate': 0.9613658782103671, 'min_samples_split': 15, 'min_samples_leaf': 1, 'subsample': 0.6384810937034745}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:41,664] Trial 26 finished with value: 53.52632633930889 and parameters: {'n_estimators': 193, 'max_depth': 20, 'learning_rate': 0.26702490812690427, 'min_samples_split': 15, 'min_samples_leaf': 3, 'subsample': 0.6123338828196416}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:41,775] Trial 27 finished with value: 44.96480731992531 and parameters: {'n_estimators': 101, 'max_depth': 7, 'learning_rate': 0.021175676762964172, 'min_samples_split': 12, 'min_samples_leaf': 6, 'subsample': 0.7420087385038796}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:41,993] Trial 28 finished with value: 50.23488465870904 and parameters: {'n_estimators': 272, 'max_depth': 28, 'learning_rate': 0.6086186798036581, 'min_samples_split': 17, 'min_samples_leaf': 3, 'subsample': 0.6629463639950799}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:42,255] Trial 29 finished with value: 40.64215273060158 and parameters: {'n_estimators': 352, 'max_depth': 23, 'learning_rate': 0.08694979826332212, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.7237055893749651}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:42,408] Trial 30 finished with value: 46.315766864792394 and parameters: {'n_estimators': 167, 'max_depth': 21, 'learning_rate': 0.048966334117231336, 'min_samples_split': 11, 'min_samples_leaf': 4, 'subsample': 0.5044235061581122}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:42,673] Trial 31 finished with value: 38.409586128289234 and parameters: {'n_estimators': 328, 'max_depth': 14, 'learning_rate': 0.9918497123084632, 'min_samples_split': 15, 'min_samples_leaf': 1, 'subsample': 0.6375545673020326}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:42,867] Trial 32 finished with value: 38.99035821369867 and parameters: {'n_estimators': 210, 'max_depth': 13, 'learning_rate': 0.5541273496542862, 'min_samples_split': 13, 'min_samples_leaf': 1, 'subsample': 0.588877176927201}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:43,147] Trial 33 finished with value: 46.61891860662555 and parameters: {'n_estimators': 305, 'max_depth': 16, 'learning_rate': 0.002225841182737031, 'min_samples_split': 16, 'min_samples_leaf': 2, 'subsample': 0.6681018482379232}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:43,342] Trial 34 finished with value: 35.26491686487703 and parameters: {'n_estimators': 243, 'max_depth': 12, 'learning_rate': 0.36398617533906463, 'min_samples_split': 20, 'min_samples_leaf': 4, 'subsample': 0.5508598248508035}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:43,741] Trial 35 finished with value: 47.80333143779713 and parameters: {'n_estimators': 609, 'max_depth': 11, 'learning_rate': 0.012209084685232543, 'min_samples_split': 20, 'min_samples_leaf': 4, 'subsample': 0.5495450951670066}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:43,949] Trial 36 finished with value: 40.868286228494384 and parameters: {'n_estimators': 254, 'max_depth': 6, 'learning_rate': 0.17591097214649226, 'min_samples_split': 20, 'min_samples_leaf': 5, 'subsample': 0.5456377902426449}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:44,451] Trial 37 finished with value: 42.739212541493345 and parameters: {'n_estimators': 726, 'max_depth': 24, 'learning_rate': 0.3256166755115158, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.716208590820696}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:44,595] Trial 38 finished with value: 34.68811757953083 and parameters: {'n_estimators': 163, 'max_depth': 8, 'learning_rate': 0.661753659223, 'min_samples_split': 18, 'min_samples_leaf': 2, 'subsample': 0.610648680957343}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:44,742] Trial 39 finished with value: 39.26082083345504 and parameters: {'n_estimators': 155, 'max_depth': 9, 'learning_rate': 0.21070170577273203, 'min_samples_split': 18, 'min_samples_leaf': 7, 'subsample': 0.6201201102684271}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:45,398] Trial 40 finished with value: 45.64627795658401 and parameters: {'n_estimators': 997, 'max_depth': 7, 'learning_rate': 0.11832802859586408, 'min_samples_split': 19, 'min_samples_leaf': 3, 'subsample': 0.5302390192642684}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:45,600] Trial 41 finished with value: 42.84481244319661 and parameters: {'n_estimators': 210, 'max_depth': 20, 'learning_rate': 0.7003639459244079, 'min_samples_split': 18, 'min_samples_leaf': 2, 'subsample': 0.5958891140772923}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:45,911] Trial 42 finished with value: 56.799621638425954 and parameters: {'n_estimators': 406, 'max_depth': 5, 'learning_rate': 0.35827814351217424, 'min_samples_split': 17, 'min_samples_leaf': 2, 'subsample': 0.6840002814732147}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:46,044] Trial 43 finished with value: 46.35810090911142 and parameters: {'n_estimators': 139, 'max_depth': 11, 'learning_rate': 0.6664578461268118, 'min_samples_split': 19, 'min_samples_leaf': 4, 'subsample': 0.646687024140197}. Best is trial 22 with value: 32.731617100784746.\n",
      "[I 2024-08-30 22:43:46,197] Trial 44 finished with value: 32.26189246366774 and parameters: {'n_estimators': 179, 'max_depth': 26, 'learning_rate': 0.4138173344738259, 'min_samples_split': 11, 'min_samples_leaf': 6, 'subsample': 0.5620339843786618}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:46,352] Trial 45 finished with value: 36.67034491504836 and parameters: {'n_estimators': 183, 'max_depth': 27, 'learning_rate': 0.37921483881170276, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.568505140800874}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:46,928] Trial 46 finished with value: 34.50701602498961 and parameters: {'n_estimators': 894, 'max_depth': 28, 'learning_rate': 0.2441158927227785, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.5513670389336223}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:47,469] Trial 47 finished with value: 38.34759731180729 and parameters: {'n_estimators': 846, 'max_depth': 31, 'learning_rate': 0.22050919772297042, 'min_samples_split': 7, 'min_samples_leaf': 8, 'subsample': 0.5634088427533045}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:48,036] Trial 48 finished with value: 44.829098987767615 and parameters: {'n_estimators': 923, 'max_depth': 29, 'learning_rate': 0.27186674206575134, 'min_samples_split': 7, 'min_samples_leaf': 11, 'subsample': 0.5258699244325227}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:48,516] Trial 49 finished with value: 41.10268920459834 and parameters: {'n_estimators': 714, 'max_depth': 26, 'learning_rate': 0.09003016044505682, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.6062267702843235}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:48,863] Trial 50 finished with value: 45.58290210190939 and parameters: {'n_estimators': 540, 'max_depth': 29, 'learning_rate': 0.006328614851546197, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.570835763261082}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:49,307] Trial 51 finished with value: 41.339009402722596 and parameters: {'n_estimators': 662, 'max_depth': 26, 'learning_rate': 0.6533228122096133, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.5478390863227979}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:49,819] Trial 52 finished with value: 43.610120104557026 and parameters: {'n_estimators': 780, 'max_depth': 32, 'learning_rate': 0.3183152668184504, 'min_samples_split': 12, 'min_samples_leaf': 6, 'subsample': 0.5691048157916944}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:49,982] Trial 53 finished with value: 41.37293812369444 and parameters: {'n_estimators': 172, 'max_depth': 27, 'learning_rate': 0.15828033602157277, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.5048723246198048}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:50,089] Trial 54 finished with value: 43.96294035492506 and parameters: {'n_estimators': 101, 'max_depth': 30, 'learning_rate': 0.45880340834891775, 'min_samples_split': 6, 'min_samples_leaf': 8, 'subsample': 0.532908409208239}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:50,221] Trial 55 finished with value: 41.21077512202945 and parameters: {'n_estimators': 134, 'max_depth': 24, 'learning_rate': 0.37442956572053043, 'min_samples_split': 11, 'min_samples_leaf': 5, 'subsample': 0.5789199431204562}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:50,367] Trial 56 finished with value: 44.714883618345446 and parameters: {'n_estimators': 187, 'max_depth': 9, 'learning_rate': 0.12182515319445095, 'min_samples_split': 8, 'min_samples_leaf': 20, 'subsample': 0.6248921935992766}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:50,576] Trial 57 finished with value: 39.33223069441908 and parameters: {'n_estimators': 290, 'max_depth': 25, 'learning_rate': 0.6717968396301169, 'min_samples_split': 4, 'min_samples_leaf': 11, 'subsample': 0.6017581473013651}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:50,905] Trial 58 finished with value: 41.79135957483659 and parameters: {'n_estimators': 481, 'max_depth': 27, 'learning_rate': 0.23770316543609749, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.5617348053611158}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:51,058] Trial 59 finished with value: 40.3590680500398 and parameters: {'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.49535951819365615, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.5194656160304894}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:51,629] Trial 60 finished with value: 32.28384993953763 and parameters: {'n_estimators': 877, 'max_depth': 4, 'learning_rate': 0.845440316386853, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.589362462660095}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:52,191] Trial 61 finished with value: 33.640181473811985 and parameters: {'n_estimators': 892, 'max_depth': 2, 'learning_rate': 0.5280973037385729, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.5830150973830096}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:52,786] Trial 62 finished with value: 41.082489495680214 and parameters: {'n_estimators': 891, 'max_depth': 2, 'learning_rate': 0.7779629831678048, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.592893363541973}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:53,341] Trial 63 finished with value: 34.92304827781946 and parameters: {'n_estimators': 858, 'max_depth': 4, 'learning_rate': 0.5460653090267413, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.6259516776551763}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:53,880] Trial 64 finished with value: 40.95440633239133 and parameters: {'n_estimators': 882, 'max_depth': 4, 'learning_rate': 0.8219883805460445, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.6326329007406855}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:54,377] Trial 65 finished with value: 39.78590053388801 and parameters: {'n_estimators': 814, 'max_depth': 3, 'learning_rate': 0.5711866528707511, 'min_samples_split': 12, 'min_samples_leaf': 10, 'subsample': 0.6192845885170212}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:55,055] Trial 66 finished with value: 39.60875739745068 and parameters: {'n_estimators': 939, 'max_depth': 4, 'learning_rate': 0.49366857734832165, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.653985689286622}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:55,506] Trial 67 finished with value: 45.728150266995655 and parameters: {'n_estimators': 770, 'max_depth': 2, 'learning_rate': 0.790094239692056, 'min_samples_split': 11, 'min_samples_leaf': 14, 'subsample': 0.6056285958629285}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:56,045] Trial 68 finished with value: 40.69511018272 and parameters: {'n_estimators': 848, 'max_depth': 5, 'learning_rate': 0.2887965769841207, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.5799508073394848}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:56,627] Trial 69 finished with value: 40.27706442763325 and parameters: {'n_estimators': 970, 'max_depth': 3, 'learning_rate': 0.9421093794807051, 'min_samples_split': 11, 'min_samples_leaf': 9, 'subsample': 0.5418941838871254}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:57,168] Trial 70 finished with value: 46.79830030195376 and parameters: {'n_estimators': 900, 'max_depth': 6, 'learning_rate': 0.5899480030992794, 'min_samples_split': 16, 'min_samples_leaf': 5, 'subsample': 0.9901014990738346}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:57,694] Trial 71 finished with value: 36.39737576988263 and parameters: {'n_estimators': 872, 'max_depth': 5, 'learning_rate': 0.44469557956379135, 'min_samples_split': 20, 'min_samples_leaf': 6, 'subsample': 0.5549693099454401}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:58,287] Trial 72 finished with value: 37.38246959827191 and parameters: {'n_estimators': 967, 'max_depth': 7, 'learning_rate': 0.19218217540366814, 'min_samples_split': 13, 'min_samples_leaf': 8, 'subsample': 0.5899390652490146}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:58,787] Trial 73 finished with value: 40.552660184894975 and parameters: {'n_estimators': 771, 'max_depth': 10, 'learning_rate': 0.41519827555654515, 'min_samples_split': 17, 'min_samples_leaf': 5, 'subsample': 0.6125450108298124}. Best is trial 44 with value: 32.26189246366774.\n",
      "[I 2024-08-30 22:43:59,349] Trial 74 finished with value: 31.86174424337055 and parameters: {'n_estimators': 928, 'max_depth': 6, 'learning_rate': 0.7443082271853387, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.9140336257070236}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:43:59,903] Trial 75 finished with value: 37.68989848118926 and parameters: {'n_estimators': 922, 'max_depth': 6, 'learning_rate': 0.7354833142686745, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.7863497834707509}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:00,403] Trial 76 finished with value: 44.127129381226105 and parameters: {'n_estimators': 857, 'max_depth': 3, 'learning_rate': 0.5598748549485858, 'min_samples_split': 10, 'min_samples_leaf': 19, 'subsample': 0.8635765656859603}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:00,910] Trial 77 finished with value: 44.74254677255565 and parameters: {'n_estimators': 797, 'max_depth': 4, 'learning_rate': 0.9768804779235898, 'min_samples_split': 12, 'min_samples_leaf': 10, 'subsample': 0.9103320703947758}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:01,420] Trial 78 finished with value: 46.73370594620884 and parameters: {'n_estimators': 831, 'max_depth': 5, 'learning_rate': 0.8164197843617008, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.943237626645839}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:02,017] Trial 79 finished with value: 46.87196549936051 and parameters: {'n_estimators': 956, 'max_depth': 8, 'learning_rate': 0.002002199621057936, 'min_samples_split': 10, 'min_samples_leaf': 12, 'subsample': 0.8331456428258786}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:02,520] Trial 80 finished with value: 44.04818296649755 and parameters: {'n_estimators': 747, 'max_depth': 2, 'learning_rate': 0.039974240520212555, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.7623410501311719}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:03,011] Trial 81 finished with value: 49.25869053424495 and parameters: {'n_estimators': 672, 'max_depth': 17, 'learning_rate': 0.3166379617263061, 'min_samples_split': 11, 'min_samples_leaf': 4, 'subsample': 0.6335070404855607}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:03,599] Trial 82 finished with value: 41.09796171098323 and parameters: {'n_estimators': 913, 'max_depth': 8, 'learning_rate': 0.6406703709377736, 'min_samples_split': 18, 'min_samples_leaf': 6, 'subsample': 0.5795863266532473}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:03,783] Trial 83 finished with value: 40.842331327482015 and parameters: {'n_estimators': 235, 'max_depth': 13, 'learning_rate': 0.5115277449876582, 'min_samples_split': 19, 'min_samples_leaf': 5, 'subsample': 0.538303852239622}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:04,437] Trial 84 finished with value: 38.31953132274864 and parameters: {'n_estimators': 995, 'max_depth': 4, 'learning_rate': 0.38503994203363806, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.6678162999094359}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:05,007] Trial 85 finished with value: 45.2775676814899 and parameters: {'n_estimators': 938, 'max_depth': 6, 'learning_rate': 0.02093533181023465, 'min_samples_split': 15, 'min_samples_leaf': 8, 'subsample': 0.5161164754102922}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:05,170] Trial 86 finished with value: 45.71614776823076 and parameters: {'n_estimators': 158, 'max_depth': 11, 'learning_rate': 0.2661321005982605, 'min_samples_split': 12, 'min_samples_leaf': 4, 'subsample': 0.6883735392242767}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:05,561] Trial 87 finished with value: 59.25496996761941 and parameters: {'n_estimators': 600, 'max_depth': 10, 'learning_rate': 0.7200876835633991, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.5599296066208153}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:05,770] Trial 88 finished with value: 57.565618966849385 and parameters: {'n_estimators': 206, 'max_depth': 19, 'learning_rate': 0.5751626390466827, 'min_samples_split': 11, 'min_samples_leaf': 3, 'subsample': 0.5976793196627405}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:05,898] Trial 89 finished with value: 43.5175565930024 and parameters: {'n_estimators': 123, 'max_depth': 7, 'learning_rate': 0.4116180605506791, 'min_samples_split': 19, 'min_samples_leaf': 6, 'subsample': 0.5763815398011156}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:06,416] Trial 90 finished with value: 32.5673547608534 and parameters: {'n_estimators': 822, 'max_depth': 16, 'learning_rate': 0.8756697541730426, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.643788707230075}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:06,956] Trial 91 finished with value: 33.3256201743989 and parameters: {'n_estimators': 868, 'max_depth': 16, 'learning_rate': 0.8810235777017429, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.6501045054130513}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:07,496] Trial 92 finished with value: 36.15182948225218 and parameters: {'n_estimators': 827, 'max_depth': 16, 'learning_rate': 0.9180850386609773, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.6486081402166178}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:08,041] Trial 93 finished with value: 42.94148792255237 and parameters: {'n_estimators': 868, 'max_depth': 16, 'learning_rate': 0.9936615122487635, 'min_samples_split': 14, 'min_samples_leaf': 10, 'subsample': 0.6772715718719827}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:08,611] Trial 94 finished with value: 42.108302045032914 and parameters: {'n_estimators': 902, 'max_depth': 14, 'learning_rate': 0.7139781187720876, 'min_samples_split': 12, 'min_samples_leaf': 9, 'subsample': 0.658744567967971}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:09,127] Trial 95 finished with value: 39.49322127850703 and parameters: {'n_estimators': 808, 'max_depth': 22, 'learning_rate': 0.8167629929966737, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.6269494747128285}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:09,411] Trial 96 finished with value: 46.238425064995845 and parameters: {'n_estimators': 383, 'max_depth': 18, 'learning_rate': 0.6336753351262941, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.6424969678514415}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:09,984] Trial 97 finished with value: 36.15821185810976 and parameters: {'n_estimators': 891, 'max_depth': 19, 'learning_rate': 0.5575783680360662, 'min_samples_split': 12, 'min_samples_leaf': 8, 'subsample': 0.6975068402508869}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:10,501] Trial 98 finished with value: 41.66719305471199 and parameters: {'n_estimators': 847, 'max_depth': 31, 'learning_rate': 0.48175531681061984, 'min_samples_split': 16, 'min_samples_leaf': 11, 'subsample': 0.6123758060871781}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:11,056] Trial 99 finished with value: 40.746776527897524 and parameters: {'n_estimators': 867, 'max_depth': 17, 'learning_rate': 0.8362120150801319, 'min_samples_split': 11, 'min_samples_leaf': 8, 'subsample': 0.6194477063911159}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:11,638] Trial 100 finished with value: 37.7215673175602 and parameters: {'n_estimators': 953, 'max_depth': 29, 'learning_rate': 0.7131659514256384, 'min_samples_split': 15, 'min_samples_leaf': 7, 'subsample': 0.7081199198707688}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:11,762] Trial 101 finished with value: 42.57537664666279 and parameters: {'n_estimators': 113, 'max_depth': 15, 'learning_rate': 0.3445440893984701, 'min_samples_split': 13, 'min_samples_leaf': 6, 'subsample': 0.5887072631326862}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:12,344] Trial 102 finished with value: 38.993807431144056 and parameters: {'n_estimators': 916, 'max_depth': 12, 'learning_rate': 0.4962040635095161, 'min_samples_split': 20, 'min_samples_leaf': 5, 'subsample': 0.7333734567300414}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:12,975] Trial 103 finished with value: 41.411193155665934 and parameters: {'n_estimators': 981, 'max_depth': 3, 'learning_rate': 0.6199873276411362, 'min_samples_split': 13, 'min_samples_leaf': 8, 'subsample': 0.552950124073716}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:13,564] Trial 104 finished with value: 50.2273321126052 and parameters: {'n_estimators': 832, 'max_depth': 13, 'learning_rate': 0.8480715083000805, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.6000950755711458}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:14,029] Trial 105 finished with value: 43.80386544081823 and parameters: {'n_estimators': 537, 'max_depth': 14, 'learning_rate': 0.3049832018288505, 'min_samples_split': 14, 'min_samples_leaf': 6, 'subsample': 0.6398512746418216}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:14,212] Trial 106 finished with value: 46.575126138039145 and parameters: {'n_estimators': 149, 'max_depth': 15, 'learning_rate': 0.41603971472279183, 'min_samples_split': 17, 'min_samples_leaf': 10, 'subsample': 0.56964862360777}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:14,755] Trial 107 finished with value: 39.74475992000075 and parameters: {'n_estimators': 790, 'max_depth': 12, 'learning_rate': 0.7212899567194461, 'min_samples_split': 9, 'min_samples_leaf': 9, 'subsample': 0.5343401485915424}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:15,418] Trial 108 finished with value: 37.74072996052103 and parameters: {'n_estimators': 886, 'max_depth': 28, 'learning_rate': 0.23802256409853012, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.6069870179404074}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:16,306] Trial 109 finished with value: 34.03300702458599 and parameters: {'n_estimators': 935, 'max_depth': 5, 'learning_rate': 0.4457748962799243, 'min_samples_split': 11, 'min_samples_leaf': 8, 'subsample': 0.679157700906516}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:17,012] Trial 110 finished with value: 36.151184626489886 and parameters: {'n_estimators': 941, 'max_depth': 5, 'learning_rate': 0.45155518679351514, 'min_samples_split': 11, 'min_samples_leaf': 9, 'subsample': 0.676100244249769}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:17,755] Trial 111 finished with value: 43.51563476578398 and parameters: {'n_estimators': 908, 'max_depth': 4, 'learning_rate': 0.3604266345457922, 'min_samples_split': 12, 'min_samples_leaf': 8, 'subsample': 0.6568093305324092}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:18,341] Trial 112 finished with value: 39.33666021661693 and parameters: {'n_estimators': 927, 'max_depth': 3, 'learning_rate': 0.5334487028668623, 'min_samples_split': 13, 'min_samples_leaf': 6, 'subsample': 0.6285802275233592}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:19,001] Trial 113 finished with value: 37.61369901008738 and parameters: {'n_estimators': 879, 'max_depth': 2, 'learning_rate': 0.628391334901835, 'min_samples_split': 10, 'min_samples_leaf': 7, 'subsample': 0.6698131722844226}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:19,206] Trial 114 finished with value: 37.583530004309324 and parameters: {'n_estimators': 196, 'max_depth': 16, 'learning_rate': 0.9030741622729083, 'min_samples_split': 11, 'min_samples_leaf': 8, 'subsample': 0.6152953973347277}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:19,780] Trial 115 finished with value: 35.737936265250056 and parameters: {'n_estimators': 857, 'max_depth': 6, 'learning_rate': 0.760201869102693, 'min_samples_split': 12, 'min_samples_leaf': 5, 'subsample': 0.524889234826298}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:20,386] Trial 116 finished with value: 44.40507841161395 and parameters: {'n_estimators': 950, 'max_depth': 4, 'learning_rate': 0.45600614054587923, 'min_samples_split': 15, 'min_samples_leaf': 7, 'subsample': 0.9422048964930365}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:20,667] Trial 117 finished with value: 44.07944440756869 and parameters: {'n_estimators': 435, 'max_depth': 8, 'learning_rate': 0.5872904964447959, 'min_samples_split': 11, 'min_samples_leaf': 16, 'subsample': 0.5841517434753889}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:21,167] Trial 118 finished with value: 37.09880361562734 and parameters: {'n_estimators': 815, 'max_depth': 9, 'learning_rate': 0.3872805391631462, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.5493071382010771}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:21,355] Trial 119 finished with value: 35.84267437259302 and parameters: {'n_estimators': 221, 'max_depth': 17, 'learning_rate': 0.8774334701080253, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.5604391314565874}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:22,082] Trial 120 finished with value: 41.879493627664 and parameters: {'n_estimators': 981, 'max_depth': 21, 'learning_rate': 0.9943590817895716, 'min_samples_split': 19, 'min_samples_leaf': 3, 'subsample': 0.6384771432098332}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:22,785] Trial 121 finished with value: 38.929640660540805 and parameters: {'n_estimators': 863, 'max_depth': 6, 'learning_rate': 0.7517331775632378, 'min_samples_split': 12, 'min_samples_leaf': 5, 'subsample': 0.5234542560156532}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:22,965] Trial 122 finished with value: 40.46115156810648 and parameters: {'n_estimators': 172, 'max_depth': 5, 'learning_rate': 0.5337299884195218, 'min_samples_split': 12, 'min_samples_leaf': 6, 'subsample': 0.5103797585485149}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:23,535] Trial 123 finished with value: 38.670166117044666 and parameters: {'n_estimators': 836, 'max_depth': 7, 'learning_rate': 0.7141553006457897, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.5412422321128286}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:24,173] Trial 124 finished with value: 44.98959564357574 and parameters: {'n_estimators': 890, 'max_depth': 25, 'learning_rate': 0.647943193980869, 'min_samples_split': 12, 'min_samples_leaf': 4, 'subsample': 0.8727535265019966}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:24,716] Trial 125 finished with value: 41.81085154116222 and parameters: {'n_estimators': 858, 'max_depth': 6, 'learning_rate': 0.7944419762959704, 'min_samples_split': 18, 'min_samples_leaf': 6, 'subsample': 0.5695498363373199}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:25,305] Trial 126 finished with value: 37.950608039544946 and parameters: {'n_estimators': 926, 'max_depth': 10, 'learning_rate': 0.49567428824145043, 'min_samples_split': 13, 'min_samples_leaf': 5, 'subsample': 0.7924975907584035}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:25,906] Trial 127 finished with value: 44.63113654390066 and parameters: {'n_estimators': 899, 'max_depth': 4, 'learning_rate': 0.25135360826878533, 'min_samples_split': 11, 'min_samples_leaf': 7, 'subsample': 0.6486947234582054}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:26,653] Trial 128 finished with value: 48.59439389075047 and parameters: {'n_estimators': 910, 'max_depth': 6, 'learning_rate': 0.010753777504408956, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.6841645971809823}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:27,262] Trial 129 finished with value: 47.97616821857624 and parameters: {'n_estimators': 844, 'max_depth': 19, 'learning_rate': 0.19874117419956022, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.661202032639655}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:27,413] Trial 130 finished with value: 40.7131591548756 and parameters: {'n_estimators': 118, 'max_depth': 3, 'learning_rate': 0.6416048549372034, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.525873327774745}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:27,604] Trial 131 finished with value: 42.07993034310377 and parameters: {'n_estimators': 225, 'max_depth': 17, 'learning_rate': 0.8800373515346237, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.5007639962208579}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:27,809] Trial 132 finished with value: 32.65853553840724 and parameters: {'n_estimators': 257, 'max_depth': 18, 'learning_rate': 0.8604867366366801, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.5586504727579444}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:28,024] Trial 133 finished with value: 37.19933154065012 and parameters: {'n_estimators': 254, 'max_depth': 5, 'learning_rate': 0.7553026740183468, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.5914726721397939}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:28,187] Trial 134 finished with value: 34.28328762711489 and parameters: {'n_estimators': 151, 'max_depth': 22, 'learning_rate': 0.9938112527530903, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.5781017861172054}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:28,409] Trial 135 finished with value: 44.69850499341312 and parameters: {'n_estimators': 278, 'max_depth': 18, 'learning_rate': 0.055464616639731214, 'min_samples_split': 13, 'min_samples_leaf': 10, 'subsample': 0.5555109237195058}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:28,562] Trial 136 finished with value: 42.2140590466276 and parameters: {'n_estimators': 157, 'max_depth': 22, 'learning_rate': 0.9971384280520423, 'min_samples_split': 15, 'min_samples_leaf': 9, 'subsample': 0.5738787477428403}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:28,866] Trial 137 finished with value: 49.43094934589769 and parameters: {'n_estimators': 310, 'max_depth': 19, 'learning_rate': 0.86428467149661, 'min_samples_split': 13, 'min_samples_leaf': 8, 'subsample': 0.605331680476484}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:29,086] Trial 138 finished with value: 45.78418979325556 and parameters: {'n_estimators': 179, 'max_depth': 23, 'learning_rate': 0.5728510258204695, 'min_samples_split': 14, 'min_samples_leaf': 9, 'subsample': 0.5892107579176059}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:29,321] Trial 139 finished with value: 45.80168662356643 and parameters: {'n_estimators': 142, 'max_depth': 20, 'learning_rate': 0.31855284157190955, 'min_samples_split': 13, 'min_samples_leaf': 10, 'subsample': 0.5778871861164744}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:29,533] Trial 140 finished with value: 46.39648120802598 and parameters: {'n_estimators': 197, 'max_depth': 30, 'learning_rate': 0.4224898245126551, 'min_samples_split': 20, 'min_samples_leaf': 11, 'subsample': 0.5630795060185345}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:29,758] Trial 141 finished with value: 37.36120827745365 and parameters: {'n_estimators': 249, 'max_depth': 2, 'learning_rate': 0.8105817631353479, 'min_samples_split': 12, 'min_samples_leaf': 8, 'subsample': 0.5381951671173725}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:29,930] Trial 142 finished with value: 38.84354731807773 and parameters: {'n_estimators': 105, 'max_depth': 16, 'learning_rate': 0.6187228507690007, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.6213425383620079}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:30,109] Trial 143 finished with value: 35.89495736249259 and parameters: {'n_estimators': 131, 'max_depth': 18, 'learning_rate': 0.702986876381953, 'min_samples_split': 16, 'min_samples_leaf': 8, 'subsample': 0.5444823430294548}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:30,822] Trial 144 finished with value: 36.24775768879505 and parameters: {'n_estimators': 880, 'max_depth': 27, 'learning_rate': 0.9869957074418686, 'min_samples_split': 13, 'min_samples_leaf': 6, 'subsample': 0.5972827546425383}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:31,401] Trial 145 finished with value: 36.32805835909887 and parameters: {'n_estimators': 743, 'max_depth': 24, 'learning_rate': 0.5204171239809942, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.5300645577116984}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:31,581] Trial 146 finished with value: 46.76495698781104 and parameters: {'n_estimators': 172, 'max_depth': 7, 'learning_rate': 0.6848178980185502, 'min_samples_split': 11, 'min_samples_leaf': 9, 'subsample': 0.5557052443973967}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:32,256] Trial 147 finished with value: 59.27982761904355 and parameters: {'n_estimators': 868, 'max_depth': 26, 'learning_rate': 0.803590730789019, 'min_samples_split': 14, 'min_samples_leaf': 6, 'subsample': 0.8289438864924441}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:32,666] Trial 148 finished with value: 37.24181539504157 and parameters: {'n_estimators': 506, 'max_depth': 4, 'learning_rate': 0.4618748260386141, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.6330430541940264}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:33,218] Trial 149 finished with value: 36.61276389373074 and parameters: {'n_estimators': 813, 'max_depth': 5, 'learning_rate': 0.554124123978836, 'min_samples_split': 11, 'min_samples_leaf': 8, 'subsample': 0.5836093460081935}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:33,796] Trial 150 finished with value: 38.538402758553694 and parameters: {'n_estimators': 930, 'max_depth': 26, 'learning_rate': 0.36719929309787513, 'min_samples_split': 13, 'min_samples_leaf': 10, 'subsample': 0.5151455532673005}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:33,976] Trial 151 finished with value: 39.79191301573522 and parameters: {'n_estimators': 213, 'max_depth': 17, 'learning_rate': 0.8690824518629413, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.5603691584024962}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:34,159] Trial 152 finished with value: 33.88212872853483 and parameters: {'n_estimators': 211, 'max_depth': 17, 'learning_rate': 0.8787756043803975, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.5487532801919985}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:34,306] Trial 153 finished with value: 44.03888484430121 and parameters: {'n_estimators': 150, 'max_depth': 15, 'learning_rate': 0.6866858401824417, 'min_samples_split': 14, 'min_samples_leaf': 9, 'subsample': 0.5439600253894564}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:34,476] Trial 154 finished with value: 43.88708773883644 and parameters: {'n_estimators': 191, 'max_depth': 28, 'learning_rate': 0.7735763224161694, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.5684925787242566}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:35,089] Trial 155 finished with value: 40.38083846957009 and parameters: {'n_estimators': 964, 'max_depth': 21, 'learning_rate': 0.8930798841051987, 'min_samples_split': 15, 'min_samples_leaf': 8, 'subsample': 0.6080265805781224}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:35,316] Trial 156 finished with value: 39.28737728054631 and parameters: {'n_estimators': 248, 'max_depth': 18, 'learning_rate': 0.5851027761613525, 'min_samples_split': 13, 'min_samples_leaf': 9, 'subsample': 0.5477654989241328}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:35,498] Trial 157 finished with value: 46.935038757079276 and parameters: {'n_estimators': 168, 'max_depth': 16, 'learning_rate': 0.0042211000773584185, 'min_samples_split': 15, 'min_samples_leaf': 1, 'subsample': 0.6456353212673329}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:36,091] Trial 158 finished with value: 45.69304224641814 and parameters: {'n_estimators': 900, 'max_depth': 22, 'learning_rate': 0.001017300406716271, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.5806084330497561}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:36,633] Trial 159 finished with value: 41.70544911391836 and parameters: {'n_estimators': 857, 'max_depth': 17, 'learning_rate': 0.9798311842036478, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.5343421959813612}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:36,850] Trial 160 finished with value: 37.56481324487398 and parameters: {'n_estimators': 236, 'max_depth': 14, 'learning_rate': 0.7702690759923085, 'min_samples_split': 16, 'min_samples_leaf': 5, 'subsample': 0.6261686830313199}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:37,063] Trial 161 finished with value: 38.65074417520312 and parameters: {'n_estimators': 226, 'max_depth': 18, 'learning_rate': 0.8592431223637055, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.5619857994584384}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:37,331] Trial 162 finished with value: 40.508516127375984 and parameters: {'n_estimators': 276, 'max_depth': 16, 'learning_rate': 0.6638396062696982, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.549487688437}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:37,530] Trial 163 finished with value: 36.643811010424564 and parameters: {'n_estimators': 208, 'max_depth': 19, 'learning_rate': 0.8889808953311462, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.5717546434116837}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:37,718] Trial 164 finished with value: 43.81165369882483 and parameters: {'n_estimators': 187, 'max_depth': 17, 'learning_rate': 0.9957756473928496, 'min_samples_split': 15, 'min_samples_leaf': 9, 'subsample': 0.5976463415014874}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:38,272] Trial 165 finished with value: 34.97927519021785 and parameters: {'n_estimators': 680, 'max_depth': 18, 'learning_rate': 0.757143857021176, 'min_samples_split': 14, 'min_samples_leaf': 8, 'subsample': 0.6704862198172203}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:38,732] Trial 166 finished with value: 35.83618618992026 and parameters: {'n_estimators': 674, 'max_depth': 18, 'learning_rate': 0.727197002821616, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.7199721392855302}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:39,213] Trial 167 finished with value: 43.94751464033517 and parameters: {'n_estimators': 693, 'max_depth': 20, 'learning_rate': 0.028377482522749978, 'min_samples_split': 11, 'min_samples_leaf': 8, 'subsample': 0.6743577763713597}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:39,751] Trial 168 finished with value: 42.61187618735672 and parameters: {'n_estimators': 828, 'max_depth': 3, 'learning_rate': 0.4983073583932032, 'min_samples_split': 13, 'min_samples_leaf': 6, 'subsample': 0.6980354050117498}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:40,315] Trial 169 finished with value: 40.091311870336185 and parameters: {'n_estimators': 878, 'max_depth': 15, 'learning_rate': 0.0775952741703058, 'min_samples_split': 17, 'min_samples_leaf': 9, 'subsample': 0.6621899414991171}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:40,754] Trial 170 finished with value: 41.00390553037789 and parameters: {'n_estimators': 637, 'max_depth': 5, 'learning_rate': 0.6171204047706351, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.6545063892586133}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:41,199] Trial 171 finished with value: 39.07341823597913 and parameters: {'n_estimators': 651, 'max_depth': 18, 'learning_rate': 0.704284847819107, 'min_samples_split': 13, 'min_samples_leaf': 7, 'subsample': 0.70590067791742}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:41,595] Trial 172 finished with value: 39.819728188149234 and parameters: {'n_estimators': 577, 'max_depth': 19, 'learning_rate': 0.7608601178790567, 'min_samples_split': 14, 'min_samples_leaf': 7, 'subsample': 0.7541271933194867}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:42,087] Trial 173 finished with value: 36.27034007720771 and parameters: {'n_estimators': 681, 'max_depth': 6, 'learning_rate': 0.6039762909982425, 'min_samples_split': 13, 'min_samples_leaf': 8, 'subsample': 0.6868171196036201}. Best is trial 74 with value: 31.86174424337055.\n",
      "[I 2024-08-30 22:44:42,629] Trial 174 finished with value: 29.154190418789447 and parameters: {'n_estimators': 622, 'max_depth': 17, 'learning_rate': 0.7594337593225224, 'min_samples_split': 13, 'min_samples_leaf': 6, 'subsample': 0.7269947408392278}. Best is trial 174 with value: 29.154190418789447.\n",
      "[I 2024-08-30 22:44:43,102] Trial 175 finished with value: 29.847759578559945 and parameters: {'n_estimators': 572, 'max_depth': 21, 'learning_rate': 0.8342140913105447, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6676094718002545}. Best is trial 174 with value: 29.154190418789447.\n",
      "[I 2024-08-30 22:44:43,265] Trial 176 finished with value: 28.27344892212728 and parameters: {'n_estimators': 124, 'max_depth': 20, 'learning_rate': 0.8542739959889716, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6679774882733525}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:43,669] Trial 177 finished with value: 28.42641271532821 and parameters: {'n_estimators': 509, 'max_depth': 21, 'learning_rate': 0.8496049096297992, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6777083519146038}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:43,868] Trial 178 finished with value: 30.409320637057306 and parameters: {'n_estimators': 119, 'max_depth': 21, 'learning_rate': 0.8670360949229166, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7308395955457982}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:44,371] Trial 179 finished with value: 28.87394849806308 and parameters: {'n_estimators': 604, 'max_depth': 21, 'learning_rate': 0.8786731201687308, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7096725513873312}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:44,829] Trial 180 finished with value: 28.590728932824938 and parameters: {'n_estimators': 588, 'max_depth': 21, 'learning_rate': 0.9909351464537405, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7089979402024824}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:45,247] Trial 181 finished with value: 32.0407173834469 and parameters: {'n_estimators': 609, 'max_depth': 21, 'learning_rate': 0.9855726880478088, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7322871275722823}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:45,637] Trial 182 finished with value: 29.568046188748315 and parameters: {'n_estimators': 578, 'max_depth': 21, 'learning_rate': 0.9123274861447798, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7293987653290903}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:46,035] Trial 183 finished with value: 29.57206745095925 and parameters: {'n_estimators': 594, 'max_depth': 21, 'learning_rate': 0.8996403190057721, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7341798030217593}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:46,433] Trial 184 finished with value: 29.561345650348546 and parameters: {'n_estimators': 589, 'max_depth': 21, 'learning_rate': 0.86545978090821, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7350732934122846}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:46,841] Trial 185 finished with value: 28.708100056231174 and parameters: {'n_estimators': 603, 'max_depth': 21, 'learning_rate': 0.8610759880139953, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7351787767371947}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:47,245] Trial 186 finished with value: 28.838300630588883 and parameters: {'n_estimators': 605, 'max_depth': 21, 'learning_rate': 0.8734215803795371, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7362620740198358}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:47,694] Trial 187 finished with value: 31.087839926504653 and parameters: {'n_estimators': 602, 'max_depth': 21, 'learning_rate': 0.9827304620893624, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7346016466220524}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:48,157] Trial 188 finished with value: 30.714394681202606 and parameters: {'n_estimators': 601, 'max_depth': 21, 'learning_rate': 0.999247870614101, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.727657473335405}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:48,590] Trial 189 finished with value: 32.080743582254314 and parameters: {'n_estimators': 600, 'max_depth': 21, 'learning_rate': 0.9876413615077437, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7379010123559321}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:49,106] Trial 190 finished with value: 32.878106697858904 and parameters: {'n_estimators': 610, 'max_depth': 21, 'learning_rate': 0.9801939479479682, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.734586370516281}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:49,634] Trial 191 finished with value: 36.8355975006119 and parameters: {'n_estimators': 571, 'max_depth': 21, 'learning_rate': 0.8471361890620234, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7451018819217192}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:50,046] Trial 192 finished with value: 33.727808133034415 and parameters: {'n_estimators': 594, 'max_depth': 21, 'learning_rate': 0.9738445861372731, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7278995973845532}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:50,424] Trial 193 finished with value: 35.612350105026174 and parameters: {'n_estimators': 551, 'max_depth': 20, 'learning_rate': 0.9961446871332349, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7146267466760903}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:50,834] Trial 194 finished with value: 46.789300437206016 and parameters: {'n_estimators': 620, 'max_depth': 23, 'learning_rate': 0.8097071636154705, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7663867169156849}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:51,244] Trial 195 finished with value: 30.51378238277314 and parameters: {'n_estimators': 580, 'max_depth': 22, 'learning_rate': 0.8453436980345638, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7382635680243373}. Best is trial 176 with value: 28.27344892212728.\n",
      "[I 2024-08-30 22:44:51,634] Trial 196 finished with value: 25.952881615906495 and parameters: {'n_estimators': 584, 'max_depth': 22, 'learning_rate': 0.8021801188750151, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7387261753074341}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:52,027] Trial 197 finished with value: 27.30044417057776 and parameters: {'n_estimators': 587, 'max_depth': 22, 'learning_rate': 0.7887048379517038, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7377170263864501}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:52,426] Trial 198 finished with value: 28.650299744731864 and parameters: {'n_estimators': 590, 'max_depth': 22, 'learning_rate': 0.7833617098087046, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7388711090014094}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:52,805] Trial 199 finished with value: 46.12106993295213 and parameters: {'n_estimators': 558, 'max_depth': 22, 'learning_rate': 0.7889677009038512, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7524970449751343}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:53,202] Trial 200 finished with value: 32.09032313035525 and parameters: {'n_estimators': 580, 'max_depth': 23, 'learning_rate': 0.7222714835985878, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7257982436699941}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:53,596] Trial 201 finished with value: 29.63689102196115 and parameters: {'n_estimators': 589, 'max_depth': 22, 'learning_rate': 0.8661512653092748, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7346944907908617}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:54,010] Trial 202 finished with value: 25.961693698387418 and parameters: {'n_estimators': 624, 'max_depth': 22, 'learning_rate': 0.8023832518173623, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7449056837240199}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:54,472] Trial 203 finished with value: 31.397382680266258 and parameters: {'n_estimators': 532, 'max_depth': 22, 'learning_rate': 0.677891507270842, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7432169776598296}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:54,885] Trial 204 finished with value: 33.786915505678415 and parameters: {'n_estimators': 526, 'max_depth': 22, 'learning_rate': 0.8245338533621346, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7444526084588993}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:55,394] Trial 205 finished with value: 28.140522194178192 and parameters: {'n_estimators': 630, 'max_depth': 22, 'learning_rate': 0.671167347097449, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7172482861172883}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:56,013] Trial 206 finished with value: 33.737282595558085 and parameters: {'n_estimators': 635, 'max_depth': 23, 'learning_rate': 0.822670367579034, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7110236109573598}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:56,606] Trial 207 finished with value: 28.69785864102052 and parameters: {'n_estimators': 619, 'max_depth': 20, 'learning_rate': 0.6742747776594271, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7229592041761922}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:57,090] Trial 208 finished with value: 30.00176100301497 and parameters: {'n_estimators': 625, 'max_depth': 20, 'learning_rate': 0.6559239536229531, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7211051242140766}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:57,548] Trial 209 finished with value: 48.10149086062302 and parameters: {'n_estimators': 584, 'max_depth': 20, 'learning_rate': 0.6580703512196857, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7761055686510907}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:57,982] Trial 210 finished with value: 45.11142694520084 and parameters: {'n_estimators': 624, 'max_depth': 22, 'learning_rate': 0.6570264262622815, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7581985948945773}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:58,424] Trial 211 finished with value: 29.05255148510945 and parameters: {'n_estimators': 649, 'max_depth': 20, 'learning_rate': 0.7769896426951574, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7218956462630444}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:58,877] Trial 212 finished with value: 36.37158495319505 and parameters: {'n_estimators': 648, 'max_depth': 20, 'learning_rate': 0.7679514501980428, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7188483633363786}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:59,377] Trial 213 finished with value: 30.58286852860685 and parameters: {'n_estimators': 559, 'max_depth': 20, 'learning_rate': 0.7003483702024018, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7197783071262163}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:44:59,900] Trial 214 finished with value: 35.76736868888491 and parameters: {'n_estimators': 625, 'max_depth': 22, 'learning_rate': 0.8331644204323682, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.7480213926184034}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:00,350] Trial 215 finished with value: 33.41367981813312 and parameters: {'n_estimators': 586, 'max_depth': 23, 'learning_rate': 0.7574515938187253, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7077393107438616}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:00,782] Trial 216 finished with value: 32.290785816726036 and parameters: {'n_estimators': 565, 'max_depth': 22, 'learning_rate': 0.606721357287833, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6962238313703539}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:01,220] Trial 217 finished with value: 33.96777026717891 and parameters: {'n_estimators': 641, 'max_depth': 21, 'learning_rate': 0.8546643947278302, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7236280322540192}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:01,661] Trial 218 finished with value: 30.474730027510436 and parameters: {'n_estimators': 616, 'max_depth': 20, 'learning_rate': 0.6936118261428305, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7387892562275749}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:02,098] Trial 219 finished with value: 28.920333251093624 and parameters: {'n_estimators': 621, 'max_depth': 24, 'learning_rate': 0.6765457075389599, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7111221087616844}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:02,551] Trial 220 finished with value: 31.144384552280062 and parameters: {'n_estimators': 660, 'max_depth': 24, 'learning_rate': 0.6161995028092547, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.7146995813800562}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:02,979] Trial 221 finished with value: 30.525785942097848 and parameters: {'n_estimators': 613, 'max_depth': 20, 'learning_rate': 0.6943164017079725, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7290897969101917}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:03,573] Trial 222 finished with value: 45.849243369771685 and parameters: {'n_estimators': 619, 'max_depth': 20, 'learning_rate': 0.7423775969966571, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7509214275257642}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:04,098] Trial 223 finished with value: 30.152747151079485 and parameters: {'n_estimators': 593, 'max_depth': 23, 'learning_rate': 0.8599641107863407, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7390451507634083}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:04,554] Trial 224 finished with value: 32.31608326856347 and parameters: {'n_estimators': 596, 'max_depth': 24, 'learning_rate': 0.8638625126057293, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7068944886026737}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:05,030] Trial 225 finished with value: 31.51699478974132 and parameters: {'n_estimators': 632, 'max_depth': 23, 'learning_rate': 0.8601680664366975, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.7197290850956225}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:05,461] Trial 226 finished with value: 43.01378711241801 and parameters: {'n_estimators': 575, 'max_depth': 21, 'learning_rate': 0.7836481836893691, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7667024010443878}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:05,871] Trial 227 finished with value: 37.75397796788455 and parameters: {'n_estimators': 548, 'max_depth': 22, 'learning_rate': 0.6169019289466591, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.6959911893185962}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:06,380] Trial 228 finished with value: 30.03943236130342 and parameters: {'n_estimators': 591, 'max_depth': 21, 'learning_rate': 0.8850358589437899, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7433485842240525}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:06,815] Trial 229 finished with value: 46.447752995583016 and parameters: {'n_estimators': 589, 'max_depth': 23, 'learning_rate': 0.7273998524874481, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7437137100827629}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:07,268] Trial 230 finished with value: 49.46353812185682 and parameters: {'n_estimators': 648, 'max_depth': 22, 'learning_rate': 0.8810714882778948, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7599233440674885}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:07,762] Trial 231 finished with value: 28.226081049381943 and parameters: {'n_estimators': 595, 'max_depth': 21, 'learning_rate': 0.7881965670926905, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7297936312257773}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:08,236] Trial 232 finished with value: 26.087768934369926 and parameters: {'n_estimators': 596, 'max_depth': 21, 'learning_rate': 0.7554811433604581, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7242566553406969}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:08,714] Trial 233 finished with value: 29.61103206446452 and parameters: {'n_estimators': 567, 'max_depth': 21, 'learning_rate': 0.6694359799174678, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7235263758871968}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:09,105] Trial 234 finished with value: 37.61773578004258 and parameters: {'n_estimators': 564, 'max_depth': 20, 'learning_rate': 0.6507947425814563, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7147741428108058}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:09,515] Trial 235 finished with value: 34.36538918805469 and parameters: {'n_estimators': 516, 'max_depth': 21, 'learning_rate': 0.7306449688680934, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7262864120678256}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:09,997] Trial 236 finished with value: 39.99371225374725 and parameters: {'n_estimators': 628, 'max_depth': 19, 'learning_rate': 0.6035864013431961, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7214640864645112}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:10,418] Trial 237 finished with value: 28.526560352475904 and parameters: {'n_estimators': 610, 'max_depth': 21, 'learning_rate': 0.7696595200303878, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7058442180581558}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:10,897] Trial 238 finished with value: 35.80022010109909 and parameters: {'n_estimators': 604, 'max_depth': 21, 'learning_rate': 0.7487563255317277, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7007312891297865}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:11,323] Trial 239 finished with value: 39.51219803227707 and parameters: {'n_estimators': 565, 'max_depth': 22, 'learning_rate': 0.5643755965729226, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7075832649309335}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:11,800] Trial 240 finished with value: 26.54569143617958 and parameters: {'n_estimators': 609, 'max_depth': 21, 'learning_rate': 0.7690645472585873, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7328257244656389}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:12,336] Trial 241 finished with value: 27.91879711010082 and parameters: {'n_estimators': 610, 'max_depth': 21, 'learning_rate': 0.7793071989025738, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7310920738591308}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:12,779] Trial 242 finished with value: 27.813824464818108 and parameters: {'n_estimators': 611, 'max_depth': 22, 'learning_rate': 0.7583982414645392, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7323776400357269}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:13,213] Trial 243 finished with value: 39.126073072329525 and parameters: {'n_estimators': 612, 'max_depth': 21, 'learning_rate': 0.7402766877359708, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.7257168859629235}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:13,646] Trial 244 finished with value: 27.829385420300856 and parameters: {'n_estimators': 658, 'max_depth': 22, 'learning_rate': 0.7578407364183456, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7325368578602677}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:14,109] Trial 245 finished with value: 26.636137494736424 and parameters: {'n_estimators': 664, 'max_depth': 22, 'learning_rate': 0.7604041800972613, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7335586126553781}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:14,555] Trial 246 finished with value: 37.24737802802328 and parameters: {'n_estimators': 661, 'max_depth': 22, 'learning_rate': 0.7698108581403431, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.7491543794264693}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:14,991] Trial 247 finished with value: 40.24645617085214 and parameters: {'n_estimators': 649, 'max_depth': 23, 'learning_rate': 0.5718002558978901, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7124762679181089}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:15,456] Trial 248 finished with value: 37.716341012725216 and parameters: {'n_estimators': 635, 'max_depth': 22, 'learning_rate': 0.7491730383286083, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.6896367851284322}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:15,944] Trial 249 finished with value: 31.31129023742477 and parameters: {'n_estimators': 615, 'max_depth': 20, 'learning_rate': 0.6733372010803009, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.7332501757977923}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:16,459] Trial 250 finished with value: 41.79966849638423 and parameters: {'n_estimators': 707, 'max_depth': 21, 'learning_rate': 0.7832627950550937, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7522346818762563}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:16,966] Trial 251 finished with value: 44.49007208552344 and parameters: {'n_estimators': 662, 'max_depth': 23, 'learning_rate': 0.01516115716507425, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.707457295134113}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:17,446] Trial 252 finished with value: 43.546658304157525 and parameters: {'n_estimators': 642, 'max_depth': 22, 'learning_rate': 0.6455152535440721, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7403982636601995}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:17,916] Trial 253 finished with value: 45.64739537868779 and parameters: {'n_estimators': 613, 'max_depth': 21, 'learning_rate': 0.0018153718526741707, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7281849027931894}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:18,364] Trial 254 finished with value: 36.744715556386 and parameters: {'n_estimators': 632, 'max_depth': 22, 'learning_rate': 0.9910053859106895, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.714477171426426}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:18,789] Trial 255 finished with value: 44.05376943811341 and parameters: {'n_estimators': 607, 'max_depth': 20, 'learning_rate': 0.542970249652377, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7334217168453302}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:19,261] Trial 256 finished with value: 46.07944343773802 and parameters: {'n_estimators': 630, 'max_depth': 24, 'learning_rate': 0.7775636224002531, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7531194415068319}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:19,729] Trial 257 finished with value: 28.005011952535536 and parameters: {'n_estimators': 683, 'max_depth': 21, 'learning_rate': 0.9115578203821219, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7008907918586998}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:20,187] Trial 258 finished with value: 28.836640909051056 and parameters: {'n_estimators': 690, 'max_depth': 19, 'learning_rate': 0.6988648638927036, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6974305904265198}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:20,671] Trial 259 finished with value: 45.98626043780084 and parameters: {'n_estimators': 690, 'max_depth': 19, 'learning_rate': 0.6570436031682624, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.6876017655188864}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:21,161] Trial 260 finished with value: 39.756543649032665 and parameters: {'n_estimators': 680, 'max_depth': 20, 'learning_rate': 0.5462809995028781, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6992090656771077}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:21,615] Trial 261 finished with value: 36.709538404241336 and parameters: {'n_estimators': 705, 'max_depth': 19, 'learning_rate': 0.7030446050800617, 'min_samples_split': 6, 'min_samples_leaf': 13, 'subsample': 0.7004834743002472}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:22,058] Trial 262 finished with value: 26.924754051092613 and parameters: {'n_estimators': 665, 'max_depth': 22, 'learning_rate': 0.7699349085609004, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7127707473859839}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:22,505] Trial 263 finished with value: 42.63113281617657 and parameters: {'n_estimators': 667, 'max_depth': 22, 'learning_rate': 0.6029998819782733, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7136224822444112}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:22,963] Trial 264 finished with value: 29.467492379993455 and parameters: {'n_estimators': 734, 'max_depth': 20, 'learning_rate': 0.8035925114789417, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.692215288241016}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:23,434] Trial 265 finished with value: 43.382799381773374 and parameters: {'n_estimators': 655, 'max_depth': 23, 'learning_rate': 0.040149061504613524, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.708068877057934}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:23,908] Trial 266 finished with value: 41.10049813388927 and parameters: {'n_estimators': 695, 'max_depth': 22, 'learning_rate': 0.7484945039609383, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6820790577691184}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:24,365] Trial 267 finished with value: 35.16486870705126 and parameters: {'n_estimators': 715, 'max_depth': 21, 'learning_rate': 0.916915058265872, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7156486621822633}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:24,812] Trial 268 finished with value: 31.511367445294262 and parameters: {'n_estimators': 673, 'max_depth': 25, 'learning_rate': 0.6314015176789733, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7053547547594382}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:25,238] Trial 269 finished with value: 30.190729810596295 and parameters: {'n_estimators': 645, 'max_depth': 20, 'learning_rate': 0.8028182055347305, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7194478708348251}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:25,681] Trial 270 finished with value: 40.228909644324986 and parameters: {'n_estimators': 602, 'max_depth': 22, 'learning_rate': 0.09955426036311457, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.743613047935092}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:26,106] Trial 271 finished with value: 47.65484799140757 and parameters: {'n_estimators': 646, 'max_depth': 21, 'learning_rate': 0.6870956118270944, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.6954558973608636}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:26,536] Trial 272 finished with value: 28.87018849858302 and parameters: {'n_estimators': 665, 'max_depth': 22, 'learning_rate': 0.9897853734503869, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7214382683572285}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:26,974] Trial 273 finished with value: 32.14635772427758 and parameters: {'n_estimators': 670, 'max_depth': 22, 'learning_rate': 0.9235885752836054, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7025985106746981}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:27,375] Trial 274 finished with value: 35.07751490240379 and parameters: {'n_estimators': 612, 'max_depth': 23, 'learning_rate': 0.9974430377144311, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7417174196322306}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:27,795] Trial 275 finished with value: 46.35865936295246 and parameters: {'n_estimators': 630, 'max_depth': 23, 'learning_rate': 0.8973705186562236, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.7706237652027186}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:28,255] Trial 276 finished with value: 42.0143375086761 and parameters: {'n_estimators': 683, 'max_depth': 22, 'learning_rate': 0.5257692734062822, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7575838376369234}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:28,662] Trial 277 finished with value: 31.498914052768516 and parameters: {'n_estimators': 594, 'max_depth': 21, 'learning_rate': 0.8599182776108741, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.7157565519934247}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:29,040] Trial 278 finished with value: 31.40561524647844 and parameters: {'n_estimators': 546, 'max_depth': 22, 'learning_rate': 0.6797040876798126, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7314295525458919}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:29,446] Trial 279 finished with value: 32.13159277582374 and parameters: {'n_estimators': 622, 'max_depth': 21, 'learning_rate': 0.9940902501379366, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.6899259166850701}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:29,859] Trial 280 finished with value: 45.85617967853674 and parameters: {'n_estimators': 663, 'max_depth': 24, 'learning_rate': 0.7993825791972816, 'min_samples_split': 7, 'min_samples_leaf': 18, 'subsample': 0.7256040527114218}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:30,286] Trial 281 finished with value: 39.757750546501775 and parameters: {'n_estimators': 606, 'max_depth': 21, 'learning_rate': 0.5931171418000295, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.6785956506852775}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:30,673] Trial 282 finished with value: 40.90349940567579 and parameters: {'n_estimators': 581, 'max_depth': 23, 'learning_rate': 0.7167609958418998, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7482240126420768}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:31,128] Trial 283 finished with value: 32.690782443515616 and parameters: {'n_estimators': 717, 'max_depth': 22, 'learning_rate': 0.8613987841109376, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7092963466708999}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:31,565] Trial 284 finished with value: 31.979668659799835 and parameters: {'n_estimators': 635, 'max_depth': 21, 'learning_rate': 0.9958180679536898, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.7373260470363672}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:31,975] Trial 285 finished with value: 41.356425931924136 and parameters: {'n_estimators': 597, 'max_depth': 22, 'learning_rate': 0.761054077261719, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.7201535990458835}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:32,433] Trial 286 finished with value: 29.10271114371967 and parameters: {'n_estimators': 698, 'max_depth': 20, 'learning_rate': 0.6436317936060139, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7059493363242837}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:32,726] Trial 287 finished with value: 32.76141059591585 and parameters: {'n_estimators': 335, 'max_depth': 21, 'learning_rate': 0.8298421382043595, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7283131832340675}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:33,037] Trial 288 finished with value: 42.44956836808127 and parameters: {'n_estimators': 374, 'max_depth': 23, 'learning_rate': 0.14936538857111184, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7435591470900275}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:33,454] Trial 289 finished with value: 31.540158756433904 and parameters: {'n_estimators': 614, 'max_depth': 22, 'learning_rate': 0.6960144485034874, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.716596922901489}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:33,837] Trial 290 finished with value: 44.80979087880222 and parameters: {'n_estimators': 574, 'max_depth': 20, 'learning_rate': 0.5808572146162484, 'min_samples_split': 6, 'min_samples_leaf': 15, 'subsample': 0.7000504253244517}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:34,285] Trial 291 finished with value: 51.33936438615488 and parameters: {'n_estimators': 638, 'max_depth': 21, 'learning_rate': 0.8769454133122274, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.7582445494068414}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:34,795] Trial 292 finished with value: 41.75632893456599 and parameters: {'n_estimators': 659, 'max_depth': 19, 'learning_rate': 0.507783636277561, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7349075347607333}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:35,184] Trial 293 finished with value: 46.51972931894014 and parameters: {'n_estimators': 448, 'max_depth': 24, 'learning_rate': 0.006321259968216773, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7230558037991351}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:35,606] Trial 294 finished with value: 29.17630432548703 and parameters: {'n_estimators': 584, 'max_depth': 22, 'learning_rate': 0.7498172766602393, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6933110810477288}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:36,019] Trial 295 finished with value: 31.718264162714714 and parameters: {'n_estimators': 622, 'max_depth': 21, 'learning_rate': 0.809908745683137, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7119171534018517}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:36,421] Trial 296 finished with value: 30.931497188167913 and parameters: {'n_estimators': 603, 'max_depth': 20, 'learning_rate': 0.6621091653120156, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.748156851966629}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:36,809] Trial 297 finished with value: 39.434289687120696 and parameters: {'n_estimators': 550, 'max_depth': 22, 'learning_rate': 0.8960703479045745, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.7331942863640348}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:37,313] Trial 298 finished with value: 31.957144614258528 and parameters: {'n_estimators': 678, 'max_depth': 23, 'learning_rate': 0.5971581736718803, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.7260097385434895}. Best is trial 196 with value: 25.952881615906495.\n",
      "[I 2024-08-30 22:45:37,891] Trial 299 finished with value: 21.667207188919914 and parameters: {'n_estimators': 656, 'max_depth': 21, 'learning_rate': 0.9976202996087893, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6823449477673802}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:38,625] Trial 300 finished with value: 32.6180165213685 and parameters: {'n_estimators': 660, 'max_depth': 21, 'learning_rate': 0.9997542156510221, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.6761764586020471}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:39,370] Trial 301 finished with value: 32.03204245031642 and parameters: {'n_estimators': 693, 'max_depth': 22, 'learning_rate': 0.889431157745183, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.6794607324023683}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:39,837] Trial 302 finished with value: 39.84051301722363 and parameters: {'n_estimators': 640, 'max_depth': 20, 'learning_rate': 0.7807814961421813, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.6885415096576372}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:40,276] Trial 303 finished with value: 47.53492441699191 and parameters: {'n_estimators': 567, 'max_depth': 21, 'learning_rate': 0.8854006314028263, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7393760273459679}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:40,670] Trial 304 finished with value: 26.45195981764014 and parameters: {'n_estimators': 593, 'max_depth': 21, 'learning_rate': 0.9798619192072643, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7010197241955182}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:41,072] Trial 305 finished with value: 46.688104751220706 and parameters: {'n_estimators': 586, 'max_depth': 19, 'learning_rate': 0.9887441134802673, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.6653537259702444}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:41,436] Trial 306 finished with value: 36.30429855084895 and parameters: {'n_estimators': 477, 'max_depth': 22, 'learning_rate': 0.7785025642502234, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6994773705170839}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:41,878] Trial 307 finished with value: 46.92048993902067 and parameters: {'n_estimators': 649, 'max_depth': 20, 'learning_rate': 0.9997195740306165, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7550940134299483}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:42,326] Trial 308 finished with value: 27.71515111575527 and parameters: {'n_estimators': 677, 'max_depth': 21, 'learning_rate': 0.762730184180215, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.681287941688399}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:42,811] Trial 309 finished with value: 38.67499173107714 and parameters: {'n_estimators': 688, 'max_depth': 21, 'learning_rate': 0.7126123206998795, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6830944041140032}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:43,223] Trial 310 finished with value: 29.615006384452926 and parameters: {'n_estimators': 599, 'max_depth': 21, 'learning_rate': 0.7849338435419343, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.673639216305306}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:43,694] Trial 311 finished with value: 29.768764875991057 and parameters: {'n_estimators': 729, 'max_depth': 20, 'learning_rate': 0.6293469306074607, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6877987913223451}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:44,135] Trial 312 finished with value: 36.30663030605383 and parameters: {'n_estimators': 625, 'max_depth': 20, 'learning_rate': 0.7118296012734752, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.6955062425371946}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:44,550] Trial 313 finished with value: 41.869402781092134 and parameters: {'n_estimators': 559, 'max_depth': 21, 'learning_rate': 0.5406755019110797, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.7458894407732972}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:44,984] Trial 314 finished with value: 48.06480121917977 and parameters: {'n_estimators': 575, 'max_depth': 23, 'learning_rate': 0.8200968379905225, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.76418854749661}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:45,461] Trial 315 finished with value: 28.277689468116204 and parameters: {'n_estimators': 616, 'max_depth': 21, 'learning_rate': 0.6994063743524708, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7023257228082057}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:45,963] Trial 316 finished with value: 34.45533585873216 and parameters: {'n_estimators': 675, 'max_depth': 22, 'learning_rate': 0.6182700165923198, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7022605067430612}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:46,435] Trial 317 finished with value: 36.59770314519506 and parameters: {'n_estimators': 643, 'max_depth': 21, 'learning_rate': 0.4854600782491403, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.679680145628697}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:46,899] Trial 318 finished with value: 28.938007033215897 and parameters: {'n_estimators': 705, 'max_depth': 20, 'learning_rate': 0.7027225444693221, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6625511842038827}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:47,338] Trial 319 finished with value: 37.58649830836018 and parameters: {'n_estimators': 616, 'max_depth': 22, 'learning_rate': 0.568256435714371, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6942021397580811}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:47,768] Trial 320 finished with value: 30.662823656273286 and parameters: {'n_estimators': 657, 'max_depth': 22, 'learning_rate': 0.7737045775153935, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.703276576540402}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:48,171] Trial 321 finished with value: 37.13989890175599 and parameters: {'n_estimators': 589, 'max_depth': 19, 'learning_rate': 0.6431596148046342, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7765457392665478}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:48,610] Trial 322 finished with value: 42.00007858026575 and parameters: {'n_estimators': 632, 'max_depth': 23, 'learning_rate': 0.7143136644272273, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7149576253153767}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:49,099] Trial 323 finished with value: 32.33896626389897 and parameters: {'n_estimators': 762, 'max_depth': 21, 'learning_rate': 0.854283855315883, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.6876535940657884}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:49,521] Trial 324 finished with value: 33.89290676949293 and parameters: {'n_estimators': 610, 'max_depth': 20, 'learning_rate': 0.786169644630716, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7245116387094584}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:49,910] Trial 325 finished with value: 27.306159498141387 and parameters: {'n_estimators': 545, 'max_depth': 21, 'learning_rate': 0.6683006866742734, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6725574713329276}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:50,320] Trial 326 finished with value: 29.528021789882843 and parameters: {'n_estimators': 537, 'max_depth': 22, 'learning_rate': 0.5978736113663298, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6711165632648275}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:50,722] Trial 327 finished with value: 35.622452331257534 and parameters: {'n_estimators': 509, 'max_depth': 21, 'learning_rate': 0.8757377029526779, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6671400982747352}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:51,139] Trial 328 finished with value: 30.603776543218814 and parameters: {'n_estimators': 557, 'max_depth': 21, 'learning_rate': 0.517768920770774, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.659695224793417}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:51,548] Trial 329 finished with value: 41.03228427539156 and parameters: {'n_estimators': 582, 'max_depth': 23, 'learning_rate': 0.6900738022416132, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7319783975893723}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:51,985] Trial 330 finished with value: 37.70994629871453 and parameters: {'n_estimators': 597, 'max_depth': 22, 'learning_rate': 0.8882594334949723, 'min_samples_split': 9, 'min_samples_leaf': 7, 'subsample': 0.6824407069016443}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:52,353] Trial 331 finished with value: 26.786179758124312 and parameters: {'n_estimators': 527, 'max_depth': 21, 'learning_rate': 0.782742072403528, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7136513106150457}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:52,771] Trial 332 finished with value: 32.00696531542375 and parameters: {'n_estimators': 537, 'max_depth': 21, 'learning_rate': 0.6049236642909175, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7086900622671215}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:53,136] Trial 333 finished with value: 28.41887989132773 and parameters: {'n_estimators': 529, 'max_depth': 22, 'learning_rate': 0.7562930423428291, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7180960757708679}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:53,503] Trial 334 finished with value: 35.729805773474624 and parameters: {'n_estimators': 512, 'max_depth': 23, 'learning_rate': 0.7799846006544893, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7130650431757654}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:53,919] Trial 335 finished with value: 28.04369809522588 and parameters: {'n_estimators': 490, 'max_depth': 22, 'learning_rate': 0.9969362549476566, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.6878855903930343}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:54,299] Trial 336 finished with value: 36.44386052826544 and parameters: {'n_estimators': 484, 'max_depth': 22, 'learning_rate': 0.9979023526670923, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.6878793926908612}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:54,708] Trial 337 finished with value: 28.867744544346806 and parameters: {'n_estimators': 491, 'max_depth': 22, 'learning_rate': 0.8912322764976061, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.6792055876800738}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:55,166] Trial 338 finished with value: 35.21413836628719 and parameters: {'n_estimators': 495, 'max_depth': 23, 'learning_rate': 0.8002255967516421, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.6730559557927996}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:55,539] Trial 339 finished with value: 42.08790083712856 and parameters: {'n_estimators': 524, 'max_depth': 22, 'learning_rate': 0.8964110389261601, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7008562289422263}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:55,929] Trial 340 finished with value: 43.12182272054557 and parameters: {'n_estimators': 531, 'max_depth': 23, 'learning_rate': 0.7283384514220747, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.6919976459039954}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:56,370] Trial 341 finished with value: 44.93281196804514 and parameters: {'n_estimators': 513, 'max_depth': 21, 'learning_rate': 0.02267657347031547, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7099825480442279}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:56,718] Trial 342 finished with value: 36.17461218889003 and parameters: {'n_estimators': 422, 'max_depth': 22, 'learning_rate': 0.9800993339984132, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7033423109374645}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:57,181] Trial 343 finished with value: 40.716668803460365 and parameters: {'n_estimators': 553, 'max_depth': 21, 'learning_rate': 0.7936360445104538, 'min_samples_split': 7, 'min_samples_leaf': 4, 'subsample': 0.65891412536004}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:57,722] Trial 344 finished with value: 41.05588740484673 and parameters: {'n_estimators': 536, 'max_depth': 21, 'learning_rate': 0.06028253240831895, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.7194663507931243}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:58,206] Trial 345 finished with value: 26.392494302955555 and parameters: {'n_estimators': 473, 'max_depth': 22, 'learning_rate': 0.9918444441615063, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.694178619150145}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:58,652] Trial 346 finished with value: 40.92021077644739 and parameters: {'n_estimators': 506, 'max_depth': 22, 'learning_rate': 0.6686674829311028, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.6817099453824016}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:59,071] Trial 347 finished with value: 55.081088508530634 and parameters: {'n_estimators': 478, 'max_depth': 23, 'learning_rate': 0.9983999206866703, 'min_samples_split': 8, 'min_samples_leaf': 4, 'subsample': 0.671036700219695}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:59,420] Trial 348 finished with value: 31.397476604604787 and parameters: {'n_estimators': 466, 'max_depth': 22, 'learning_rate': 0.8251567328715941, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.6925084194247476}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:45:59,793] Trial 349 finished with value: 41.5201391568957 and parameters: {'n_estimators': 492, 'max_depth': 23, 'learning_rate': 0.5524844596918963, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6856818107456617}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:00,145] Trial 350 finished with value: 40.165619197094045 and parameters: {'n_estimators': 455, 'max_depth': 24, 'learning_rate': 0.7162811637111269, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.6971588468885718}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:00,511] Trial 351 finished with value: 32.10121148975148 and parameters: {'n_estimators': 520, 'max_depth': 22, 'learning_rate': 0.8699888783897091, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7259665780547349}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:00,913] Trial 352 finished with value: 40.7052507233389 and parameters: {'n_estimators': 535, 'max_depth': 21, 'learning_rate': 0.4632615526357424, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.6518627604331536}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:01,305] Trial 353 finished with value: 27.663772098037 and parameters: {'n_estimators': 550, 'max_depth': 20, 'learning_rate': 0.6366646481514034, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6727799931662791}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:01,702] Trial 354 finished with value: 41.53734312177112 and parameters: {'n_estimators': 543, 'max_depth': 20, 'learning_rate': 0.5824049290856198, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.6672359168928634}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:02,078] Trial 355 finished with value: 28.948430163742984 and parameters: {'n_estimators': 501, 'max_depth': 20, 'learning_rate': 0.644448206595079, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6737445547823658}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:02,429] Trial 356 finished with value: 45.10302054770793 and parameters: {'n_estimators': 555, 'max_depth': 22, 'learning_rate': 0.699216570178304, 'min_samples_split': 5, 'min_samples_leaf': 20, 'subsample': 0.6820619891166}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:02,810] Trial 357 finished with value: 45.5686062316397 and parameters: {'n_estimators': 520, 'max_depth': 23, 'learning_rate': 0.0027115195532345327, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6555446498071397}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:03,188] Trial 358 finished with value: 39.51050818919995 and parameters: {'n_estimators': 551, 'max_depth': 20, 'learning_rate': 0.8849047328759692, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7509284162193772}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:03,633] Trial 359 finished with value: 37.22696049662426 and parameters: {'n_estimators': 665, 'max_depth': 22, 'learning_rate': 0.6248248876042996, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.6694953007599358}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:04,051] Trial 360 finished with value: 37.228602864242276 and parameters: {'n_estimators': 568, 'max_depth': 21, 'learning_rate': 0.5204802071512881, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.692992981145133}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:04,420] Trial 361 finished with value: 34.86899622360889 and parameters: {'n_estimators': 519, 'max_depth': 22, 'learning_rate': 0.745641710594066, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.716499836570445}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:04,815] Trial 362 finished with value: 48.23332411353985 and parameters: {'n_estimators': 572, 'max_depth': 21, 'learning_rate': 0.8567865455428038, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7366749905572034}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:05,264] Trial 363 finished with value: 48.880928002837564 and parameters: {'n_estimators': 653, 'max_depth': 23, 'learning_rate': 0.993925317760363, 'min_samples_split': 3, 'min_samples_leaf': 7, 'subsample': 0.6811611598893046}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:05,692] Trial 364 finished with value: 26.854211986854974 and parameters: {'n_estimators': 642, 'max_depth': 21, 'learning_rate': 0.7545502345043061, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7266319041659732}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:06,136] Trial 365 finished with value: 39.38933576571235 and parameters: {'n_estimators': 675, 'max_depth': 22, 'learning_rate': 0.6624711290279, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7278905765726542}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:06,571] Trial 366 finished with value: 44.78789601281957 and parameters: {'n_estimators': 638, 'max_depth': 20, 'learning_rate': 0.5752537212740902, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.742373593794544}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:07,055] Trial 367 finished with value: 44.9044045492464 and parameters: {'n_estimators': 636, 'max_depth': 21, 'learning_rate': 0.12358483744569404, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7210216413225725}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:07,516] Trial 368 finished with value: 39.16091748203313 and parameters: {'n_estimators': 675, 'max_depth': 20, 'learning_rate': 0.7635073059693742, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7334838776638641}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:07,956] Trial 369 finished with value: 40.664116737237954 and parameters: {'n_estimators': 628, 'max_depth': 22, 'learning_rate': 0.4691459983116854, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.716214696348467}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:08,384] Trial 370 finished with value: 39.89826371324976 and parameters: {'n_estimators': 655, 'max_depth': 23, 'learning_rate': 0.6748688376195054, 'min_samples_split': 6, 'min_samples_leaf': 12, 'subsample': 0.7476881505906258}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:08,811] Trial 371 finished with value: 27.195713659504793 and parameters: {'n_estimators': 647, 'max_depth': 21, 'learning_rate': 0.7673082710018486, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7287865698494383}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:09,239] Trial 372 finished with value: 41.277855708034494 and parameters: {'n_estimators': 649, 'max_depth': 20, 'learning_rate': 0.876731734534891, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7611589431954766}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:09,696] Trial 373 finished with value: 44.79920095450921 and parameters: {'n_estimators': 694, 'max_depth': 21, 'learning_rate': 0.9997149227681519, 'min_samples_split': 5, 'min_samples_leaf': 14, 'subsample': 0.7281735859730337}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:10,143] Trial 374 finished with value: 46.63175820009114 and parameters: {'n_estimators': 660, 'max_depth': 19, 'learning_rate': 0.584318328752975, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.742866896930032}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:10,629] Trial 375 finished with value: 27.79553811640466 and parameters: {'n_estimators': 625, 'max_depth': 21, 'learning_rate': 0.7880574911551359, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.731340392986255}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:11,100] Trial 376 finished with value: 45.91621447077866 and parameters: {'n_estimators': 641, 'max_depth': 21, 'learning_rate': 0.010224628951458242, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7540465284130026}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:11,562] Trial 377 finished with value: 25.37963905716517 and parameters: {'n_estimators': 714, 'max_depth': 20, 'learning_rate': 0.7984711243918087, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7332185175997102}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:12,031] Trial 378 finished with value: 27.9895118419503 and parameters: {'n_estimators': 710, 'max_depth': 24, 'learning_rate': 0.7891114606958511, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7369734481861397}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:12,509] Trial 379 finished with value: 38.86118289386932 and parameters: {'n_estimators': 711, 'max_depth': 25, 'learning_rate': 0.7852333054088692, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7382113877838626}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:12,991] Trial 380 finished with value: 30.045725355718986 and parameters: {'n_estimators': 713, 'max_depth': 25, 'learning_rate': 0.6590466585217107, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7463342475345643}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:13,484] Trial 381 finished with value: 51.337314750118736 and parameters: {'n_estimators': 760, 'max_depth': 24, 'learning_rate': 0.8821521717075665, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.8438147450004915}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:13,977] Trial 382 finished with value: 27.20903573137939 and parameters: {'n_estimators': 732, 'max_depth': 22, 'learning_rate': 0.7662106461992777, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7320675634172717}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:14,442] Trial 383 finished with value: 46.98551791993167 and parameters: {'n_estimators': 722, 'max_depth': 24, 'learning_rate': 0.8089280044471935, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7563505368677722}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:14,905] Trial 384 finished with value: 35.970727597940034 and parameters: {'n_estimators': 719, 'max_depth': 23, 'learning_rate': 0.8693904483759344, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.7357665889786172}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:15,362] Trial 385 finished with value: 31.137246296919038 and parameters: {'n_estimators': 698, 'max_depth': 24, 'learning_rate': 0.999859987462988, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7430526059133676}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:15,836] Trial 386 finished with value: 42.08078294760123 and parameters: {'n_estimators': 734, 'max_depth': 20, 'learning_rate': 0.7740374404652148, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7306084688958018}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:16,290] Trial 387 finished with value: 39.847484282410086 and parameters: {'n_estimators': 679, 'max_depth': 19, 'learning_rate': 0.7583220281040277, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7715660810284333}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:16,777] Trial 388 finished with value: 30.04769110884853 and parameters: {'n_estimators': 751, 'max_depth': 21, 'learning_rate': 0.8842862907631414, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7281162342305695}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:17,274] Trial 389 finished with value: 43.16645447240001 and parameters: {'n_estimators': 744, 'max_depth': 22, 'learning_rate': 0.5997261159801393, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7458076003585401}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:17,753] Trial 390 finished with value: 30.620523429432495 and parameters: {'n_estimators': 726, 'max_depth': 21, 'learning_rate': 0.6876615244669697, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7339003506771506}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:18,093] Trial 391 finished with value: 42.17921345376491 and parameters: {'n_estimators': 468, 'max_depth': 23, 'learning_rate': 0.9968808340811979, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7558026904562537}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:18,551] Trial 392 finished with value: 35.935974945076495 and parameters: {'n_estimators': 697, 'max_depth': 20, 'learning_rate': 0.7419407287297931, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7239968081963333}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:19,107] Trial 393 finished with value: 47.033524392305274 and parameters: {'n_estimators': 775, 'max_depth': 22, 'learning_rate': 0.5298239095376478, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7383760273481775}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:19,593] Trial 394 finished with value: 46.96257491387026 and parameters: {'n_estimators': 677, 'max_depth': 21, 'learning_rate': 0.8143809789884511, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7504929023413377}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:20,053] Trial 395 finished with value: 34.134484218632196 and parameters: {'n_estimators': 689, 'max_depth': 22, 'learning_rate': 0.6212928837369837, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7230600421609016}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:20,506] Trial 396 finished with value: 49.067427595663304 and parameters: {'n_estimators': 703, 'max_depth': 20, 'learning_rate': 0.8535902362938856, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.9875317264612562}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:21,017] Trial 397 finished with value: 36.79017402909387 and parameters: {'n_estimators': 735, 'max_depth': 19, 'learning_rate': 0.7361593743940464, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7110579234877926}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:21,350] Trial 398 finished with value: 29.646738078639707 and parameters: {'n_estimators': 450, 'max_depth': 21, 'learning_rate': 0.8920717137350165, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7371848216256096}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:21,830] Trial 399 finished with value: 44.02196918129128 and parameters: {'n_estimators': 666, 'max_depth': 23, 'learning_rate': 0.6946251912237574, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7648445797948539}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:22,181] Trial 400 finished with value: 48.262748965942016 and parameters: {'n_estimators': 436, 'max_depth': 22, 'learning_rate': 0.9016885777971726, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.7279365465446662}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:22,668] Trial 401 finished with value: 35.81273911377453 and parameters: {'n_estimators': 684, 'max_depth': 20, 'learning_rate': 0.6350472789564052, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7175006146323403}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:23,138] Trial 402 finished with value: 28.71651517483743 and parameters: {'n_estimators': 659, 'max_depth': 21, 'learning_rate': 0.7786663521303712, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7450855607148421}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:23,649] Trial 403 finished with value: 42.99332444131642 and parameters: {'n_estimators': 651, 'max_depth': 23, 'learning_rate': 0.5678429928903495, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7052340098482031}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:24,107] Trial 404 finished with value: 34.15203093053231 and parameters: {'n_estimators': 677, 'max_depth': 22, 'learning_rate': 0.9998363375615713, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7843750140769902}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:24,769] Trial 405 finished with value: 29.40593358757182 and parameters: {'n_estimators': 703, 'max_depth': 21, 'learning_rate': 0.7151324894566096, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7348276357746797}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:25,356] Trial 406 finished with value: 29.52793968850668 and parameters: {'n_estimators': 638, 'max_depth': 22, 'learning_rate': 0.8693612355570962, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.723924858496565}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:25,878] Trial 407 finished with value: 43.07693718124136 and parameters: {'n_estimators': 623, 'max_depth': 21, 'learning_rate': 0.1757815741197488, 'min_samples_split': 9, 'min_samples_leaf': 5, 'subsample': 0.7148194684447224}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:26,319] Trial 408 finished with value: 41.432418477611414 and parameters: {'n_estimators': 569, 'max_depth': 20, 'learning_rate': 0.6308593790230719, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7445970621261323}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:27,028] Trial 409 finished with value: 43.16784595161467 and parameters: {'n_estimators': 723, 'max_depth': 22, 'learning_rate': 0.784324291787059, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7573497187260747}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:27,687] Trial 410 finished with value: 33.61774802569303 and parameters: {'n_estimators': 746, 'max_depth': 21, 'learning_rate': 0.8801635857270993, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.7306712284962847}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:28,197] Trial 411 finished with value: 37.71479458202011 and parameters: {'n_estimators': 670, 'max_depth': 23, 'learning_rate': 0.5254332571309783, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.6951311434101525}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:28,678] Trial 412 finished with value: 35.4234812880797 and parameters: {'n_estimators': 617, 'max_depth': 24, 'learning_rate': 0.9995684383079203, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7135172945821899}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:29,215] Trial 413 finished with value: 29.922308595195066 and parameters: {'n_estimators': 648, 'max_depth': 22, 'learning_rate': 0.7117170863487917, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7061055066917561}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:29,642] Trial 414 finished with value: 45.61277052358551 and parameters: {'n_estimators': 481, 'max_depth': 21, 'learning_rate': 0.7993349435856972, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7407493017130289}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:30,245] Trial 415 finished with value: 42.34525617940074 and parameters: {'n_estimators': 579, 'max_depth': 20, 'learning_rate': 0.04540106294652667, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.7269904282676309}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:30,783] Trial 416 finished with value: 37.11361670466359 and parameters: {'n_estimators': 630, 'max_depth': 19, 'learning_rate': 0.6461023586058556, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.7485055564466666}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:31,326] Trial 417 finished with value: 31.149802674950337 and parameters: {'n_estimators': 687, 'max_depth': 22, 'learning_rate': 0.8882433823609199, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6898404234480416}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:31,722] Trial 418 finished with value: 45.24477229457696 and parameters: {'n_estimators': 602, 'max_depth': 23, 'learning_rate': 0.7195525502953107, 'min_samples_split': 5, 'min_samples_leaf': 17, 'subsample': 0.720704520204201}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:32,291] Trial 419 finished with value: 44.47277245540073 and parameters: {'n_estimators': 708, 'max_depth': 27, 'learning_rate': 0.4665197017310992, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.736432619483464}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:32,704] Trial 420 finished with value: 30.115372034327 and parameters: {'n_estimators': 554, 'max_depth': 21, 'learning_rate': 0.782368773300915, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7026272750986129}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:33,194] Trial 421 finished with value: 43.82968689916136 and parameters: {'n_estimators': 665, 'max_depth': 22, 'learning_rate': 0.5980870685050971, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7301252277432538}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:33,626] Trial 422 finished with value: 28.79025609030831 and parameters: {'n_estimators': 647, 'max_depth': 20, 'learning_rate': 0.8950831374756962, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.715396853384863}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:34,042] Trial 423 finished with value: 48.242519205389115 and parameters: {'n_estimators': 586, 'max_depth': 22, 'learning_rate': 0.6877423213632212, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7525874250655564}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:34,500] Trial 424 finished with value: 46.07593052517255 and parameters: {'n_estimators': 618, 'max_depth': 21, 'learning_rate': 0.005188957761169284, 'min_samples_split': 8, 'min_samples_leaf': 7, 'subsample': 0.7629272186076927}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:34,935] Trial 425 finished with value: 24.919956921678324 and parameters: {'n_estimators': 634, 'max_depth': 21, 'learning_rate': 0.9979774315852834, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6867468418653493}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:35,381] Trial 426 finished with value: 33.36628828825597 and parameters: {'n_estimators': 638, 'max_depth': 20, 'learning_rate': 0.8026928132428173, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7229452642585453}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:35,820] Trial 427 finished with value: 36.24621580430485 and parameters: {'n_estimators': 602, 'max_depth': 25, 'learning_rate': 0.5619093542698048, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.7372067883333201}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:36,144] Trial 428 finished with value: 29.95387341924701 and parameters: {'n_estimators': 409, 'max_depth': 21, 'learning_rate': 0.7117942580434194, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.709321073284528}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:36,587] Trial 429 finished with value: 36.970398412390196 and parameters: {'n_estimators': 630, 'max_depth': 20, 'learning_rate': 0.8591245691560931, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.6971678097094285}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:37,049] Trial 430 finished with value: 31.5180617682452 and parameters: {'n_estimators': 658, 'max_depth': 21, 'learning_rate': 0.6426837958849531, 'min_samples_split': 3, 'min_samples_leaf': 6, 'subsample': 0.7445039188811952}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:37,555] Trial 431 finished with value: 41.995950825922115 and parameters: {'n_estimators': 611, 'max_depth': 19, 'learning_rate': 0.07336119893571753, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6778895252785857}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:38,018] Trial 432 finished with value: 42.68352974924025 and parameters: {'n_estimators': 684, 'max_depth': 21, 'learning_rate': 0.8043383892103643, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.8028738050162814}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:38,508] Trial 433 finished with value: 30.915306423490797 and parameters: {'n_estimators': 647, 'max_depth': 19, 'learning_rate': 0.8816063021312485, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7303893758685217}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:38,951] Trial 434 finished with value: 36.483007268133484 and parameters: {'n_estimators': 576, 'max_depth': 21, 'learning_rate': 0.7307651546353162, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7226090156482459}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:39,540] Trial 435 finished with value: 31.543841112556745 and parameters: {'n_estimators': 708, 'max_depth': 26, 'learning_rate': 0.6122195098005593, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7080587208572621}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:40,080] Trial 436 finished with value: 27.98998952216185 and parameters: {'n_estimators': 668, 'max_depth': 20, 'learning_rate': 0.9209068740192164, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.739327986093526}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:40,795] Trial 437 finished with value: 42.14135544324125 and parameters: {'n_estimators': 632, 'max_depth': 20, 'learning_rate': 0.776189118766354, 'min_samples_split': 4, 'min_samples_leaf': 7, 'subsample': 0.7548103649273615}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:41,489] Trial 438 finished with value: 29.886189625177405 and parameters: {'n_estimators': 664, 'max_depth': 19, 'learning_rate': 0.9904889819783664, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7395560770674834}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:42,152] Trial 439 finished with value: 39.38748308823923 and parameters: {'n_estimators': 605, 'max_depth': 20, 'learning_rate': 0.5042115541781954, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.749037461485053}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:42,776] Trial 440 finished with value: 45.225328378069065 and parameters: {'n_estimators': 623, 'max_depth': 23, 'learning_rate': 0.0013937516072974447, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7655360229220816}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:43,412] Trial 441 finished with value: 45.852664509571106 and parameters: {'n_estimators': 592, 'max_depth': 22, 'learning_rate': 0.015408507616219813, 'min_samples_split': 4, 'min_samples_leaf': 5, 'subsample': 0.7348937299467095}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:43,839] Trial 442 finished with value: 31.940568006058328 and parameters: {'n_estimators': 391, 'max_depth': 24, 'learning_rate': 0.6704614386011214, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7417470886805578}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:44,381] Trial 443 finished with value: 45.50233248767174 and parameters: {'n_estimators': 649, 'max_depth': 20, 'learning_rate': 0.002912693133166704, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.72668040611014}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:45,092] Trial 444 finished with value: 46.0808682334428 and parameters: {'n_estimators': 791, 'max_depth': 21, 'learning_rate': 0.7936651040669415, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7516957854436571}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:45,652] Trial 445 finished with value: 28.08409739598174 and parameters: {'n_estimators': 565, 'max_depth': 23, 'learning_rate': 0.8640124623009282, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.7325553343351964}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:46,286] Trial 446 finished with value: 42.44174621585551 and parameters: {'n_estimators': 669, 'max_depth': 20, 'learning_rate': 0.030906630652615712, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.6628494253372177}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:46,937] Trial 447 finished with value: 41.26823722967951 and parameters: {'n_estimators': 618, 'max_depth': 22, 'learning_rate': 0.576024159928654, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7214016942269847}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:47,512] Trial 448 finished with value: 42.52457632832267 and parameters: {'n_estimators': 591, 'max_depth': 21, 'learning_rate': 0.7136922734305767, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7409881830943893}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:48,124] Trial 449 finished with value: 28.562691217384284 and parameters: {'n_estimators': 638, 'max_depth': 19, 'learning_rate': 0.9912400734348901, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7177418713834387}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:48,786] Trial 450 finished with value: 41.35839581189564 and parameters: {'n_estimators': 655, 'max_depth': 22, 'learning_rate': 0.40437134280534465, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.733568381162476}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:49,366] Trial 451 finished with value: 39.646518889384225 and parameters: {'n_estimators': 543, 'max_depth': 21, 'learning_rate': 0.800807313775084, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.7574683611486007}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:49,993] Trial 452 finished with value: 40.7229185179889 and parameters: {'n_estimators': 689, 'max_depth': 20, 'learning_rate': 0.6671416577626152, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.7464977154429926}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:50,856] Trial 453 finished with value: 28.02676287802867 and parameters: {'n_estimators': 726, 'max_depth': 23, 'learning_rate': 0.9024479654523604, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7156469216294862}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:51,338] Trial 454 finished with value: 36.41956540212367 and parameters: {'n_estimators': 614, 'max_depth': 22, 'learning_rate': 0.737909360992764, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.726751931442334}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:51,808] Trial 455 finished with value: 40.70535159094061 and parameters: {'n_estimators': 580, 'max_depth': 21, 'learning_rate': 0.5521900482526799, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.6829955886105296}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:52,236] Trial 456 finished with value: 29.919579826687585 and parameters: {'n_estimators': 631, 'max_depth': 22, 'learning_rate': 0.8884217353534556, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7391140239873648}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:52,736] Trial 457 finished with value: 43.9599976774472 and parameters: {'n_estimators': 665, 'max_depth': 20, 'learning_rate': 0.6417833556037292, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7753348207760193}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:53,129] Trial 458 finished with value: 49.98598039879038 and parameters: {'n_estimators': 557, 'max_depth': 21, 'learning_rate': 0.8053065933175445, 'min_samples_split': 4, 'min_samples_leaf': 6, 'subsample': 0.9461928596372271}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:53,566] Trial 459 finished with value: 32.092149442064034 and parameters: {'n_estimators': 606, 'max_depth': 22, 'learning_rate': 0.7217308497047826, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.6733106250428168}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:54,015] Trial 460 finished with value: 30.43829737213837 and parameters: {'n_estimators': 645, 'max_depth': 23, 'learning_rate': 0.9068061515094054, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7278483117751052}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:54,584] Trial 461 finished with value: 29.325216484181926 and parameters: {'n_estimators': 737, 'max_depth': 19, 'learning_rate': 0.6453134547759167, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.704939806439148}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:55,014] Trial 462 finished with value: 43.54070868999958 and parameters: {'n_estimators': 676, 'max_depth': 20, 'learning_rate': 0.9874415640933146, 'min_samples_split': 7, 'min_samples_leaf': 19, 'subsample': 0.6492649830169502}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:55,502] Trial 463 finished with value: 28.8070519145447 and parameters: {'n_estimators': 709, 'max_depth': 22, 'learning_rate': 0.8019202829756508, 'min_samples_split': 5, 'min_samples_leaf': 5, 'subsample': 0.7151487987736223}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:55,996] Trial 464 finished with value: 49.12425232763739 and parameters: {'n_estimators': 589, 'max_depth': 21, 'learning_rate': 0.5121512079919707, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7499986129514603}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:56,412] Trial 465 finished with value: 41.61653706346132 and parameters: {'n_estimators': 570, 'max_depth': 21, 'learning_rate': 0.763745618882101, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6880916800554453}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:56,879] Trial 466 finished with value: 43.99700823277123 and parameters: {'n_estimators': 631, 'max_depth': 20, 'learning_rate': 0.6040789841098029, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7330621139824663}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:57,367] Trial 467 finished with value: 47.679928872297594 and parameters: {'n_estimators': 697, 'max_depth': 24, 'learning_rate': 0.8870087621978534, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7619137473129136}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:57,840] Trial 468 finished with value: 31.37290501104192 and parameters: {'n_estimators': 603, 'max_depth': 21, 'learning_rate': 0.6956900629828268, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7228645752571972}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:58,334] Trial 469 finished with value: 31.569673277342122 and parameters: {'n_estimators': 659, 'max_depth': 18, 'learning_rate': 0.991783475300182, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6969649606540378}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:58,864] Trial 470 finished with value: 24.98571744100165 and parameters: {'n_estimators': 620, 'max_depth': 23, 'learning_rate': 0.8007746840447002, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7379604647467922}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:59,322] Trial 471 finished with value: 32.22760401131142 and parameters: {'n_estimators': 619, 'max_depth': 24, 'learning_rate': 0.6076165701076421, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.6608892002216996}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:46:59,790] Trial 472 finished with value: 45.22341392313799 and parameters: {'n_estimators': 610, 'max_depth': 23, 'learning_rate': 0.6980167369548196, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.898769215938251}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:00,249] Trial 473 finished with value: 45.79045703944884 and parameters: {'n_estimators': 586, 'max_depth': 24, 'learning_rate': 0.008284252487708841, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.7106898803020684}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:00,756] Trial 474 finished with value: 42.73419476230533 and parameters: {'n_estimators': 626, 'max_depth': 23, 'learning_rate': 0.45957184625345077, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.7293888497237017}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:01,185] Trial 475 finished with value: 24.22179383089584 and parameters: {'n_estimators': 564, 'max_depth': 23, 'learning_rate': 0.7934119964277395, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.7453402177445843}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:01,576] Trial 476 finished with value: 41.07749002542218 and parameters: {'n_estimators': 550, 'max_depth': 23, 'learning_rate': 0.5383793488885784, 'min_samples_split': 6, 'min_samples_leaf': 11, 'subsample': 0.7483623094105839}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:02,071] Trial 477 finished with value: 46.15593164079461 and parameters: {'n_estimators': 567, 'max_depth': 22, 'learning_rate': 0.7991580253856833, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.7670379440274558}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:02,468] Trial 478 finished with value: 38.294932264444675 and parameters: {'n_estimators': 545, 'max_depth': 22, 'learning_rate': 0.668623549747915, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7178866360182984}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:02,886] Trial 479 finished with value: 38.24643456680581 and parameters: {'n_estimators': 577, 'max_depth': 23, 'learning_rate': 0.7367598383376298, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.7517841875572635}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:03,326] Trial 480 finished with value: 26.51128664778634 and parameters: {'n_estimators': 597, 'max_depth': 22, 'learning_rate': 0.5957796884412688, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6735149914644469}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:03,757] Trial 481 finished with value: 30.469489958217938 and parameters: {'n_estimators': 596, 'max_depth': 23, 'learning_rate': 0.5659012758557003, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6744875311807962}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:04,200] Trial 482 finished with value: 39.175552441023065 and parameters: {'n_estimators': 567, 'max_depth': 22, 'learning_rate': 0.6209383561583589, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.6811373404129162}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:04,639] Trial 483 finished with value: 41.486525914108924 and parameters: {'n_estimators': 562, 'max_depth': 22, 'learning_rate': 0.4769207581710851, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6903428469847377}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:05,080] Trial 484 finished with value: 39.043025628101574 and parameters: {'n_estimators': 527, 'max_depth': 23, 'learning_rate': 0.654774618013559, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.6713354105848831}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:05,614] Trial 485 finished with value: 55.65885896719797 and parameters: {'n_estimators': 584, 'max_depth': 22, 'learning_rate': 0.8533088592864018, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6574445599132496}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:06,050] Trial 486 finished with value: 38.85157425986142 and parameters: {'n_estimators': 598, 'max_depth': 22, 'learning_rate': 0.5665957688933676, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.6733187151439138}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:06,456] Trial 487 finished with value: 27.91226257935208 and parameters: {'n_estimators': 550, 'max_depth': 23, 'learning_rate': 0.7192540586395877, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6968345734136294}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:06,910] Trial 488 finished with value: 36.74752574208712 and parameters: {'n_estimators': 643, 'max_depth': 22, 'learning_rate': 0.8557248014216488, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.689718236086295}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:07,384] Trial 489 finished with value: 44.29148428706517 and parameters: {'n_estimators': 620, 'max_depth': 23, 'learning_rate': 0.9946471443572741, 'min_samples_split': 6, 'min_samples_leaf': 7, 'subsample': 0.645081949802641}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:07,816] Trial 490 finished with value: 26.53965167388806 and parameters: {'n_estimators': 599, 'max_depth': 22, 'learning_rate': 0.7652817847899361, 'min_samples_split': 7, 'min_samples_leaf': 6, 'subsample': 0.6612499118466735}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:08,268] Trial 491 finished with value: 43.40189464864207 and parameters: {'n_estimators': 594, 'max_depth': 22, 'learning_rate': 0.6498161321665754, 'min_samples_split': 5, 'min_samples_leaf': 7, 'subsample': 0.651166720516198}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:08,688] Trial 492 finished with value: 30.723255926942198 and parameters: {'n_estimators': 578, 'max_depth': 21, 'learning_rate': 0.7975870350097081, 'min_samples_split': 8, 'min_samples_leaf': 6, 'subsample': 0.6681208229752872}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:09,143] Trial 493 finished with value: 28.588614775656666 and parameters: {'n_estimators': 541, 'max_depth': 23, 'learning_rate': 0.538663648067444, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6661489715481675}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:09,616] Trial 494 finished with value: 42.05071191193404 and parameters: {'n_estimators': 610, 'max_depth': 22, 'learning_rate': 0.428886114943658, 'min_samples_split': 7, 'min_samples_leaf': 5, 'subsample': 0.6656182453664702}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:10,042] Trial 495 finished with value: 41.920380049544846 and parameters: {'n_estimators': 596, 'max_depth': 21, 'learning_rate': 0.707058989076175, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.635160636990236}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:10,461] Trial 496 finished with value: 28.455186111656445 and parameters: {'n_estimators': 562, 'max_depth': 23, 'learning_rate': 0.8565884500375593, 'min_samples_split': 5, 'min_samples_leaf': 6, 'subsample': 0.6809648796661593}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:10,906] Trial 497 finished with value: 38.07328692560857 and parameters: {'n_estimators': 576, 'max_depth': 24, 'learning_rate': 0.6135261451452676, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.6597119342181414}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:11,397] Trial 498 finished with value: 36.901118443572045 and parameters: {'n_estimators': 626, 'max_depth': 21, 'learning_rate': 0.7705577911279182, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6414435132995266}. Best is trial 299 with value: 21.667207188919914.\n",
      "[I 2024-08-30 22:47:11,832] Trial 499 finished with value: 47.77939814907597 and parameters: {'n_estimators': 606, 'max_depth': 22, 'learning_rate': 0.8774489770518994, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.6566638698554292}. Best is trial 299 with value: 21.667207188919914.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'n_estimators': 656, 'max_depth': 21, 'learning_rate': 0.9976202996087893, 'min_samples_split': 6, 'min_samples_leaf': 6, 'subsample': 0.6823449477673802}\n",
      "Best score:  21.667207188919914\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to be tuned\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1.0, log=True)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "\n",
    "    # Create the model with the suggested hyperparameters\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        subsample=subsample,\n",
    "        random_state=42\n",
    "    ).fit(X_train,y_train)\n",
    "    predictions=model.predict(X_test)\n",
    "\n",
    "    tahminler=pd.DataFrame()\n",
    "    tahminler[\"Hedef Fiyat\"]=hisse[\"Close\"][-13:-2]*(1+(predictions[:-1]/100))\n",
    "    tahminler[\"Gerçekleşen Fiyat\"]=hisse[\"Close\"].loc[\"2022-03-31\":].values\n",
    "\n",
    "    return np.sqrt(mean_squared_error(tahminler[\"Gerçekleşen Fiyat\"][:-1],tahminler[\"Hedef Fiyat\"][:-1]))\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best score: \", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "params=study.best_params\n",
    "model = GradientBoostingRegressor(**params,random_state=42\n",
    "    ).fit(X_train,y_train)\n",
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hedef Fiyat</th>\n",
       "      <th>Gerçekleşen Fiyat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>37.65</td>\n",
       "      <td>37.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>43.57</td>\n",
       "      <td>46.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>57.94</td>\n",
       "      <td>60.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>71.25</td>\n",
       "      <td>86.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>89.94</td>\n",
       "      <td>77.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>129.08</td>\n",
       "      <td>80.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>125.26</td>\n",
       "      <td>120.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>104.74</td>\n",
       "      <td>112.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30</th>\n",
       "      <td>181.89</td>\n",
       "      <td>165.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>200.58</td>\n",
       "      <td>240.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-31</th>\n",
       "      <td>246.28</td>\n",
       "      <td>254.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Hedef Fiyat  Gerçekleşen Fiyat\n",
       "Date                                      \n",
       "2021-09-30        37.65              37.04\n",
       "2021-12-31        43.57              46.13\n",
       "2022-03-31        57.94              60.60\n",
       "2022-06-30        71.25              86.55\n",
       "2022-09-30        89.94              77.17\n",
       "2022-12-31       129.08              80.48\n",
       "2023-03-31       125.26             120.10\n",
       "2023-06-30       104.74             112.70\n",
       "2023-09-30       181.89             165.30\n",
       "2023-12-31       200.58             240.03\n",
       "2024-03-31       246.28             254.32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tahminler=pd.DataFrame()\n",
    "tahminler[\"Hedef Fiyat\"]=hisse[\"Close\"][-13:-2]*(1+(predictions[:-1]/100))\n",
    "tahminler[\"Gerçekleşen Fiyat\"]=hisse[\"Close\"].loc[\"2022-03-31\":].values\n",
    "tahminler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Q</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>32.64</td>\n",
       "      <td>37.44</td>\n",
       "      <td>32.10</td>\n",
       "      <td>37.32</td>\n",
       "      <td>37.32</td>\n",
       "      <td>54643293</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>37.60</td>\n",
       "      <td>39.78</td>\n",
       "      <td>37.60</td>\n",
       "      <td>38.24</td>\n",
       "      <td>38.24</td>\n",
       "      <td>52294851</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-17</th>\n",
       "      <td>38.40</td>\n",
       "      <td>39.90</td>\n",
       "      <td>35.80</td>\n",
       "      <td>37.02</td>\n",
       "      <td>37.02</td>\n",
       "      <td>37112636</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-24</th>\n",
       "      <td>36.96</td>\n",
       "      <td>38.46</td>\n",
       "      <td>34.02</td>\n",
       "      <td>37.06</td>\n",
       "      <td>37.06</td>\n",
       "      <td>39157071</td>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-31</th>\n",
       "      <td>37.56</td>\n",
       "      <td>37.60</td>\n",
       "      <td>34.64</td>\n",
       "      <td>34.64</td>\n",
       "      <td>34.64</td>\n",
       "      <td>23987293</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-29</th>\n",
       "      <td>273.75</td>\n",
       "      <td>274.75</td>\n",
       "      <td>258.75</td>\n",
       "      <td>263.50</td>\n",
       "      <td>263.50</td>\n",
       "      <td>11248361</td>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>237.50</td>\n",
       "      <td>260.00</td>\n",
       "      <td>237.50</td>\n",
       "      <td>243.70</td>\n",
       "      <td>243.70</td>\n",
       "      <td>11934025</td>\n",
       "      <td>2024-08-05</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-12</th>\n",
       "      <td>245.00</td>\n",
       "      <td>247.50</td>\n",
       "      <td>231.50</td>\n",
       "      <td>236.70</td>\n",
       "      <td>236.70</td>\n",
       "      <td>10383823</td>\n",
       "      <td>2024-08-12</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-19</th>\n",
       "      <td>236.70</td>\n",
       "      <td>245.50</td>\n",
       "      <td>234.10</td>\n",
       "      <td>235.50</td>\n",
       "      <td>235.50</td>\n",
       "      <td>7178865</td>\n",
       "      <td>2024-08-19</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-26</th>\n",
       "      <td>235.50</td>\n",
       "      <td>249.90</td>\n",
       "      <td>231.90</td>\n",
       "      <td>249.90</td>\n",
       "      <td>249.90</td>\n",
       "      <td>10235725</td>\n",
       "      <td>2024-08-26</td>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close  Adj Close    Volume       Date  Q  \\\n",
       "Date                                                                        \n",
       "2022-01-03  32.64  37.44  32.10  37.32      37.32  54643293 2022-01-03  1   \n",
       "2022-01-10  37.60  39.78  37.60  38.24      38.24  52294851 2022-01-10  1   \n",
       "2022-01-17  38.40  39.90  35.80  37.02      37.02  37112636 2022-01-17  1   \n",
       "2022-01-24  36.96  38.46  34.02  37.06      37.06  39157071 2022-01-24  1   \n",
       "2022-01-31  37.56  37.60  34.64  34.64      34.64  23987293 2022-01-31  1   \n",
       "...           ...    ...    ...    ...        ...       ...        ... ..   \n",
       "2024-07-29 273.75 274.75 258.75 263.50     263.50  11248361 2024-07-29  3   \n",
       "2024-08-05 237.50 260.00 237.50 243.70     243.70  11934025 2024-08-05  3   \n",
       "2024-08-12 245.00 247.50 231.50 236.70     236.70  10383823 2024-08-12  3   \n",
       "2024-08-19 236.70 245.50 234.10 235.50     235.50   7178865 2024-08-19  3   \n",
       "2024-08-26 235.50 249.90 231.90 249.90     249.90  10235725 2024-08-26  3   \n",
       "\n",
       "            Year  \n",
       "Date              \n",
       "2022-01-03  2022  \n",
       "2022-01-10  2022  \n",
       "2022-01-17  2022  \n",
       "2022-01-24  2022  \n",
       "2022-01-31  2022  \n",
       "...          ...  \n",
       "2024-07-29  2024  \n",
       "2024-08-05  2024  \n",
       "2024-08-12  2024  \n",
       "2024-08-19  2024  \n",
       "2024-08-26  2024  \n",
       "\n",
       "[139 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hisse=yf.download(tickers=\"TAVHL.IS\",start=\"2022-01-01\",interval=\"1wk\")\n",
    "hisse[\"Date\"]=pd.to_datetime(hisse.index)\n",
    "hisse[\"Q\"]=hisse[\"Date\"].dt.quarter\n",
    "hisse[\"Year\"]=hisse[\"Date\"].dt.year\n",
    "hisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisse[\"Hedef\"]=0\n",
    "hisse[\"Hedef\"].loc[(hisse.index<tahminler.index[2]) & (hisse.index>tahminler.index[1])]=tahminler[\"Hedef Fiyat\"].iloc[0]\n",
    "hisse[\"Hedef\"].loc[(hisse.index<tahminler.index[2]) & (hisse.index>tahminler.index[1])]=tahminler[\"Hedef Fiyat\"].iloc[0]\n",
    "for i in range(3,len(tahminler)):\n",
    "    hisse[\"Hedef\"].loc[(hisse.index<tahminler.index[i]) & (hisse.index>tahminler.index[i-1])]=tahminler[\"Hedef Fiyat\"].iloc[i-2]\n",
    "hisse[\"Hedef\"].loc[\"2024-04-01\":\"2024-06-30\"]=tahminler[\"Hedef Fiyat\"].iloc[-2]\n",
    "hisse[\"Hedef\"].loc[\"2024-07-01\":]=tahminler[\"Hedef Fiyat\"].iloc[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeni=pd.DataFrame({\"Hedef\":[tahminler[\"Gerçekleşen Fiyat\"].iloc[-2]*(1+(predictions[-1]/100))]})\n",
    "yeni = pd.concat([yeni] * 17, ignore_index=True)\n",
    "yeni=yeni.set_index(pd.date_range(start=\"2024-09-01\",freq=\"W\",periods=len(yeni)))\n",
    "yeni.loc[\"2024-09-01\":\"2024-09-30\"]=hisse[\"Hedef\"].iloc[-1]\n",
    "yeni=pd.concat([hisse[\"Hedef\"].loc[\"2024-07-01\":],yeni],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x210ae42ff70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFMAAAKzCAYAAADSsEIpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADGbElEQVR4nOzdd5xU5dn/8e+Z2ZntHdil7NJRqUIsgAUVbIC9xsSWPLHnJzEPMTExlliixqgxiiUmivGxxRbFaBAsdMUCCtjodSnL9jKzM+f3B+7Kcu7Z3Vl2dmZ2Pu/Xy5dyz5mZezmAO1+u+7qssrIyWwAAAAAAAGgTV7Q3AAAAAAAAEE8IUwAAAAAAAMJAmAIAAAAAABAGwhQAAAAAAIAwEKYAAAAAAACEgTAFAAAAAAAgDIQpAAAAAAAAYSBMAQAAAAAACANhCgAAAAAAQBgIUwAAAAAAAMJAmBID6urqtGbNGtXV1UV7KwiBexQ/uFfxg3sV+7hH8YX7FT+4V/GB+xQ/uFfxoyvdK8KUGBEIBKK9BbSCexQ/uFfxg3sV+7hH8YX7FT+4V/GB+xQ/uFfxo6vcK8IUAAAAAACAMBCmAAAAAAAAhIEwBQAAAAAAIAyEKQAAAAAAAGEgTAEAAAAAAAgDYQoAAAAAAEAYkqK9gWgKBoOqrq6O+ozrYDAor9er8vJyVVZWRnUvMIvVe5SSkqL09HS5XOSiAAAAANBZEjZMCQaD2rVrlzIyMtStWzdZlhXVvfh8Pnm9Xj4Ux6hYvEe2bauurk67du1Sfn5+zOwLAAAAALq6hP30VV1drYyMDKWmpkY1SAHay7IspaamKiMjQ9XV1dHeDgAAAAAkjIQNU+rq6pSSkhLtbQD7LSUlJepH1QAAAAAgkSRsmCKJihR0Cfw6BgAAAIDOldBhCgAAAAAAQLgIUwAAAAAAAMJAmAIAAAAAABAGwhSE5corr1ROTo7Wr18f7a10qClTpignJyfa2wAAAAAAxAHClAS0fv165eTk6Kyzzgp5zbx585STk6Nf/OIXnbizjtcY/oT659e//nXU9paTk6MpU6ZE7f0BAAAAAO2TFO0NIL7cdNNN+sUvfqFevXpFeythufDCC417PvTQQyVJjzzyiGprazt7WwAAAACAOESYgrAUFhaqsLAw2tsI20UXXdQUnJgUFRV14m4AAAAAAPGMYz4IS6ieKa+99pomT56sQYMGqaCgQAceeKBOO+00vfbaa82u++CDD3T22WfrwAMPVI8ePTR48GCdfPLJevLJJx3vtW7dOv385z/X8OHD1aNHDx1wwAG68sortWHDhg7/uvbtmTJz5kzl5OTogQceMF7//vvvKycnR9OmTWta++CDD3T11VfrkEMOUe/evdW7d28dc8wxjq+t8QiVJC1YsKDZsaNnnnmm2TV33nlnR36ZAAAAAIAOQGWKwfFvbO/U97Ml2UFblsuS1cq1s6f26IwtheWJJ57QL3/5SxUWFmrq1KnKy8tTSUmJPvnkE82aNUunnXaaJOntt9/W+eefr+zsbE2ePFmFhYXauXOnvvjiCz3//PO65JJLml5z6dKlOvPMM1VTU6MTTzxRAwcO1IYNG/Tiiy/qnXfe0ezZs9WvX7+IfU1nnXWWfve73+npp5/Wtdde63h85syZkqSLL764ae2BBx7QmjVrdOihh6pXr14qLy/XO++8o2nTpumbb77R7bffLkkqLi7W9ddfr7vuuktFRUW64IILml5jxIgREfuaAAAAAAAdgzDF4KMd/mhvoVOsWbMmZOVDONUfM2fOlNfr1bx589S9e/dmj5WWljb99z//+U/Ztq3XX3/dERrsfZ3f79dPfvIT2batOXPmaNSoUU2PLVq0SFOnTtX111+v559/Pqw9vvPOO83WUlJSQjbYTU9P1znnnKMnnnhC8+fP1/jx45se2717t9544w2NGDFCo0ePblq/9957HQFPQ0ODzjnnHD3yyCO64oorVFRUpL59++o3v/mN7rrrLhUXF+s3v/lNm78OAAAAAED0EaYksLVr1+quu+7qkNfyeDzyeDyO9by8PMdaampqi9e99dZb2rBhg2644YZmQYokjRs3TpMnT9asWbNUUVGhrKysNu3v6aefdqxlZWW1OK3o0ksv1RNPPKGZM2c2C1Oee+451dfXN6tKkWSslElKStKll16qd999V/PmzWtWhQIAAAAAiE9hhyl1dXW69dZb9emnn2rt2rXavXu3srOz1b9/f1144YU677zzHB+qKyoq9Mc//lH//ve/tX37dhUUFOj000/X9ddfr4yMDMd7BINBPf7443rqqae0Zs0apaen65hjjtGNN94Y0aMdiWbixIl66aWXjI/NmzdPp5xySpte56yzztLvf/97jRs3TmeffbaOOuoojR071hF0nHXWWXr99dc1adIknXPOOTr66KM1fvx45efnN7tu6dKlkqRvv/3WWDmzfft2BYNBrV69ulllSEtmz57dYgNak+HDh+vQQw/Vv//9b911111NIdDTTz+ttLQ0nXPOOc2ur6ys1IMPPqhZs2Zp3bp1qq6ubvb4tm3bwnp/AAAAADGuoVKumnXR3kXMsL3dZafE38CS9gg7TKmurtbf//53jRkzRieccIK6deumsrIyzZ49W9dcc41efvll/etf/5LL5Wq6fsqUKfr888913HHH6eyzz9by5cv14IMPasGCBXrzzTeVkpLS7D2mTZummTNn6qCDDtLll1+urVu36tVXX9XcuXP1zjvvaODAgR3z1aND/PznP1dubq7+/ve/669//asefPBBJSUl6YQTTtAdd9zRFICdfvrpeuaZZ/TQQw/p73//ux5//HFZlqWjjjpKt912m0aOHClpzzEaSXrhhRdafN99w4pIuOSSS3T11VfrhRde0MUXX6ylS5dq5cqV+uEPf6js7Oym63w+n6ZOnaply5Zp5MiROu+885SXlye3260NGzbo2WefVX19fcT3CwAAAKAT2EGlrPyNvOufkGU3RHs3MaNu4DTVH3hztLfRKcIOU3Jzc7VhwwZ5vd5m6w0NDTr99NM1d+5czZ49WyeeeKKkPU05P//8c02bNk0333xz0/U333yz7r//fj388MO67rrrmtY/+OCDpmMVr776atP7nHPOOTrnnHM0ffp0vfzyy+35Wtvs0O7O4yqRFE4D2lhkWZYuvPBCXXjhhSotLdXChQv10ksv6ZVXXtGaNWu0YMECud1uSXum5kyZMkWVlZVasmSJXn/9dT399NM6++yz9eGHHyonJ0eZmZmS9hynOemkk6L5penMM8/UDTfcoKeffloXX3xx03GhfY/4vPnmm1q2bJkuvPBCPfjgg80ee+mll/Tss8922p4BAAAARJZny7+UvO7RaG8DURR2mOJyuRxBirSnN8TUqVM1f/58rVmzRpJk27aefvppZWRkaPr06c2unz59uv72t79p5syZzcKUxikpv/3tb5u9z/HHH68jjzxSc+fO1caNG1VUVBTu1tussyfmBINB+Xw+eb3epoqeeJWXl6epU6dq6tSp2rVrlz744AOtWbNGgwcPbnZdZmamJk2apEmTJikQCOif//ynPv74Y02cOFGHHHKIJOmjjz6KepiSmpqq888/X48++qjmz5+vV155RQcccIDGjh3b7Lq1a9dKkiZPnux4jUWLFhlf2+VyKRgMdvymAQAAAERU0vZ3Wr8IXVqHfXIPBoOaM2eOJGno0KGSpNWrV2vr1q06/PDDlZ6e3uz69PR0HX744Vq3bp02bdrUtD5//nylp6c7PqxKe3p8SNKCBQs6atvoAPPmzZNt283W/H5/03Gd5ORkSXvuWyAQcDx/x44dza6bPHmy+vTpo4ceesh4r/1+f8iAIhIuvfRSSdI111yjqqoqXXTRRY5rGsO9xYsXN1ufP3++nnrqKePr5ubmavPmzR28WwAAAACRZvl3RXsLiLJ2T/Px+Xy69957Zdu2du/erffff19ff/21fvSjH2nChAmS9oQpkjRgwADjawwYMEBz5szR6tWr1adPH1VXV2vbtm0aOnRo07GQfa/f+3VbUldX1+LjwWAwZqoCGoMI27Y7ZU9teb/Wrtl7/Uc/+pEyMzN1yCGHqKioSH6/X++9956++uornXrqqerTp4+CwaCuv/56bdu2TWPHjlVRUZEsy9LixYv1ySef6JBDDtHhhx+uYDAoj8ejJ598Uueee66mTJmio48+WgcddJAsy9KmTZu0aNEi5eXlacmSJW3+mtt6v03XDBkyROPGjdOiRYuUnJys8847z3HdCSecoOLiYj3wwANauXKlDjroIH377bd6++23NWXKFP373/92/FweddRRevXVV3XBBRdoxIgRcrvdOvnkkzVs2LCwf00Eg8FWf80nCp/P1+zfiF3cq9jHPYov3K/4wb2KD9yn+BGNe5Xqq+i094ongYaGFj+XxOrvq337uLbFfoUpe4/VtSxLP//5z3XTTTc1rVVU7PkFtnejzr01TntpvK7x36HG3e57fUu2bNlirIJo5PV6Y+4G+v3+Tnmfxq/btu2QPweNe2k8gtSo8efU5/M1rd9www1699139fHHH+vtt99WWlqa+vbtq7vuuksXXHBB03XXXHON3nzzTS1fvlxz5syRx+NRUVGRfve73+nSSy9VIBBoev3hw4drzpw5evjhhzVnzhwtWbJEXq9XhYWFOumkk3TGGWe06f41vl5DQ0OL1zcGFqGuOeecc7Ro0SKdfPLJysjIcFzn9Xr14osv6tZbb9XixYs1f/58HXDAAXrooYfUvXt3/fvf/1YgEGj2vFtvvVXBYFDz58/XW2+9pWAwqB49emjw4MFNP//7PieUurq6Nv2+SCQlJSXR3gLaiHsV+7hH8YX7FT+4V/GB+xQ/OvNeZdbu1r7NL2q9/bUt11nFnkhq7YGq2bix1eti6feV2+0OWQDSknaHKRkZGSorK1MwGNTWrVv11ltv6dZbb9VHH32kF154IWQg0ll69erV4uPl5eXG3i/RYNu2/H6/PB6PLCvyLWgHDRqk0tLSFq859thjjdc88sgjeuSRR5qtXXbZZbrssstafd9zzz1X5557bpv32RjI7A/Tfk1mzZrV4uMrVqyQtKfxbKhfN4MHD25qULsv089lnz599OSTTxqvD/XzH0pKSooKCgrafH1X5vP5VFJSooKCgpj5PQ4z7lXs4x7FF+5X/OBexQfuU/yIxr1K3uCc1OnKGqy04Vd2yvvHqjRJ+S083pV+X7U7TGnkcrnUu3dv/fSnP1V+fr4uueQS3XvvvbrllluaApXy8nLjc/etRGmt8qS1ypW9tVamU1lZGTPNXhurIizLipk94Xs7d+7U888/r0GDBunoo4+OyXvkcrnaVZrWlXm9Xn5O4gT3KvZxj+IL9yt+cK/iA/cpfnTmvbIC1c41bza/VtqoK/y+2u8wZW/HHnuspD1NNyVp4MCBktQ03WdfjeuN16Wnp6uwsFDr169XIBBw9E3Z93ogkt5++20tW7ZMr732mqqqqvS///u/nVI5BAAAACC2WYEqx5qdlBGFnSBaOvSv2Ldt2yZJ8ng8kvaEHj179tSSJUtUXd08uauurtaSJUvUt29f9enTp2n9iCOOUHV1tWMqiqSmaUHjx4/vyG0DRq+++qruuOMOlZaW6sYbb9Tpp58e7S0BAAAAiLZAvaygoa8hYUpCCTtM+fLLL1VTU+NYr6mp0W9/+1tJ0vHHHy9pz7GVCy+8UFVVVbrnnnuaXX/PPfeoqqpKF198cbP1xh/ffvvtzRpvzp49W/Pnz9dxxx2n4uLicLcNhG3GjBkqKyvTqlWr9Itf/CLa2wEAAAAQA0xVKRKVKYkm7GM+r7zyih5++GGNHTtWxcXFyszM1JYtW/TOO++otLRU48aN01VXXdV0/bXXXqs333xT999/v5YvX65Ro0Zp2bJlmjt3rsaMGaMrr2zeoOfoo4/WRRddpJkzZ2rChAk64YQTtG3bNr3yyivKzc3V3Xffvf9fNQAAAAAA7dFQaVy2kzI7eSOIprDDlJNOOknbtm3Thx9+qA8//FDV1dXKysrSsGHDdNZZZ+nHP/6xkpK+f9n09HTNmjVLf/zjH/X6669r3rx5Kigo0DXXXKPrr79eqampjve4//77NXToUD311FN65JFHlJ6erqlTp+rGG29U//799+8rBgAAAACgnayGEJUpbipTEknYYcro0aM1evTosJ6TnZ2tO++8U3feeWebrne5XLriiit0xRVXhLs9AAAAAAAiJlSYIipTEkrszXgFAAAAACBGhaxMoWdKQiFMAQAAAACgrWhACxGmAAAAAADQZlbIBrSEKYmEMAUAAAAAgDYKHabQMyWREKYAAAAAANBGIRvQMs0noRCmAAAAAADQRqEb0FKZkkgIUxA1V155pXJycrR+/fr9ep2Kigpdf/31GjlypLp166acnBwtX758v/e3fv165eTk6Morr9zv1wIAAADQRRjCFNvySO7kKGwG0UKYkoAaQ4Kzzjor5DXz5s1TTk6OfvGLX3Tiztrnpptu0qOPPqqDDjpI06ZN0/XXX6+CgoIWn5OTk9PiPx0RxrTHM888o5ycHD3zzDNReX8AAAAALTNVptB8NvEkRXsDwP56++23NWjQID3//PNhPS8vL08/+9nPjI8VFBQoLy9PH374obKysjpimwAAAAC6ACtgaEBLmJJwCFMQ97Zu3arx48eH/bz8/Hz95je/afGaIUOGSJKCwWC79gYAAACgazFXptAvJdFwzAdhq6ys1B133KGxY8eqsLBQxcXFOvPMM7Vo0SLj9atWrdJ5552nPn36qLi4WOecc45WrlzZ4nvMmjVLp556qvr27auCggKNGzdODz74oAKBQNM1jT1XbNvWggULmo7oTJkypUO+TlPPlJNPPln5+fnatm2b8TmXX365cnJy9OGHH0qSfD6fHn30UZ155pkaNmyYevTooUGDBunHP/6xli1b1uy5V155pa6++mpJ0tVXX93s2BEAAACAGGEKU5jkk3CoTDFIX3B8J7+jrWDQlstlSbJavLL6iNmds6UQdu/ercmTJ2vVqlUaO3asLr30UlVWVurNN9/UKaecoieffFJTp05tun7lypU66aSTVFVVpVNOOUUDBw7Uxx9/rJNOOknDhg0zvsctt9yi++67T7169dIpp5yirKwsLVq0SDfeeKOWLl2qp556SpI0ZcoUFRcX66677lJRUZEuuOACSVJxcXHEvv5LLrlES5Ys0TPPPKNf/vKXzR4rKyvTv//9bx100EE67LDDJO35+frNb36jcePG6fjjj1dOTo7WrVun//znP3rnnXf05ptvasyYMU1fT3l5ud58801NnjxZI0aMiNjXAQAAAKB9rAbnMR96piQewhSDpLKPor2FTrFmzRrdeeedxsc2bNhgXP/Vr36lVatW6S9/+YsuuuiipvUdO3bo2GOP1bRp0zRp0iSlpKRIkqZPn66Kigo99thjOvfcc5uuv/XWW/XnP//Z8frvvvuu7rvvPk2cOFEzZ85Uenq6JMm2bf3yl7/U3//+d7322ms67bTTNHXqVE2dOlV33XWXiouLWz2ys69du3YZv/5DDz1UkyZNMj7ntNNO0w033KCnn35a1113nSzr+/DrxRdfVG1tbbOfl5ycHH3xxRfq1atXs9dZtWqVjj/+eN1666169dVXJUlTp05tClOmTJmiH/3oR2F9PQAAAAAizzgamWM+CYcwJYGtXbtWd911V5uv37Vrl15++WUdffTRzQIDSerevbt+/vOf6/rrr9d7772nk046SRs3btSCBQs0bNiwZkGKJF133XV64oknVF5e3mz9sccekyTdf//9TUGKJFmWpZtuukn/+Mc/9NJLL+m0004L98t1KC0tNX79V1xxRcgwJSUlRT/84Q/18MMP64MPPtCECROaHnv66aeVnJys888/v2ktOTnZEaRI0kEHHaQjjzxSc+fOld/vl8fj2e+vBwAAAEDkMc0HEmFKQps4caJeeukl42Pz5s3TKaec0mztk08+USAQkM/nM1Z0rFmzRpL0zTff6KSTTtIXX3whSRo3bpzj2oyMDI0YMULz589vtr506VKlp6frn//8p3Ffqamp+uabb1r/4tpg8ODB+uij8KuQLrnkEj388MN66qmnmsKUzz77TMuXL9c555yj3NzcZtcvX75cf/nLX7R48WKVlJTI7/c3e3zXrl0qLCxs/xcCAAAAoHPYQVkBwhQQpiAMu3fvliQtXrxYixcvDnlddXW1JKmiokKS1K1bN+N1PXr0ML5HQ0NDixUzja8fLUOGDNERRxyhWbNmqbS0VHl5eZo5c6YkOSp2lixZolNPPVWSdOyxx+q0005Tenq6LMvSrFmz9MUXX6i+vr7TvwYAAAAA7RAwfxZhmk/iIUwxaMg5tJPfse0NaKMpM3PPHxDXXHONbrvttlavz8rKkiTt3LnT+Pj27duN72FZVlOVS6z6yU9+ogULFujZZ5/VpZdeqn/9618aOHCgjjrqqGbX3Xvvvaqvr9d//vMfR4XO0qVLm6p3AAAAAMQ+Y78UUZmSiAhTDDp7Yk4wGJTP55PX65XLFbvTqseMGSPLstp8NGb48OGSZByZXFVVpc8//9yxfsghh2j27NlavXq1Bg4cuH8bjqBTTjlF3bp109NPP63c3FxVVFQ4pvtIe/rS5ObmOoKUmpoax2hkSXK73ZLUbAQ0AAAAgNgQKkwRo5ETTux+ckfMKSgo0BlnnKElS5boL3/5i2zbdlyzdOlS1dTUSJKKioo0fvx4rVixQi+88EKz6/785z87ms9K0uWXXy5pT/VLaWmp4/GSkhJ99dVXHfHl7Bev16sLLrhAX375pf7whz/I4/E0jWbeW1FRkcrKyrRq1aqmtUAgoBtvvNFYsdPYb2Xz5s2R2zwAAACAdjGNRZaoTElEVKYgLPfee6+++eYb/f73v9dzzz2nww47TNnZ2dq8ebM+/fRTrV69Wl999ZXS0tIkSX/605900kkn6YorrtCsWbM0cOBAffzxx/r00081btw4R9XKpEmTNH36dN1zzz0aPXq0Jk2apKKiIpWWlmrNmjVatGiRfve73+mAAw6IxpffzKWXXqoHH3xQW7du1amnnqru3bs7rrnssss0d+5cnXTSSTrjjDOUnJys+fPna+vWrTryyCMdDXgPO+wwpaamasaMGSorK2vqNzN9+vRO+ZoAAAAAtIAwBd+hMgVhyc3N1X//+1/deuut8nq9evHFF/XYY4/po48+0oEHHqhHHnlE+fn5TdcPHTpUb731liZNmqQ5c+bo8ccfl9fr1VtvvaV+/foZ3+O3v/2tXn31VY0bN07vv/++HnroIb399tvy+Xz69a9/rXPOOaeTvtqW9e/fX2PHjpUkXXzxxcZrTjrpJD311FPq16+fXnjhBf3rX//SkCFDNHfuXBUVFTmuz83N1VNPPaVBgwZp5syZuv3223X77bdH9OsAAAAA0Dahe6bQgDbRWGVlZc6zGglgx44dxkqCaIiXnimJzHSP6urqNHToUKWnp2vZsmVRvXex9Os52urq6rRx40YVFRUpJSUl2ttBC7hXsY97FF+4X/GDexUfEv0+1TbYemhFlVbt9uuonsk6b2CaUpNic1hGZ94rz6bnlbbscsd61RFzFcgZE9H37gq60u8rjvkA7fTMM8+otLRU11xzDSEYAAAAugxfwNbZs3dqwTafJOmltbVausOnvx6ZG+WdRZ8VYJoP9iBMAcJ03333aefOnXryySfVvXt3/fSnP432lgAAAIAOM2NlVVOQ0uif39To6mEZOijXE6VdxQhGI+M7hClAmG655RZ5PB4NHz5cd999t7Kzs6O9JQAAAKBDbKkO6J7PzE1W395Yl/BhSshpPoxGTjiEKUCYysrKor0FAAAAICJuWlquqgZzW83Zm+s0bWRiN1oN1YBWVKYkHBo9AAAAAAC0cFu9XlxTG/LxxSU+lfuCnbij2GOqTLHd6ZLFR+tEwx0HAAAAgAQXCNr61ZLylq+xpfe21HfSjmKTqTKFsciJiTAFAAAAABLcP76q1hel/lav+++muk7YTQwzTPOh+WxiSugwxbbNZwGBeMKvYwAAAOyPXXUB3fZJRZuufWdTXUJ//2muTCFMSUQJG6akpKSori7BU1V0CXV1dUpJSYn2NgAAABCn/vBxhcp8bQtISmqDWt6GCpauyjjNh0k+CSlhw5T09HRVVVWptrY2oZNVxC/btlVbW6uqqiqlp6dHezsAAACIQ5/t9Ompr2uMj11+kPl7zNmbErdvCpUpaJSwo5FdLpfy8/NVXV2tnTt3RnUvwWCwqbrA5UrYfCumxeo9SklJUX5+fkztCQAAAPEhaNuavrhMpr9aPqVvin7/gyz946tq7TvA551NdfrfUQnadJUGtPhOwoYp0p5AJTMzU5mZ0f3FX1dXp4qKChUUFHBcI0ZxjwAAANDVLCzx6aMdziM7KW7p9sOyle5x6YjCZL27zwSfD3f4tLs+qNzkxPsLPeNoZCpTElLi/eoHAAAAAGj+VvNxnV+MzFRxxp6/dz++j/MvEoO2NHdzAvafDNTLsg39YghTEhJhCgAAAAAkoI3VAceaxyX9v+HfV+4f3yfZ+NzZCTgi2TKMRZY45pOoCFMAAAAAIAFtrHKGKX3S3UpNspp+PCgrSf0y3Y7r3tlcr2CiDfIwTfIRx3wSFWEKAAAAACSgDVUNjrWijOZtNS3LMh712VkX1Gc7E2tEsmmSjyTZjEZOSIQpAAAAAJBggratzYZjPkUZziqU43ubBzD8N8GO+oQKU8Qxn4REmAIAAAAACWZbTVD+oHO9KN0ZphzZ06sU57LeSbAmtCErUzjmk5AIUwAAAAAgwWw0HPGRpGJDZUpakktHFTob0X68w6+ddc7qli4rZANawpRERJgCAAAAAAlmg6H5rOTsmdJokqFvii1pzmbzeOWuyPJXGNcJUxITYQoAAAAAJBjTWGTJ3DNFkrEJrSS9k0B9UxiNjL0RpgAAAABAgjEd83FZUm9DzxRJGpCVpEFZzqqVdzbXKRBMjBHJNKDF3ghTAAAAACDBbDQc8+mV5pbHZYV8zqQ+zr4pu+ttfbzT16F7i1WMRsbeCFMAAAAAIMGYeqaEOuLT6IQQR33mb0uMMEWGMMW2PJLbGTKh6yNMAQAAAIAEYtu2sTLFNBZ5b+MKkuU1fIJcuC0xmtCaKlNoPpu4CFMAAAAAIIHsqg+qNuDsc9JaZUpqkqUfdPc61heX+NSQAH1TrEClc5EwJWERpgAAAABAAtlQaZ7kUxxiLPLejihwHmmparD1eal/v/cV6yy/M0xhkk/iIkwBAAAAgAQS7ljkvY0vdFamSNL8RDjqYxiNTPPZxEWYAgAAAAAJZINhLLLUtjDlsB5euQ0DfxYmQBNaY88UD5UpiYowBQAAAAASiKn5rCT1SW/9mE+Gx6WD8z2O9UUl9QraXbtvinE0MpUpCYswBQAAAAASiGksco9Ul1KTDCUnBkcUOvumlPlsrdxtrnjpKpjmg70RpgAAAABAAtloOObT2ljkvYXqm7KgK/dNsYOyTD1TCFMSFmEKAAAAACQQUwPaojZM8mk0tkeyTDUsC0u6cJgSqDYuM80ncRGmAAAAAECCKKsPqsLn7G3SluazjXKSXRqe5+ybsnCbT3YX7Zti7JciKlMSGWEKAAAAACSIUGORi8MIUyTpCMNRnx11QX1T3jX7plgNleYHaECbsAhTAAAAACBBmPqlSOFVpkjS+AJnE1pJWtBFRyRTmYJ9EaYAAAAAQIIINRa5qA1jkfcWqgltl+2bEqIyhZ4piYswBQAAAAASRMgwJczKlG4pbh2Y4wxgFmyr75J9U6hMwb4IUwAAAAAgQWwwHPPJ9lrK8ob/0fCIQudRny01Qa0PEdjEs1BhiqhMSViEKQAAAACQIEwNaIvDGIu8t/EF5qM+87d1vaM+VoDKFDRHmAIAAAAACcJ0zCfcIz6NxhsqU6Q9I5K7HI75YB+EKQAAAACQAGoagtpZF3SsF6W3L0zpmebWgEzncxd0xcqUUA1oGY2csAhTAAAAACABdFTz2b2Z+qasrwpoU4gRzPEqVJgiKlMSFmEKAAAAACSAUGFKe3umSC0c9SnpWkd9TA1obXeGZPGROlFx5wEAAAAgAYQOU/anMsXchHZhFzvqYwxTqEpJaIQpAAAAAJAANlabj97szzGf4owk9TH0XFnQxSpTZJjmQ5iS2AhTAAAAACABbDBUpqQlWcpL3r+PhabqlG/KG7S91lwJE4+oTMG+CFMAAAAAIAGYjvkUZ7hlWdZ+va6pCa3UtUYkGxvQMsknoRGmAAAAAEAC2GiYsNPesch7O6LAHKZ8Uerf79eOFVSmYF+EKQAAAADQxfkCtrbWBB3rRfsxyafRgCy30pOc1S1rKrvQeGRDZYqdlBmFjSBWEKYAAAAAQBe3uTog27C+P81nG1mWpf5ZzlBmTUXXCVOoTMG+CFMAAAAAoIszNZ+V9m8s8t4GZDpfZ01Fg2zbFOHEmUC9LNtwZInKlIRGmAIAAAAAXVwkxiLvbYChMqXCb2tXvfNoUbyxDGORJSpTEh1hCgAAAAB0caZJPlLH9EyRzGGK1EWO+pgm+YgwJdF1zO8cAAAAAEDUbasJ6J/f1MgftPXDQWnql7nnI5/pmI/XJRWkdszfr4cKU1ZXBHRYjw55i6gx9UuRJJvRyAmNMAUAAAAAuoANVQ068rXtqvDt6VPy5+WVemB8ji4YnG4ci9wn3S2X5ZzC0x4DMrtuZUqoMIWeKYmNMAUAAAAAuoCbl1Y0BSmS5A9KV80v07baoPGYT0cd8ZGknmkupbot1QaaN5xd2wXGI4esTOGYT0KjZwoAAAAAxLnSuoDeWF9rfOzWjyu03himdEzzWalxPLJ5ok+8s+iZAgPCFAAAAACIc8+vrpUvzME5HRmmSOajPqu7wnhkwhQYEKYAAAAAQByzbVtPf10d9vOKO/CYj2RuQlvus7U7zscjhx6NTM+UREaYAgAAAABx7JOdfq0sC/84TUdXpgwMNR650jyWOV7QgBYmhCkAAAAAEMfaU5UiSUXpHRum9A85Hjm++6YwGhkmhCkAAAAAEKeq/UG9tNbZeDbLY+m1E7spL9n8kc9lSb06OEwZkGl+vbhvQmsIU2zLI7mTo7AZxArCFAAAAACIU6+tq1Wl39ng9ewBaZrQK1lvT+mmYsNxngk9k+VxWR26l17pbqUY8pS1cR6mmCpTaD4LwhQAAAAAiFNPf1NjXL9wSJokaXC2R7OndNfYHt6mx3qkuvS7MVkdvheXZam/YaLPmsp4D1MqnIuEKQmvY9s3AwAAAAA6xbflfi0q8TnWh+Um6eB8T9OPC9Lc+s/kbpq3zaeahqAO6e5VN1MJSQfon5WkVfs0w+2KPVOY5APCFAAAAACIQ/8MWZWSLstqfoTHsiwd3TPyPT4GGCpTdtfvGY+cG6J/S8wzjEYmTEGc/moGAAAAgMTlD9p69ltnmOJ1SecOSI3CjvYINR45nvum0DMFJoQpAAAAABBn/ruxTiW1Qcf61L6pyovQEZ62GJBlfu94PupjHI3MWOSER5gCAAAAAHEmVOPZi75rPBst/UNUpsRzE1oqU2BCmAIAAAAAcWRbTUCzN9U51osz3J3SF6UlfdLdSjYUp6yJ18oUOyjL2DOFMCXREaYAAAAAQBx59tsaBWzn+o8Gp8m1T+PZzuayLPXLMIxHjtcwJVBtXKYBLcIKU7Zs2aKHH35YZ5xxhoYPH67u3btryJAhuvDCC7V06VLH9XfeeadycnJC/rN+/Xrj+8yZM0eTJ09Wnz59VFRUpKlTp+r9999v31cIAAAAAF2Ebdt6ztB41pJ0waDoHvFpZDrqs6YiEIWd7D+rodK4TmUKwhqN/Nhjj+n+++9X//79deyxx6pbt25avXq1Zs2apVmzZulvf/ubzjzzTMfzfvjDH6q4uNixnp2d7Vh7/vnndfnll6tbt2764Q9/KEl65ZVXdPrpp+vJJ5/UaaedFs6WAQAAAKDLWLG7QV+VO6s8juudrCJDRUg0mJrQ7qoPqqw+qJw4G49sbD4r0YAW4YUpY8aM0RtvvKEjjzyy2frChQt12mmn6brrrtOUKVOUnNz8nN4FF1ygo446qtXXLysr069+9Svl5+fr/fffV+/evSVJ06ZN09FHH63rrrtOxx13nDIzKakCAAAAkHheXmtuPHv+wNioSpFCj0deV9mgg5O9nbyb/RMqTOGYD8KKBU899VRHkCJJ48eP11FHHaWysjKtXLmy3Zt59dVXVV5erssuu6wpSJGk3r1762c/+5l27dqlN954o92vDwAAAADxyrZtvbSm1rGe6rZ0cnFKFHZkNiDTHKbE5XhkjvkghA6rsfJ4PJIkt9tZ0rVw4ULdf//9+stf/qI33nhDVVXmdG/+/PmSpOOOO87x2MSJEyVJCxYs6KgtAwAAAEDc+GSnX+urnL1HTixKUYYndo7PhByPHIdhSujKFMKURNchh+o2btyo9957T4WFhRo2bJjj8TvvvLPZj7Ozs/XHP/6xqSdKo9WrV0uSBg4c6HiNxrXGa1pTV+ccFRarfD5fs38j9nCP4gf3Kn5wr2If9yi+cL/iB/cqPsTifXr+G/NkmVP6uGPq8093ty2PS/IHm69/U+Zr9z4/L22QLemAbLeS3c0nFkXyXqXU7jau1we9aoihn/N4EYu/ryQpJSX8yq79DlP8fr8uv/xy1dfX6+abb25WmTJ8+HD99a9/1ZFHHqnCwkKVlJTo7bff1h133KGrrrpK2dnZmjx5ctP1FRUVkqSsrCzH+zT2SWm8pjVbtmxRIBBfHaNLSkqivQW0gnsUP7hX8YN7Ffu4R/GF+xU/uFfxIVbuU8CWXl6bon0PF6S7bQ0JbNfGjdHZVyi9klO0vrb5Xr/cWaONG83hRGtuX+nVe6VJSrJsDUizdWBGUCMyAzq98PvPfJG4V93LNso5NkXauqNKdeUx9pMeR2Ll95W053TNgAEDwn7efoUpwWBQV111lRYuXKiLL75Y559/frPHTznllGY/7tu3ry677DIdcMABOv3003Xbbbc1C1M6Uq9evSLyupHg8/lUUlKigoICeb3x1ZApUXCP4gf3Kn5wr2If9yi+cL/iB/cqPsTafVq43a+dPudfLE8uStHgft2isKOWDV5TofW1/mZrW3xJKirq0a7X++aT3ZKCarAtfV1t6etqlzY1pOjnh2ZH9F6lBT3Sdud6Qe9BCqb07ND3SgSx9vtqf7Q7TAkGg7r66qv14osv6txzz9V9993X5udOmDBB/fv318qVK1VRUdFUidL474qKCuXl5TV7TmVlZbNrWtOeMp1o83q9cbnvRMI9ih/cq/jBvYp93KP4wv2KH9yr+BAr9+mNTeYjJecOzoiJ/e1rUE6d3tnSPEzZWW/L5/Iqyxtef5dddQFtrgk61kd3T272tUfiXnlk/nn3pudLntj7eY8XsfL7an+0q0tRY0XKs88+q7PPPlszZsyQyxXeS+Xn50uSamu/70bdUl+UlvqpAAAAAEA8q2kIalFJvdZXOpu0+oO2XlvnnOKTm2zpmF7JnbG9sIUaj7zW8PW1Zvkuv3F9VL4n7NcKlxVimo9oQJvwwg5TGoOU5557TmeeeaYeffRR4wSfllRXV+vLL79Uenp6U6giSUcccYQkae7cuY7nzJkzp9k1AAAAANAVLC6p1/AXSnTymzs1+qUS3fhRuYK23fT4B1vrtaveWZlxWt9UeVyWYz0WDOjAiT7LQoQpI/M6I0xxTvOx3RmSFTvTkxAdYR3zaTza89xzz+n000/XY489FjJIqaysVElJiQYNGtRsvba2Vtdee60qKyv1ox/9SElJ32/hjDPO0E033aTHHntMP/7xj9W7d29J0ubNm/X4448rPz9fU6dODfdrBAAAAICYVNdg6yfvlar0u7AkaEsPflGlKn9Qfx6XI8uy9K81zqoUSTpzQFqb38dVvVredY/LVfWlrL2Cmkg5PmBrdo5zYkv/1UlKLwnvL+NP3+3XETnfh0klgXwVundp3LfJcn0rpQSDSq2vU/KOFLnDPDHRGlfVKscaY5EhhRmm3HXXXXr22WeVkZGhQYMG6Z577nFcM2XKFI0cOVKlpaU69NBDNWbMGA0ZMkQFBQXavn273n//fW3evFlDhw7VH/7wh2bPzcnJ0T333KPLL79cEyZM0BlnnCFJeuWVV1RaWqp//OMfTVN9AAAAACDevbimRlsM/UD+8VWNkt2Wbv5Btmatd4YphakuHVHQtgaeVu1GpS88US7fzv3eb1tlSppk2l79d/+EYZQk7fVaXzQM0vCkb6Vde36cJClZkmrC32d7EKZACjNM2bBhgySpqqpKf/rTn4zXFBcXa+TIkcrNzdX//M//6OOPP9bs2bNVVlam1NRUDRkyRJdffrl+9rOfKTU11fH88847T/n5+br33nv1f//3f7IsS6NGjdL06dN1zDHHhP8VAgAAAEAMsm1bD69wHiNp9MjKan1e6leF31lJcnr/VLnbeMTHs+WlTg1SujrCFEhhhikzZszQjBkz2nRtVlaWsXKlLSZNmqRJkya167kAAAAAEA/mbqnXqrKWe4gs2OY8KiNJZ/Vv+xEfd9VXYe0LLQum9Y/2FhAD6JoDAAAAAFHw0Behq1JaUpTh1iHd29581fKXt+t94GTLJX/Rj6O9DcSAsCpTAAAAAAD7b+Vuv+ZuCbN5yHfO6p8qy2r7FB9TmGK7UhRMH9Cu92+rXXVBbat19oMZmJWklDb2oN1UHVC5r/kxp02BAh2Q41XjKaegbcvv88vj9cgVxs9LuIJp/eUrvlgN3SdG7D0QPwhTAAAAAKCTheqVclyvZL23tV7BFgbunNnf2XuyJVaDM0wJ5IxW9bj/hPU64fpgU53Omb3Lsf7UqDyd1q9tX8PJr5Q4jkIdmJOkxRMKmn5cV1enjRs3qqioSCkpKfu3aaCNOOYDAAAAAJ1oe21AL6x2jp5JS7L0xDF5+usROSGfOyQ7SSPy2n7ER5Isf4VjzU7KDus12mNApvnv7ldXtNwnplFNQ1BflTuvHZkf3tcPRAJhCgAAAAB0or99WS2f8/SLfjQoTbnJLl0wOF33j88xPvecAeEd8ZFCHPPxZIX1Gu1RnOmW27DVdzbVten5K0objBU6o/LbNhIaiCTCFAAAAADoJLUNtp5YVe1YtyRdMfT7kbuXHJCuuw/PbhZGDMxy66phYY7ltYNSQ3QqUzwuS8MNVTQLS3z6uszf6vOX7TJPMhoZZmUOEAn0TAEAAACADlZSE9Daygb1y0xSYdr33VZfWF2jXfXOspSTi1M0MLv5x7PLhmZoXGGy/rOhVtlel340OE3pnjD/PryhUpac5R22J/JhiiSdPzBNy3Y5K2Oe/LpadxyW0+Jzl+0yBy7hHnMCIoEwBQAAAAA60F+/qNRNSysU+C7DGJ7n0fG9kzWpT0rIxrNXh6g4GZHn2a/wwDJUpUidGKYMStPNH5erPtB8/dlva/T7MdlKSQp9ZMkUpvTPdCsnmQMWiD5+FQIAAABAB3lvS51+99H3QYokfVHq132fV2nKf3YaG6oenO/R+ILI9AEx9UuROueYjyTlJrt0umFyz+56W/9eXxvyeb6ArVWGo0D0S0GsIEwBAAAAgA5Q0xDUtIVlYT/v6mEZYTeVbauQYUonVaZI0qUHpBvX//GVs3dMo1VlfvkNTXpHMckHMYIwBQAAAAA6wF2fVmpdZaD1C/fSK82l0/s7Kzc6SrSP+UjS4T28OjDH2WFiUYlPX4VoRBuqXwphCmIFYQoAAAAA7Kdlu3z6a4h+KC25fGiGPK7IVKVIoStT1EnHfCTJsixdEqI65ckQ1SnLQ4QpIwlTECMIUwAAAABgPzQEbf2/BWXN+qQ0Kkx1KSNEk9XeaW5dPMQcMnSU0Md8siL6vvs6f2CaUtzO9We/rVFdg/MnzjQWuU+6W91MLwJEAWEKAAAAAOyHGSurjMdSPC7p5RO7ac0FPfXvk7rp/w3P0LDcJOV4LY0r8Or/JuVFfDKN1RDdBrSNckI0oi3z2Xptn0a0DUFbX5Q6G/VSlYJYwmhkAAAAAGindZUNuvPTSuNj00ZkamjungDg6J7JOrpnsm49tHNDDMsfqmdK51amSHsa0T632jnB58mvqnXewLSmH39T3qBaQ5nPyP0YEQ10NCpTAAAAAKAdbNvWdQvLVGM4pjI4O0m/HJkZhV01Z6pMsV2pkqvzRwwf1sOroSEa0X65VyNams8iHhCmAAAAAEA7PL+6VnO31Bsfe2B8jlJC9ErpTKaeKZ05yWdvlmXp4jY0ojX1S5GkUfmdHwABoRCmAAAAAECYyn1B3fChuR/JpQekaXxhcifvKATDaORohSmSdN7ANKW6nSHTs9/WqMIXlGSuTOme4lLPND6+InbwqxEAAAAAwvTq2lqV1gcd64WpLt18SPTCin0ZK1M6ufns3nKSXTqjv7MRbbnP1ogXt+l3H5br81JnmDIq3yPLin6lD9CIMAUAAAAAwrR0h/koyj3jcpTtjZ2PWeZjPp3ffHZvlxyQZlwv99n664oqVfqdPWjol4JYEzu/ywEAAAAgTqzY7aye6J/p1il9nVUX0WRsQBvFYz6SdGh3r4bmhjdYdiT9UhBjCFMAAAAAIAyBoK0vyxoc68NjbXSvbRtHI0fzmI+0pxHtTT8Ibw9UpiDWEKYAAAAAQBjWVQaM45CH5sbYB/5grSzbWUET7coUSTqxKEWvnJCv0d1a/znL9lrqm+HuhF0BbRdebRUAAAAAJDjTER9JGhZjYYqpX4okKSm6PVMaHds7Rcf0StbSHX49tqpKr6ytlSGj0gl9Umg+i5hDZQoAAAAAhCHew5RYqExpZFmWDu3h1eMT8vTFuYW6/uBM9Uj9/mNqv0y3fjsmNsIfYG9UpgAAAABAGFYawpS0JEv9MmPrKIrV4OyXIsVWmLK3wjS3fjM6S9eNzNSnO32qbbB1eIFXaUnUACD2EKYAAAAAQBhWlDrDlANzkuR2xdZRlJCVKTFyzCeUZLelsQXJ0d4G0CIiPgAAAABoo2p/UGsrA471WDviI8XHMR8gXhGmAAAAAEAbfVnWIEOP1Nib5KMWjvlEeTQy0BUQpgAAAABAG4VsPpsXg2EKlSlAxBCmAAAAAEAbmfqlSNKw3BhsR9kQKkyJ7Z4pQDwgTAEAAACANjJN8ilMdSk/JbYm+UjmyhTb8kiu1CjsBuhaCFMAAAAAoA1s29aK3Q2O9VjslyKZe6bYnmzJiq2pQ0A8IkwBAAAAgDYoqQ2qtD7oWI/FfilSiMqUGB+LDMQLwhQAAAAAaINQzWdjtjLFFKbQfBboEIQpAAAAANAGK+Op+axaOOYDYL8RpgAAAABAG3xhqExxW9IBOfFTmaIkwhSgIxCmAAAAAEAbrDQ0nx2UlaRkd2w2dDUf86FnCtARCFMAAAAAoBUNQVtflTkrU2K1+ayCPlnBWseyTWUK0CEIUwAAAACgFd9WNMjnHOQTw81nnf1SJHqmAB2FMAUAAAAAWhF/zWcN/VJEmAJ0FMIUAAAAAGhFVxiLLEl2Ej1TgI5AmAIAAAAArVhhaD6b6bFUnOGOwm5aFzJMoTIF6BCEKQAAAADQClNlytBcjywrNif5qIGeKUAkEaYAAAAAQAvKfUFtrAo41ofF6BEfiWM+QKQRpgAAAABAC1aF7JcSm81nJY75AJFGmAIAAAAALVhp6JciScPyYrgyJdQ0nyTCFKAjEKYAAAAAQAtCTfI5KCeGwxRDZYotl5SUEYXdAF0PYQoAAAAAtGClIUzpk+5WTnLsfpwyVqYkZUpW7O4ZiCf8TgIAAACAEGzbNlamDIvhfilSiMoU+qUAHYYwBQAAAABC2FwTVIXPdqzHcr8USbIMo5EJU4COE9txKgAAAAB0oip/UCtK/Vq2o04fbvLo6xWVxuuGxvBYZClEZQpjkYEOQ5gCAAAAIOE1BG395sNyPfVVtXzBxlWPpIDx+tgPU6hMASKJMAUAAABAwvvth+V6fFV1m671uKTB2bH9UYpjPkBk0TMFAAAAQEJ7bV2tHm1jkCJJRxUmy+OyIrij/WQHzGFKEmEK0FEIUwAAAAAkrDUVDbpm/u42X98txaU/HBrjoUSDuc+L7aFnCtBRYrs2DQAAAAAipLbB1kXvlqrS75zW06h3mkvD8jwaluvRyHyPTuiTonRPbP+dtOUvM65TmQJ0HMIUAAAAAAnp10vK9EWp3/jYH8akabx3p4b1L1JKSkon72z/mJrPSvRMATpSbEeqAAAAABABz31bo6e+rjE+9uPBafrZAanKitO/erYanGORJcIUoCMRpgAAAABIKF+W+XXdojLjY0Nzk3T32PgOHSx/iDAliZ4pQEchTAEAAACQMKr8QV08t1Q1Dc4+KRlJlp46Nk9pSfH9MSlkmEJlCtBh4vtPCQAAAAAIw8MrqvRVeYPxsb8ckaPB2Z5O3lHHM41FliTbk9O5GwG6MMIUAAAAAAnjhdW1xvX/OTBdZw5I6+TdREaoyhRxzAfoMIQpAAAAABKCP2hrTaWzKmVEnke3Hdp1jsCEbEBLmAJ0GMIUAAAAAAlhc3VAQWerFJ3RP1UpSVbnbyhCTKORbXeG5IrT8URADCJMAQAAAJAQ1hmqUiSpX4a7k3cSWaZjPjSfBToWYQoAAACAhLC+MmBc75vZtSo2TMd8OOIDdCzCFAAAAAAJIWRlSiaVKQDCQ5gCAAAAICGsr3JWpmQkWcpL7mIfiwyjkQlTgI7Vxf7UAAAAAAAzU2VK30y3LKvrNJ+VQlSmcMwH6FCEKQAAAAASwjpDz5Su1i9Fts0xH6ATEKYAAAAA6PIqfEGV1gcd612tX4oCVbLk/DrtJMIUoCMRpgAAAADo8kz9UiSpX0bXqkyx/M5+KRKVKUBHI0wBAAAA0OWtDzHJp6sd8zGNRZYk20PPFKAjEaYAAAAA6PISeSyyJIljPkCHIkwBAAAA0OWFOuZTzDEfAO1AmAIAAACgyzMd8ylMdSk1qYuNRQ55zIcwBehIhCkAAAAAujzTWOR+XaxfihT6mI+dRM8UoCMRpgAAAADo0oK2rQ1VzsqU4i7WL0VqIUyhMgXoUIQpAAAAALq0ktqg6gwtU7pkZUpDiJ4pVKYAHYowBQAAAECXFnIsckZiVKbYrmTJnRKF3QBdF2EKAAAAgC7N1C9F6pqVKTI0oOWID9DxCFMAAAAAdGnrDf1SpK4ZpphGI9tJhClARyNMAQAAANClmSpTvC6pZ1rX+zhkGo1MZQrQ8brenx4AAAAAsJd1hp4pxRlJcllWFHYTWcaeKTSfBTocYQoAAACALm2DoTKlbxcciyyFCFOoTAE6HGEKAAAAgC6rPmBrS40zTOmK/VIk82hkwhSg4xGmAAAAAOiyNlY1yDas9+uCY5EVqJMVrHeuc8wH6HCEKQAAAAC6rFBjkYu7YGWK6YiPRGUKEAmEKQAAAAC6rNBjkbteZYppko/EaGQgEghTAAAAAHRZoSpT+mZ0xcoUZ78UicoUIBIIUwAAAAB0WaaxyDleSznJXe+jUOjKFHqmAB2t6/0JAgAAAADfWW8ci9z1qlIkeqYAnYkwBQAAAECXtc7QM6Ur9kuRJBnGIkuEKUAkhB2mbNmyRQ8//LDOOOMMDR8+XN27d9eQIUN04YUXaunSpcbnVFRU6IYbbtDw4cPVo0cPjRgxQjfeeKOqqqqM1weDQT366KMaP368CgsLNXDgQP30pz/VunXrwt0uAAAAgARVVh9Uhc85GLlfF+yXIlGZAnSmsMOUxx57TDfccIPWrVunY489Vtdcc43Gjh2rN998UyeccIJefvnlZtdXV1drypQpevjhhzVkyBBdddVVGjx4sB588EGdeuqpqqurc7zHtGnTdP3118u2bV1++eWaOHGiXn/9dR177LFavXp1+79aAAAAAAnD1C9FSsBjPvRMATpc2H+KjBkzRm+88YaOPPLIZusLFy7Uaaedpuuuu05TpkxRcnKyJOmBBx7Q559/rmnTpunmm29uuv7mm2/W/fffr4cffljXXXdd0/oHH3ygmTNnavz48Xr11Vfl9XolSeecc47OOeccTZ8+3RHYAAAAAOjarNrNSl3xK7l3L5EV9LXpOeOCtsq6OStT0tZaSlpvtfjcTNtWvh2Ua7VLltXytTEjUOtYsi235E6PwmaAri3sMOXUU081ro8fP15HHXWU5s6dq5UrV2r06NGybVtPP/20MjIyNH369GbXT58+XX/72980c+bMZmHKzJkzJUm//e1vm4IUSTr++ON15JFHau7cudq4caOKiorC3ToAAACAeGQHlb7kDLmrvw7raV5JXlMtfvC7f1pgqWs0mLSTsqV4CYOAONKhfz54PB5Jktu9p6HT6tWrtXXrVh1++OFKT2+ehqanp+vwww/XunXrtGnTpqb1+fPnKz09XWPHjnW8/sSJEyVJCxYs6MhtAwAAAIhh7t0fhR2kYA/bwxEfIBI67LDgxo0b9d5776mwsFDDhg2TpKb+JgMGDDA+Z8CAAZozZ45Wr16tPn36qLq6Wtu2bdPQoUObApl9r9/7dVti6sUSq3w+X7N/I/Zwj+IH9yp+cK9iH/covnC/4gf3Knypu5dHewtxy58+LK4+G7UHv6fiR6zeq5SUlLCf0yFhit/v1+WXX676+nrdfPPNTUFIRcWe0VzZ2ebu0VlZWc2ua/x343pr17dky5YtCgScM+VjWUlJSbS3gFZwj+IH9yp+cK9iH/covnC/4gf3qu367PhU1FeEL2Clam3KGareuDHaW+kU/J6KH7F0r9xud8gCkJbsd5gSDAZ11VVXaeHChbr44ot1/vnn7+9LdohevXpFewtt5vP5VFJSooKCgmZ9YhA7uEfxg3sVP7hXsY97FF+4X/GDexW+nNIdjrWgO031PU4L+ZygpBfW1iu4T//ZAZkuje3uafU9A8GgamtrlZqaKrcr/rqnBFJ6qa7HKcrLOFB50d5MhPF7Kn50pXu1X2FKMBjU1VdfrRdffFHnnnuu7rvvvmaPN1aSlJebR3TtW4nSWuVJa5Ure2tPmU60eb3euNx3IuEexQ/uVfzgXsU+7lF84X7FD+5V2yXVrnWsBbNGyDdmhiTJF7C1oapBhWluZXj2BB8bqxr0k2XOv/2+YVCmxhzc+ueJurq6psEX8XqfPN/9kyj4PRU/usK9aneY0liR8txzz+nss8/WjBkz5NonsR04cKAkac2aNcbXaFxvvC49PV2FhYVav369AoGAo2/KvtcDAAAA6OKCfrlq1jmX0wdJkpbu8OmSd0u1qTqgVLelnx6Yrt+MztT6KvOR/36ZHdY2EkACa1e92t5ByplnnqlHH33U2DB24MCB6tmzp5YsWaLq6upmj1VXV2vJkiXq27ev+vTp07R+xBFHqLq6WosXL3a83pw5cyTtGcMMAAAAoOtz1ayXZTc41oPpg9QQtHXFB7u1qXpPcFIbsPXXFVUa/+p2Pf9tjfH1+mU6P7cAQLjCDlMaj/Y899xzOv300/XYY48ZgxRJsixLF154oaqqqnTPPfc0e+yee+5RVVWVLr744mbrjT++/fbbm3X4nT17tubPn6/jjjtOxcXF4W4bAAAAQBxyVX9jXA9kDNLSHT59W+EMWtZXBfT0N+YwpW8GlSkA9l/Yf5LcddddevbZZ5WRkaFBgwY5QhJJmjJlikaOHClJuvbaa/Xmm2/q/vvv1/LlyzVq1CgtW7ZMc+fO1ZgxY3TllVc2e+7RRx+tiy66SDNnztSECRN0wgknaNu2bXrllVeUm5uru+++u51fKgAAAIB446r+1rgeTB+kOd/Uh/VaqW5LPVLjr5ksgNgTdpiyYcMGSVJVVZX+9Kc/Ga8pLi5uClPS09M1a9Ys/fGPf9Trr7+uefPmqaCgQNdcc42uv/56paamOp5///33a+jQoXrqqaf0yCOPKD09XVOnTtWNN96o/v37h7tlAAAAAHHKXeUMU2xZCqYN0NzN5kEXofTNdMuyrI7aGoAEFnaYMmPGDM2YMSOs52RnZ+vOO+/UnXfe2abrXS6XrrjiCl1xxRXhbg8AAABAF2KqTLFTi1XqT9InO/1hvVZfms8C6CDUuAEAAACIWaYwJZAxSO9tqZcd5mv1y6D5LICOQZgCAAAAIDb5K+SqL3EsB9MHac4Wc7+U107sppOKUoyPTS42rwNAuAhTAAAAAMQkV80a43ogbaDmbq5zrBdnuHV0T6+enZinJ4/JU++07ytRrhmWoaN6JkdsrwASC4cGAQAAAMQkd5V5LPJae4C21gQd6xN7Jzc1mD29f6pO7Zeiz0v9Kkx1qyCNIz4AOg5hCgAAAICYFGos8pzyPsb143o3P8bjsiyNyvd2+L4AgGM+AAAAAGKScZKPK1WvluQ51t2WdDTHeAB0EsIUAAAAADHJXeUMUxrSBmjhdudI5MN6eJXt5eMNgM7BnzYAAAAAYo9ty1W92rFc4u6v+oDz8uN6UZUCoPMQpgAAAACIOVb9NlmBKsf6cl8/4/WT+jD2GEDnIUwBAAAAEHNCNZ99r6LIsZaf7NKofE+ktwQATQhTAAAAAMQcU78USXq/stixdmzvZLm+G4kMAJ2BMAUAAABAzAlVmfJ1oK9jjX4pADobYQoAAACAmGMKU8qUpzI727F+XG/6pQDoXIQpAAAAAGKOKUxZ1dDPsTYsN0mFae5O2BEAfI8wBQAAAEBsCfrkqlnnWF7p7+dYm0hVCoAoIEwBAAAAEFNcNetl2QHHuqlfCmEKgGggTAEAAAAQU1zV3xjXv97nmE9akqWxBd5O2BEANEeYAgAAACCmuKpWG9e/CvRr9uOjCr1KdjMSGUDnI0wBAAAAEFPchuazAdul1YHiZmtM8QEQLYQpAAAAAGKK6ZjPumBv+fT9kR5L0klFhCkAooMwBQAAAEBMcVU7j/l83dC8+exFQ9LUNzOps7YEAM0QpgAAAACIHf4KuepLHMt790vplebSrYdmd+KmAKA5whQAAAAAMcNtqEqRpK/3ClPuG5+rbC8fZQBED38CAQAAAIgZrY1FPndAqk6kVwqAKCNMAQAAABAzXIZJPtKeYz7dUly683CO9wCIPsIUAAAAADGjZPvXjrUaO0WbgwW6Z2y28lPcUdgVADRHmAIAAAAgJtQ12Koo/cqx/nVDX00uTtPp/VKjsCsAcGKWGAAAANCJrIYqef1b5Kq1ZQWTo72dmDJ/Y51OtNY51tfa/XTvuBxZltX5mwIAA8IUAAAAoDM0VCrt0/9R1o531MMOSGujvaHYc5ZkrJ3vU3igCtM43gMgdhCmAAAAAJ0gdeUN8mx/O9rbiEtDiw5UQ7Q3AQB7oWcKAAAA0AmSts+O9hbilp0xJNpbAIBmCFMAAACATmD5dkV7C3Gp2spRIHNYtLcBAM0QpgAAAACRZgdk2f5o7yLuNNhufd77FsmdEu2tAEAz9EwBAAAAIi1Qa1z2d5+ohu7Hd/JmYtNr62q1sMTX9ONqO1Uf+A/R68cdHsVdAYAZYQoAAAAQYVaIMCWQN16+/ld08m5i059XbNdHtc2rd3qmudSTKT4AYhDHfAAAAIBICxGm2C6Or0iSP2jr81LnMaiD871R2A0AtI4wBQAAAIgwK1hnfsCd1rkbiVFfljWoLuBcH93N0/mbAYA2IEwBAAAAIi1QY1y2aawqSfp0p8+4ProblSkAYhNhCgAAABBhVsBcmWK7Uzt5J7Hps53mSUcH51OZAiA2EaYAAAAAkRbqmI+LMEWSPt3lrEzpk+5W91SazwKITYQpAAAAQIRZHPMJqT5g6wtD81n6pQCIZYQpAAAAQISFOuYjjvlo1W6//EHnOv1SAMQywhQAAAAg0kKNRiZM0ach+qWMpl8KgBhGmAIAAABEWMjRyPRMMfZLkaSDqUwBEMOSor0BAAAAoMvr4j1TbNvWQyuq9MSX1fIHpcsPStc1wzNkWVarzzVVpvTPdCs3mb/3BRC7CFMAAACACAvdMyWtczcSIbd/Uqk/La9s+vGNSyvUI82t8wa2/PXVNthatdvUfJaqFACxjbgXAAAAiLQQYUpXqEyZvamuWZDS6D7D2r5W7ParwXau0y8FQKwjTAEAAAAizAqaj/nIFd9hyqaqBl32QanxsS/LGoxVJ3v7dCf9UgDEJ8IUAAAAINIMlSm2K0Wy4vfbcV/A1qXvlWp3vaG05DuvrjNPMWoUapLPKCpTAMS4+P3TGwAAAIgTlmE0sh3nVSm3fFyhj3a0XHnyWithymeGypTB2UnK8vIxBUBs408pAAAAIMKMYUoc90t5fX2tHlpR1ep1LR31qfYH9WV5g2OdfikA4gFhCgAAABBpwRDHfOLQ2ooGXT1/d5uvD3XUZ3mpX0HDCSH6pQCIB4QpAAAAQISZK1NSo7CT/VPXYOuS90pV4XOmICluyXQ659W15jAlVL+U0d2oTAEQ+whTAAAAgEgzhCnxOMnntk8qtGyXOQS5e2yOJvVxfk1flZuP+pj6pbgsaUQeYQqA2EeYAgAAAESYFYz/BrRflvk1Y6W5T8r5A1N14eA0nd7PXG3ziuGoz6eGUOaA7CRlePiIAiD28ScVAAAAEGmm0chxdMzHtm39ekm5AoYeJwflJOnecTmyLEsnFaUo2e285rW1tbLt759c4QvqG0PzWfqlAIgXhCkAAABAhJlHI8dPmDJrQ53e21LvWE+ypL8fk6f076pJsrwuTewd4qhP2ffhSch+KUzyARAnCFMAAACASIvj0ch1DbZ++2G58bErh2XooNzmAcgZIY76NE71KasP6tdLyozXjKYyBUCcIEwBAAAAIswyjkaOj8qUv66o0vqqgGO9R6pL00dlOtZPKjYf9Xl1ba18AVsXzt3VrEqlUbJbGk7zWQBxgjAFAAAAiCTbjttpPpuqGvTn5ZXGx27+QZayDLOQMz0uTTIc9fm6vEFn/Xen5m1zTvGRpIuGpCs1ydq/DQNAJyFMAQAAACIpWC9Lzs6t8XDM56alFappcO79B908On9QWsjnndHfXHUTKkgZmpuk343Jat8mASAKkqK9AQAAAKBLMxzxkWLnmM+Sknp9tMOnFLelobkeDc31KCfZpYXb6vXSWkNFjaS7x+bIZYWuIjnxu6k+9c7TQQ690lx68fhuyjZUuQBArCJMAQAAACLINMlHio3KlAe/qNSNH1U41vuku+ULGuYgS/rR4DT9oHvLjWIzPS4d3ztFb2wwB0nfX2fpheO7qXe6ockKAMQw4l8AAAAggkKGKVHumVJaF9Adn5j7oWyqDmh7bdCxnuWxdNMP2nYc5/QQR30aJVnSzGPzaDoLIC4RpgAAAACRFLIyJbrHfOZuqVdtwFx9EsqvDs5Uj9S2VZGcWJSilBYu/csROTrW0KgWAOIBYQoAAAAQQaaxyJKkKPdMmbO5PqzrB2cn6bKDMtp8faipPpJ0w+hMXTA4Paz3B4BYQpgCAAAARFKgxrgczZ4ptm3r3c0t9zPZ112HZ8vrDm908f+OytS+T7lwcJqmj8oM63UAINbQgBYAAACIICsQappPisKLJjrOit0N2mboiXJkoVcH5ni0YrdfK0r9qvDbyvLu6ZNyXDuO5BzczatnJ+brvs8r5QvYOmdgmi47KF1WC5OAACAeEKYAAAAAkRSyAW30jvnMDVGVcsXQDE3tu2dftm2r3GcrLckKuyJlbycUpeiEInqjAOhaCFMAAACACIrF0cimfilJlnR0z+SmH1uWpZxkKkgAwISeKQAAAEAkhWhAG63RyNX+oBaVOMOUw3p4leXl4wEAtAV/WgIAAAARFLoyJTrHfOZv88nnbJeiiYwpBoA2I0wBAAAAIihUmBKt0chzQvRLmdg72bgOAHAiTAEAAAAiKRhbPVPmGvqldEtxaWS+Jwq7AYD4RJgCAAAARFDo0cidX5myvrJB31Y0ONaP7ZUsF+OKAaDNCFMAAACASDIc87HlllydXwliqkqRpOPolwIAYSFMAQAAACLI1DMlaEWnP0mofinH9aJfCgCEgzAFAAAAiCTDaORgFMYi+4O2PtjqrEwZnudRQZq70/cDAPGMMAUAAACIoFipTPlou08VftuxPpGqFAAIG2EKAAAAEEmmMMXV+QFGqH4pE/vQLwUAwkWYAgAAAESQZRiNHLQ6P8CYs8V53Cg9ydLYHt5O3wsAxDvCFAAAACCSDKORO/uYz666gD7b6XesH9kzWV43I5EBIFyEKQAAAEAEmXqm2J18zOfdLfVydkuhXwoAtBdhCgAAABBBsdCAdk6ofim96ZcCAO1BmAIAAABEUpRHI9u2rbmbnXvom+HWgCxGIgNAexCmAAAAABEU7cqUlbsbVFIbdKxP7J0iy6JfCgC0B2EKAAAAEElRDlM+3ukzrh/Xm34pANBehCkAAABApAQbZNnOKTqdeczn81Ln+0vS4YxEBoB2I0wBAAAAIiXorEqROrcy5QtDmNIzzaXuqfRLAYD2IkwBAAAAIsQKOBu/SlLQ6pzKlKBtG8OUEXmeTnl/AOiqCFMAAACASDH0S5GkoKtzKlPWVwZU6bcd64QpALB/CFMAAACACLEMY5GlzqtMWR6iX8rIfPqlAMD+IEwBAAAAIiVQY1y2O6ky5fNd5jCFyhQA2D+EKQAAAECERLtnyuelzrHIGUmW+mXSfBYA9gdhCgAAABApIY/5dFJliuGYz/A8j1yW1SnvDwBdVdhhyvPPP69p06bpmGOOUY8ePZSTk6NnnnnGeO2dd96pnJyckP+sX7/e+Lw5c+Zo8uTJ6tOnj4qKijR16lS9//774W4VAAAAiCorxDGfzmhAu7MuoC01Qcf6iHyO+ADA/koK9wm33XabNm7cqPz8fBUUFGjjxo2tPueHP/yhiouLHevZ2dmOteeff16XX365unXrph/+8IeSpFdeeUWnn366nnzySZ122mnhbhkAAACIimge86FfCgBETthhyoMPPqgBAwaouLhY9913n2655ZZWn3PBBRfoqKOOavW6srIy/epXv1J+fr7ef/999e7dW5I0bdo0HX300bruuut03HHHKTMzM9xtAwAAAJ0viqORTUd8JGkkYQoA7Lewj/kcc8wxxiqTjvDqq6+qvLxcl112WVOQIkm9e/fWz372M+3atUtvvPFGRN4bAAAA6GhWqDClE3qmmMIUtyUdmEOYAgD7K+zKlPZYuHChPv74Y7lcLg0YMEDHHHOMMjIyHNfNnz9fknTcccc5Hps4caL++Mc/asGCBU3Hf1pSV2cuqYxFPp+v2b8Re7hH8YN7FT+4V7GPexRfuF+xyVVfaVwPWikRv1fLdjpff0iWW2qoV11DRN+6S+D3VPzgXsWPWL1XKSnhH73slDDlzjvvbPbj7Oxs/fGPf3SEIqtXr5YkDRw40PEajWuN17Rmy5YtCgQC7dlu1JSUlER7C2gF9yh+cK/iB/cq9nGP4gv3K7b03F0i0wH1oCs5oveqLiB9W5EqqfnUnv7e+jb1PMT3+D0VP7hX8SOW7pXb7daAAQPCfl5Ew5Thw4frr3/9q4488kgVFhaqpKREb7/9tu644w5dddVVys7O1uTJk5uur6iokCRlZWU5XquxT0rjNa3p1atXB3wFncPn86mkpEQFBQXyer3R3g4MuEfxg3sVP7hXsY97FF+4X7Epo94r7XKu21ZKRO/VJ7v8Csr5ffNhfbJUVJQakffsavg9FT+4V/GjK92riIYpp5xySrMf9+3bV5dddpkOOOAAnX766brtttuahSkdqT1lOtHm9Xrjct+JhHsUP7hX8YN7Ffu4R/GF+xVbklzmJrBByxvRe/V1lblCe3SPNKWkRL5fS1fC76n4wb2KH13hXoXdgLYjTJgwQf3799fKlSubVZo0VqSYqk8qKyubXQMAAADEPMNoZNuVIlmR/TY85CSffJrPAkBHiEqYIkn5+fmSpNra7zuct9QXpaV+KgAAAEAssgI1jjXbFfm/jf18lzNM6ZPuVm5y1L79B4AuJSp/mlZXV+vLL79Uenp6U6giSUcccYQkae7cuY7nzJkzp9k1AAAAQKyzTJUp7siGKYGgrRW7nWHKiDyqUgCgo0QsTKmsrNS3337rWK+trdW1116ryspKnX766UpK+r5tyxlnnKGsrCw99thj2rx5c9P65s2b9fjjjys/P19Tp06N1JYBAACAjhU0HfOJbAPYNZUNqm6wHesjOOIDAB0m7Aa0M2fO1KJFiyRJK1eulCQ9/fTTmj9/viRp3Lhxuuiii1RaWqpDDz1UY8aM0ZAhQ1RQUKDt27fr/fff1+bNmzV06FD94Q9/aPbaOTk5uueee3T55ZdrwoQJOuOMMyRJr7zyikpLS/WPf/yjaaoPAAAAEOuMx3wiXJliOuIjSSOpTAGADhN2mLJo0SI9++yzzdYWL16sxYsXN/34oosuUm5urv7nf/5HH3/8sWbPnq2ysjKlpqZqyJAhuvzyy/Wzn/1MqanOVP68885Tfn6+7r33Xv3f//2fLMvSqFGjNH36dB1zzDHhf4UAAABAtBiO+SjCPVNCNZ/lmA8AdJyww5QZM2ZoxowZrV6XlZWle+65p12bmjRpkiZNmtSu5wIAAACxwgrWOtYifczHFKZkeS0VZ7gj+r4AkEho5w0AAABEShQa0C43hCkj8jyyLCui7wsAiYQwBQAAAIgQK9C5lSklNQFtrw061umXAgAdizAFAAAAiBRTmOKOXJhCvxQA6ByEKQAAAECEWMbRyJE75hMyTMn3Ruw9ASAREaYAAAAAkWDbxtHIkZzmYwpTPC7pgOyw504AAFpAmAIAAABEQrDeuBzJYz7LdznDlINyPPK6aT4LAB2JMAUAAACIBMMRHylyx3yq/EGtrmhwrI/Ip18KAHQ0whQAAAAgAoxHfBS50cgrd/tlG9ZpPgsAHY8wBQAAAIgAK9C5lSmLS3zGdcIUAOh4hCkAAABAJBjGIkuR65nyxnpneOO2CFMAIBIIUwAAAIAIsEKEKXJ1fJiytSagD3c4K1OOKExWlpdv+QGgo/EnKwAAABAJwVCVKR1/zGfWevN7ndI3cmOYASCREaYAAAAAERC6Z0rHV6a8scH8XlOKIzeGGQASGWEKAAAAEAmhpvl0cAPa3fVBzdta71g/pLtHvdLdHfpeAIA9CFMAAAAQltK6gLbWBGTbpkG8aBSyMqWDj/n8Z0OtAoZbcUpfqlIAIFKSor0BAAAAxAfbtnXT0go9tKJKAVs6stCrxyfkqWca1Q9Gwc455hPqiM9UjvgAQMRQmQIAAIA2eWtjnf7yRVVTFcT8bT7d9klFdDcVw0JN8+nIypQqf1BzNzvDlKE5SRqYzd+bAkCkEKYAAACgTZ791tkD5F9rauQPctzHpDNGI8/ZXK+6gHN9aj+qUgAgkghTAAAA0CrbtrVku8+xXh+QvixriMKO4kDI0cgdF3S8EWIk8tRiRiIDQCQRpgAAAKBV66sCKqkNGh/7dKczZEFLo5E7JuioD9h6e6PzPfpmuDUiz9Mh7wEAMCNMAQAAQKsWl4QOTJbt8nfiTuKI4ZiPbbklV8cEHR9srVeF33nE6pS+qbIsq0PeAwBgRpgCAACAVi3ZXh/yMSpTzIw9U9xpHfb6IY/49OWIDwBEGmEKAAAAWrWkhcqUL0r98gVoQutgGI3cUUd8AkFbswwjkQtSXTqsh7dD3gMAEBphCgAAAFpUVh/UqhaazPqC0qoyjvrsywo4px+pg8YiL97u0846Zw+bKcWpcnHEBwAijjAFAAAALfpoh0+t1Z18tpMwxcHQgNbuoLHIHPEBgOgiTAEAAECLWjri04i+KU6WaTRyB4xFtm1br693BjXZXktHFibv9+sDAFpHmAIAAIAWLW6h+Wyjz5jo42Sa5tMBYcqyXX5tqg441k8sSpHXzREfAOgMhCkAAAAIyR+09UkbjvCs2O1XPU1om7FMx3w6oGfKPcsqjeun9O2YI0QAgNYRpgAAACCkL0r9qmloPSTxB6WVu6lO2Zt5NPL+BR7vbKozTvFJdVua2JsjPgDQWQhTAAAAENLiNvRLafQpTWibM/RM2Z8GtPUBW79aXGZ87MeD05SWxLf2ANBZ+BMXAAAAIS3Z7gxTXCHacny2iya0ezMd89mf0cgPrajSmkpnr5TcZEu/GZ3Z7tcFAISPMAUAAABGtm1riaH57LBcj/pluh3rVKbsw9iANq1dL7WxqkF/CtEr5fdjspWX4rwfAIDIIUwBAACA0YaqgLbWBB3rY3t4NTrf61hftduvujb0V0kIwQZZtiFccrWvMuV3H5Ube9ccnO/RRUPaF9AAANovKdobAAAAYbJteTf8XZ6tr8ny7YzY26TZtjJ9fnm2eOSy4nfcqu3OUEO3CaofPF1yOQMAhGY64iNJhxd4taU6oFfWNa+8aLD3TPX5QXd+nk39UqT2TfN5b0udXltnODIk6U/jcuQOde4KABAxhCkAAMQZ75oHlPrlzRF/H7ckjyR1gTYYSWUfyl2+TDWHPidZFOa2VcgwpYdXayqcvTsk6dOdPsIUheiXIklhHvPxBWxNX1xufOzCwWk6hJ9rAIgKvpsAACDOJK//R7S3EJc8O/6r5NUPRHsbcWVxibNfSu80t4oykjQq32N8zqe76JsiydgvRQq/MmXGyip9U97gWM/2WrrpkKx2bQ0AsP8IUwAAiCdBv1y166O9i7iV/PVtcu/+MNrbiAvlvqBW7nZ+iD+8YE8lRE6ySwOznE1PP9vZBUqZOoAVIkxRGKORt1QHdPdn5qazN47JUjeazgJA1BCmAAAQRyx/WbS3ENcsO6C0T38q8fPYqqU7fDK1kj2sx/fHSkZ3cx4x+bKsQTUNzqa1CSdkz5S2hym3fFyuakPT2ZF5Hl16QHq7twYA2H/0TAEAII5Y/t3G9UD6ENkpPTv0vQLBoOrr65ScnCK3Kx7//sWWe9d8WWr+wd5Vu1Fpy/+fasY8JcVxY91IC9UvZexeYcqofI/+taZ5aBCwpS9K/TqsR3JE9xfrQvVMaWuY8ulOn55fbQ5k7hmbTdNZAIgywhQAAOKI5TOHKfVDrpe/11kd+l51dXXauHGjioqKlJLSvnGu0Zb8zd1K+foOx7pn27/l3fB3+fr+NAq7MrNtW3UBKTUpNj4kLylxhinpSZaG533fK8VUmSJJn+0kTAl9zKf130u2beuGD81NZ384KE2HFyT2zy0AxIJ4/GsmAAASluUvNa7bnrxO3kl8qB/0SzXkH2V8LGXlDXJVfNHJOzJ7YXWNhr2wTUX/3KKz/rtTu+uje0ymIWhr6Q5nmPKD7l4l7VURMTLPI1P0QxNa7ddo5Dc21GmRIcxKS7L0+x/QdBYAYgGVKQAAxJFQx3yC3txO3kmcsNyqOfgxZcw7Ui7fruYPBeuV9skl8vc+P0qb22NdZYPWf1OjSyQpVdJu6e133LpoSJosY1Rh5m5oUM/ycqU3ZCspaf++xSutCehab7XklTYFC/Rm/dHaaefp8B7NK1GyvC4Nzk7S1/tMm6EJbftHI/sCtn7/kbkq5doRGeqZRtNZAIgFhCkAAMSRUMd8bE9O524kjtgpPVU7aobSPzrX8Zi7+lu5v74tCrv63oGSbsswPPB1+K+VIUm7Wruqdf0l3b7XnjYHeui4sr9rbMEhjmsPzvc4wpSvyhtU7Q8q3ZPARdCBGuNya5Upj39ZrbWVAcd6rzSXrhlm+oUCAIiGBP4/HAAA8SdUZQrHfFrW0OME1fe/JtrbiFu93dv167S/6ZDuzh4pBxv6pgRt6fPSxD7qE7IypYXRyKV1Ad39WYXxsd+NyUrscAoAYgx/IgMAEEdMlSm25ZaSMqOwm/hSd+Dv1ZA9OtrbiFsTUz5Wttf5rePobh7D1dKnOxM7TGnPaOS7l1Wq3OcchTwq36PzB7V8PAgA0LkIUwAAiCOmBrS2J5cRv23h8qp29N9lJ9HAsz16W1ukoDMgGZHnkWlK76e7ErtvSshpPiHClG/L/frbqmrjY7cdmi0Xv8cBIKYQpgAAEEdMx3w44tN2wfT+qhr7bwUyh0Z7K3HHrYBctZsc6xkel4ZkO9vwfZbolSkhjvmE6pny+6UVanAWpWhKcYqO6skoZACINTSgBQAgjrhMx3yY5BOWYPbBqjp6odRQKctQadEZfvp+qeZurm/TtS5L+s/J3TRnc73uXlYZ9nudMyBVd4/NadO1d35aocdWVevU5Hf1j6zfOfdSs1bB9P6O9YPzPfqyrHkT2q/LG/TfjXU6oaj1UcBdkRXimI9cKZKaV+3M21qvNzc4w5ckS7rlECqpACAWEaYAABBHQh7zQfiSMmUoBIi4uZvr9K9NtdozB3mv7VjSoT28WlSyz/EYW7p4ofRlmVtBO8fxeoOyklQXsLWp2jkBRpL+u92tu7ytVy+V+4J66Js6VdoeLW8YYrzGVbPWuH54j2Q9t9oZHvxqSZmO6lmg1KQEPKJiqEyxXSmS5SwMf/ALc0j2Pwela1C2uScNACC6OOYDAEAcsfxljjUqU+JHQ9DWDR+WGx/72UHpmnFUrgw9XrVyd4OChuSnMNWlNyd30xfnFurDU3J0ZK4zUFlbGdCWEEHL3p76qlqV/j1vsjpQZLzGVW0OU87on6rcZGdgsq4yoPs+D7+apiuwDKORTUd8KnxBvbvFWaWU47V0/cFUpQBArCJMAQAgXgT9shqcH0ypTIkf//iq2nEcRpLykl26/uAs9ctM0hVDM9r0Wi5LeuKYPPVIdUuSijPcmtjN+dqStLCk5SNF9QFbM1ZWNf243M7SrmC28z1DVKbkJLt0yyHO6yXp/uWV+rbcfJzKtm1trQnItqNRIxRZxtHIbudEnnc21ckfdF56xdAM5SbzrToAxCr+hAYAIE6Yms9KNKCNF7vrg7rj0wrjYzeMzlTOdx+crxuZqfw2fIi+cUyWjihs3ph0dLbhU7mkBdtaDlNeXFOjrTXNn2uqTgkVpkjSjwen6dDuziMpvqD0v4vLHYHJi6tr9IOXSnTQ89t0wPPb9P4Wc8PWuBUMccxnH7MMvVIk6bR+oUcoAwCijzAFAIA4YRmaz0oc84kXj66s0u56ZwXG0JwkXXJAetOPc5Jd+s3ozBZf64Q+ybp2hLOCpVeyrd5pzm/vFm4LPaY4aNt68PMqx7o5TFkvhagicVmW7h2XYxyT/N6Wer26bk9PlXJfUJe9X6qffbBbayr3HD/aXhvUBXNKta7SXFkTj0zHfLTPMR9fwNbsTc4wZUCmWwfm0NoQAGIZYQoAAHEidGUKYUqsC9q2nvnW8OFa0u2HZStpnwTikgPSjeOGJalPuluPHJUrl+VMLSxLGtvd+byvyhu0ozZEg9pNdfqq3BliVHj6Ol8/UC2rfrvxdSRpZL5Xlx2UbnzsN0vK9c6mOh312na9sMbZrLa6wdaf2jGtKGaZGtDuc8xn4Xa/KvzOcGpK31RZhvsLAIgdRN4AAMQJ0yQfSQq2YVILomv+Np82VjnDjEm9k3Vsb+fRjySXpT8cmq3z3tnVbN3jkp48Nk95Ke6Q7zWuh0cvrXdWoiws8RmPjjxgqEqRpAN7D5G2OdddNWsVSCkI+f43jM7Sq2trta22+bGhbbVBnT17V4hn7fHstzW6bmSmBmS1/VvU3fVBzVhZpbc31mlbjTkwyk9x6UeD03Xl0HRjCBUJxtHI+xzz+c8mc8XQlOLEHCcNAPGEyhQAAOJEyGM+npzO3QjC9n/fVBvXf3KguYpDkk4sStEvR35/lCfFLT1yVK4O6e5t8b3G9jCP0l1o6Jvy4fZ65yhm7al+GdU3vPHIjbK8Lt1xmLkZbWsCtvTHz8x9ZfZVWhfQbR9XaOSL23T3Z5Vatsuvktqg8Z+Vuxv02w/LdeW83WowjUWKhIAzTLHd34dZQVt6e7Pz575bikuHtnKPAQDRR2UKAABxIlRlCsd8YluVP6jX1zuPfHRLcen4Pi1XINz4g2xdMChdX5b5NbqbV73SQ1ekNBqY6VKPVJe271MZssAQmvz1C3NVylXDMuTKGGB8rLUwRdozKnnmNzV6zzDytzUvrq7VL0f6dUCOORQqrQvooRVVenRltaoawgtGnl9dq/qA9PiEXHlMzV06kHmaz/dhyqoql7bVOvd/clGK3BHeGwBg/1GZAgBAnLB8ZcZ1m2M+Me21dbWqNnzoP2dAaps+0A/MTtKUvqltClIkybIsjS9IdqyvKPWrrP77gGVTVYNxkkyO19JFQ9JkJxcap8+4qte1aQ9/GpstbyvfaWZ7nV+/Lemuz5y9U/xBW3d9VqGRL5bo3uVVYQcpjV5dV6sL55aqrp3PbzNjZcr3P5/v7TLfzyl9OeIDAPGAMAUAgDhhakBrW0mS2znVBbHj/0I0nr1gcOgjPvvriELnMRFb0qKS7ytFnvyqRgFDnvDTA9OV4XFJlkvBtH6Ox9tSmSJJg7I9unaEeSpRkiXd9IMsLTith5INmcLLa2u1otTf9OOahqB+PGeX7vy0st0hyt7e2linC+bsUk2DeZR0R7AMYYpc31emvG8IU9KTLE3oSZgCAPGAMAUAgDhhOuZje3L3jHBBTFpX2aAFhrHEI/I8GpFnPsbSEUyVKdKeJrSSVB+w9dTXzj4ubkv6yYHfh3P7E6ZI0nUjM/WDbs2/zoFZbs2e2l2/GJmpPhlJuvQAc6h056d7eqeU1Qd11n936e1NrR8ZOrLQqzP7pzb9c0a/VKUlmX9/zN1Sr3Nm71KlPwKBim0bG9A2Vqasrghoba3z2/CJvZOVGmK/AIDYQs8UAADihMvQgJYjPrHt2VBVKYPSjOsd5aDcJOUmW9pd37yKY8F3TWhfW1erHXXOEGFKcYp673WcKJje33GNy7dTaqiUksxVJ3tLTbL06knd9OAXVVq126+jCpN1weC0PZUv3/nFiEw99VWNavcpk3ljQ53e2VSnWz6u0Od7VamYnFSUousPztTobs6KnIXb6nXeO7tUaRhBvGCbT8Oe36buqS7lJbuUm+xSTrJL3VPcGl/g1QlFKe3rrRI0Bz+No5HfMjSelfaMRAYAxAfCFAAA4oTxmA/NZ2NW0Lb1nCFMSbKkcwZG9kOzy7I0riBZb+7TE2XZLr8q/UH9bZV5utD/HNT8yFgwzRmmSJKreq2C2SPbtJdMj0s3jM4K+XhBmlv/c1C6HjQ0w21tlPLJ34UoBxtClEbjC5P16onddOZ/d6rc5wxUKvy2KvwBrVbzscoPrZB6pLp0waA0XTg4XQOz2/5ts/GIjyR9V5nylmEkstuSTmylITEAIHZwzAcAgDhhPuaT0/kbQZssLPFpfVXAsX5CUYq6pbStmez+GF/gDBgCtvS3VdX6cIfzw/yBOUk6ap9eKyHDlDCO+rTFtSMylB7G8Za8ZJf+M7mbnp2U32KQ0ugH3b164+Tuyk8O71vf7bVB3f95lX7wcomm/GeHXlhdo9q29GwxHPGRJNuVqpKagJbubHA8dkRhsnLC3B8AIHr4ExsAgDhhmubDMZ/Y9X/fROeIT6MjC819Uxp7kezrpwemy9qn/05nhSndUty6YmjbGvL2TnPrP5O7aVyIvjChjMjzaNbkbipMbd+3vwu2+XTZB7s1+l/bNG9ry/1bjGORJcmdqrc21skUx0wppioFAOIJYQoAAPEg6JMVcB6D4JhPbKryB/XaOmd1Qn6ySyd00lGO4XkeZXqc1R4+Q7/VTI+l8w0hTzCtWLbh20V3dceGKZJ0zfBMZRn2u7dBWUl6a0o3HZDTvua9B+Z49Obk7uqb0f7KoG21Qf3kvdKWG9cGzEGa7U7RrA3mqpXJhCkAEFcIUwAAiAOWofmsRJgSq/69rlbVhuMg5wxMldfdOdNaklyWxvZo/QiMJJ0/ME2ZHsO3hS6v7NTezuUOrkyRpNxkl64cFnrM96h8j/4zuZuKMvav5d+ArCTNO62H7hmbrZ8dmK6zB6RqYu9kjenmUb9MtzGA2teOuqBeWG0OTKTQlSm1dore2+KsahmV79nvrwsA0Ln4UxsAgDhgaj4rccwnVkVris++xhcma/bm1kcK//Sg0Edsgmn95ard2GwtEmGKJF05NEOPrqxS2T6NYo8o9OrZifnK8nbM3wNmeV362UHm4CZo25q3tV4zv67R6+trjZU8kvTEqmr95ADn0ag9L2KuPllelmR8PY74AED8oTIFAIA4YGo+K1GZEmt8AVuvravVvG3OBq/D8zwamd+2SpGOckRh6+93VKFXB7ZwbMbUN8Wq3SwFzeN990dOskt/m5Cn5L1O4ZzVP1X/Or5bhwUprXFZlib0StETx+Tpy/MKdcdh2eqV5nzvlWUNWrzd/HMQqjJl4Q7z1zClmJHIABBvqEwBACAOhDrmE6QyJeps29aS7T69uKZWr6ytVWm9uZThh51clSJJB+d7leq2VBsIPYFm33HI+wqkG8IUBeWq2aBgxqD93uO+JvVJ0YpzC7Vgm0/FGW6NbsO0nkjJS3HrqmEZykt26Yp5zt+DT3xZbW6EG6JnyrslziqWvhluDc3lW3IAiDdUpgAAEAdCHvNhNHLU2Latx1ZWadS/SnTSmzv1xJfVIYOUJEs6d0DnVx943ZYOa6FvSu80d6tHTDpros/euqW4dVq/1KgGKXs7vV+q8gxji19bV6vttc7x16EqU3YHnD/XU/qmmI8KAQBiGmEKAABxgAa0sedPyyr1qyXl2lDl/DC9rxOLUtQ9tf0TZPbH+BaO+lxyQJqSXC1/kA+m9TOuRzJMiTUpSZZ+PNhZWeQPSv80jcAOhmpA66xiuXBw20ZCAwBiC2EKAABxgAa0sWXZLp/u+qyyTddmey3dekh2hHcU2hGFhmMokjwu6eIDWv8gH43KlFh06QHpMsVOf/+yWoFg82NUVohjPrV288qUowo8Oii3fWOeAQDRRZgCAEAcMIUptuWR3PytdmfzBWxdOW+3DJOPm+mT7ta0ERn66MwCDcyOXk+MH3TzNmvo2ui0fqnq0ZZqGU+Wgt58x7KrOrHClP5ZSZrY2xlMbaoOaPbm5pUooY751OwTpvzsAKb4AEC8IkwBACAOuHzOaT62N1ei10Knu3tZpVbubjA+luO1dMmQNM06uZuWn1Ogmw/JbltgEUGpSZYu3acCJcUt/XJkZptfw1Sd4qpZt79bizs/PdAcXj6xqrr5QojRyLX6PjzpnRLUxJ5UpQBAvKJ1OAAAccBYmeLhiE9n+2ynT/ctNx/vuWZYhm78QZaS3bEXcN30g2x5XZbe3linnGSXfn1wZljHS4Jp/aWypc3WXDXrJDsoWYnzd3Mn9ElRn3S3NlU375PzzuZ6ratsUL/MPd9aW4EQYcpePVPO7dkgdyv9agAAsStx/u8HAEAcM4cpNJ/tTPUBW1fN2y3TlOHheR79PkaDFGlPdcqth2ZryZkFentKdx3bO7zjJaYmtFawTlb9tg7aYXxwu5xVPpJkS/rHl3tVpxiO+TTYbjVoT4CVniSdWmCubgIAxAfCFAAA4oBpmo/tzen8jXRh1f6gbviwTMe+vl0Xzt2lF1fXqNr//ajjez6r1Moy5wfgJEt6+MgceWM0SOkIwfQQTWgTrG+KJF04JE0ew3fQT39To7rvGumYKlP27pdyXv8UZVAfDgBxjT/GAQCIAxzziSxfwNbZs3dpUYlPkvTpTr9eX1+n9CRLU4pTNK4gWfd9bj7e88tRmRqZH3r8cFfQ0kSfQP4Rnbyb6OqR6tZp/VL1rzXNA5PS+qBeXVer8welGXum7N0v5adDUqTyiG8VABBBVKYAABDrAvWyAtWOZY75dJzfflTeFKTsrbrB1gtravWLRWUhj/eE08g1XoUOU9Z17kZixE9CjJS+67MKvb6+VmowhCnf9Us5vneyBmZFtykxAGD/EaYAABDjTFUp0nfTfLDfXlhdo8f3ncbSBolwvKeRnVwg253mWHfVJN4xH0kaV+DV0BxngffayoAunFuqRVudZSeNx3yuGJYR8f0BACKPMAUAgBgXMkzhmM9++6LUr2sXlLXruf+bAMd7mliWsQltIvZMkSTLsvTTg8zVKZLkMvRMqbVTNDg7Scf2SjY8AwAQbwhTAACIcZav1LgepDJlv5TVB3XR3F2qNZ3facWIPI9+OarrH+/ZmzFMSdDKFEk6d2Ca8pLN30qnWvWOtVo7WZcflC6X1fUrmQAgERCmAAAQ40JXphCmtFfQtnXV/N1aUxkwPn7zD7J0zbAMFaY6v1VKS7L08FG58rgS60OxqW+Ky79b8pd1/mZiQKbHpb9NyFVusvPXQarlHI3ss1L3NKcFAHQJTPMBACDGEaZ0vPs/r9KbG5wfeCXpZwela9p3TWVvOSRL87fV68U1tfpsl18FqS5df3CmRuR5OnO7MaGlJrTB7IM7dzMx4rjeKfr0rEL985tq/e3Laq37LpwzVaZ0S09XhmmmMgAgLhGmAAAQ4ywfDWg70ntb6nTbJxXGxw7r7tXth2Y3/djtsjShV4om9EoxXp9IgunmMMVdvTZhwxRJykl26ZrhmbpyaIb+u6lOj62qVlq9s2dKv5wMhX+gDAAQq4jHAQCIcVSmdBxfwNY188sUNHyq7Z7i0j+OzUuI6TztEboyJXH7puzN7bJ0cnGqXjmxm7p5nWO2U7wc8QGAroTKFAAAYpwpTLFdXskdepoIzN7dUq9N1c4+KS5LeuKYPPVOd0dhV/EhmFok23LLspv//Hk2/lPu8mVR2lVscgeco7Ztd2oUdgIAiBTCFAAAYpzLMM3H9uRKTAUJ25Ltzl4W0p6Gs0f3ZGRti1weBVOL5K5Z12zZXbNG7po10dlTPHFxVAwAuhKO+QAAEOOMlSkc8WmXJdudxy+yPJauHpYRhd3En1BHfdA6KlMAoGshTAEAIMYZwxSaz4bNH7T16U6/Y/0H3b1yJ9iY4/YKZh4U7S3ErWBqUbS3AADoQIQpAADEONM0HypTwrei1K+aBmfn2cN6eKOwm/jk63OBbItT4uEKenLU0OPEaG8DANCB+L8hAAAxznzMJy8KO4lvpiM+knQ4YUqbBbOGq/qwl5S8+gG5q76K9nZin2UpkHWw6oZcLzulINq7AQB0IMIUAABiWaBOVqDGscwxn/B9tMMZpljac8wHbRfoNkE13SZEexsAAEQVx3wAAIhhpqoUiWM+7WGqTDkoJ0nZXr4dAgAA4Qn7u4fnn39e06ZN0zHHHKMePXooJydHzzzzTMjrKyoqdMMNN2j48OHq0aOHRowYoRtvvFFVVVXG64PBoB599FGNHz9ehYWFGjhwoH76059q3bp14W4VAIC4FypMCXo55hOOrTUBbawKONbplwIAANoj7DDltttu05NPPqmNGzeqoKDls5/V1dWaMmWKHn74YQ0ZMkRXXXWVBg8erAcffFCnnnqq6urqHM+ZNm2arr/+etm2rcsvv1wTJ07U66+/rmOPPVarV68Od7sAAMQ1y1dqXKcyJTwfhuiXQpgCAADaI+ww5cEHH9Ty5cu1evVq/eQnP2nx2gceeECff/65pk2bppdfflk333yzXn75ZU2bNk2ffPKJHn744WbXf/DBB5o5c6bGjx+v999/X7fccosee+wxPfPMM9q9e7emT58e7nYBAIhroY/55HTuRuIcYQoAAOhIYYcpxxxzjIqLi1u9zrZtPf3008rIyHCEINOnT1dGRoZmzpzZbL3xx7/97W/l9X7/zc3xxx+vI488UnPnztXGjRvD3TIAAHHLNBZZkmyO+YTlw+31jrW8ZJcGZtGLHwAAhC9i30GsXr1aW7du1cSJE5Went7ssfT0dB1++OGaM2eONm3apD59+kiS5s+fr/T0dI0dO9bxehMnTtT8+fO1YMECnX/++a2+v+kIUazy+XzN/o3Ywz2KH9yr+MG9ahtX7Xbjel0wTcEI/7+uq9yjuoCtz3b5HeuHdHOrvt4ZssSrrnK/EgH3Kj5wn+IH9yp+xOq9SklJCfs5EQ1TJGnAgAHGxwcMGKA5c+Zo9erV6tOnj6qrq7Vt2zYNHTpUbrfbeP3er9uaLVu2KBBwNpqLZSUlJdHeAlrBPYof3Kv4wb1qWe9dG5RpWN9YUq2gq3OqNeP9Hi2rcMkfdH6TNDipWhs3lkdhR5EV7/crkXCv4gP3KX5wr+JHLN0rt9sdMrdoScTClIqKCklSdna28fGsrKxm1zX+u3G9tetb06tXr7ZvNsp8Pp9KSkpUUFDQ7HgTYgf3KH5wr+IH96ptMquC0j4nfWxXsnoXD5YsK6Lv3VXu0euraiXVONYnDuqmoh6ezt9QhHSV+5UIuFfxgfsUP7hX8aMr3asue1C4PWU60eb1euNy34mEexQ/uFfxg3vVMk/QWTlhe3KVkpraaXuI93v0SWm1Y81tSWN7pSslKez2cTEv3u9XIuFexQfuU/zgXsWPrnCvIvYdRGMlSXm5uXx230qU1ipPWqtcAQCgKzI1oGUsctvZtq2PdjjPZY/M9yitCwYpAACgc0Tsu4iBAwdKktasWWN8vHG98br09HQVFhZq/fr1xl4n+14PAEAisPyljjXbS5jSVuurAiqpDTrWD+se36XFAAAguiIapvTs2VNLlixRdXXz8trq6motWbJEffv2bZrkI0lHHHGEqqurtXjxYsfrzZkzR5I0fvz4SG0ZAICYY/nLHGtUprTdh9vN0wIO60GYAgAA2i9iYYplWbrwwgtVVVWle+65p9lj99xzj6qqqnTxxRc3W2/88e23395sVNLs2bM1f/58HXfccSouLo7UlgEAiDkc89k/HxGmAACACAi7Ae3MmTO1aNEiSdLKlSslSU8//bTmz58vSRo3bpwuuugiSdK1116rN998U/fff7+WL1+uUaNGadmyZZo7d67GjBmjK6+8stlrH3300brooos0c+ZMTZgwQSeccIK2bdumV155Rbm5ubr77rv364sFACCuBGplBWsdy7Y3LwqbiU9LDGFKrzSX+qS7o7AbAADQVYQdpixatEjPPvtss7XFixc3O5rTGKakp6dr1qxZ+uMf/6jXX39d8+bNU0FBga655hpdf/31SjVMIrj//vs1dOhQPfXUU3rkkUeUnp6uqVOn6sYbb1T//v3D3S4AAHHL8jurUiQqU9qqyh/UF7v9jvVDe3hlRXisNAAA6NrCDlNmzJihGTNmtPn67Oxs3XnnnbrzzjvbdL3L5dIVV1yhK664ItytAQDQpZiO+EhSkAa0bfLJTr+CtnP9sB7Jnb8ZAADQpTATEACAGGWa5CNRmdJWoZrPHk6/FAAAsJ/CrkwBAKCtgratKv+efzK9ljI9ZPjhCFWZQpjSNh9ur3esJbulkXmeKOwGAAB0JYQpAID9Ztu2/vlNjV5cU6ttNQFV+oOq9Nmqamh+xuLM/qm6e2y2uqXQ/LMtTGORJRrQtkXQto2VKaPzvfK66ZcCAAD2D2EKAGC/NARtTVtYpn9+U9PqtS+vrdXCbfV6bEKeDqO4olUc82mftRUN+sMnFSrzORumMBIZAAB0BMIUAEC71TQE9ZP3duutjXVtfs622qBOe2unpg1L1bk5kdtbV+AKdcyHBrRGJTUB3bOsUk9+Va0GQ+NZiTAFAAB0DMIUAEC7lNUHdf47u7Q4RJPPltiS7ltRqzmZyXoiP6DBKR2/v67AVJliu1Ikd1oUdhO7qvxB3f95lR5eUaWaUCmKJLdF81kAANAx6AQIAAjbluqATn5zR7uClL0tr3Rr0n/K9e91tR20s67F1ICWIz7NVfmDOmHWDv1pWWWLQYok/Whwmrqn0q8HAADsPypTAABh+brMrzP/u0ubqgPGx9OSLE3snawsr0sZSZYyvS59vMOnd7c4J6tIUrnf1kXvluofx+TqjP5UXOzN8hvCFI74NPOXL6q0cndDi9ekJVn6+fAMTR+V2Um7AgAAXR1hCgCgzT7Z4dPZs3eptD5ofDwv2aUXjs/XId2bH6UI2rYeWlGlWz+ukN/8VN31WSVhyj6MYUoCVKa8t6VOj6+qVnqSpYsPSNcRhcnG63bXBzVjRVXI10mypIsPSNf0UZkqTKMiBQAAdBzCFABAm8zfVq/zZ+9yjDtu1CfdrZdPyNeQHI/jMZdl6efDM3VkYbJ+8l6p1lYG5FJAByd9qQPca/dcVCuVr255bHJ1g63ddUH1SHUlxHhbq26rY62rhynzttbr9Ld3Nf34lXW1+udx+TqxyNlY56EvqlTpN/96PKt/qn47JksDsvhWBwAAdDy+wwAAtOq/G+t00bu7VGc+2aOhOUn61wnd1Cu95b/9H93Nq/dP7aH/nb9VF5ddrcnJ85pf8GXL+0iT1L3t2+6Suvoxn9s/qWj2Y39Q+vmC3VpyRoFyk79v9barLqBHVpqrUl49MV/H9KKrMQAAiBwa0AIAWvTq2lpdMCd0kDK2h1dvTu7eapDSKMvr0gNFbzmDFLSJ7cmL9hYiptwX1Ic7nE2Nt9cG9ZslZc3W/vpFlbFK6sSiFIIUAAAQcYQpAICQnv66Wj95v1ShhqScWJSil0/MV05yeP87yS+f2wG7S0zB5G7R3kLELNhWr2CIX2vPra7V7E11kqSddQE9tqraeN1vDqbJLAAAiDzCFACAg23bmrGiSj9fUBbyw+3ZA1L1z+PylJYU/v9KXNXf7ucOE1dD90nR3kLEvB9i4lOjXywsU4UvqL98XqVqQ8I3uThFB3fzGp4JAADQseiZAgBoUu0P6l9ravXEl9VaXuoPed3FQ9L053E5crva0QTWDshVvWY/dpmYbFey6g66TcHMg6K9lYh5f2vLYcqm6oCmLSzTWxvrjI//mqoUAADQSQhTAABatduvv39Vree/rVFFiOkoja4ZlqE/HJoly2rfNB1XzQZZtjOoeajmfD1Zd7pG5nn0wBHfN1md+XW1/vGV+UhHozHdvPrT2Ox27ynW2ZZLwYwDJXfX7QWyrSagL8saWr3u5bW1xvVT+qZoZD5VKQAAoHMQpgBAAtpeG9DiEp+WbPdpYUm9Pt0ZugplbzeMztT0UZn7FVqEOuLzvv9QLW0YoU93SDen9VSWd8/xoRlbt+uLhpb3t3SbdGBJjn5yYHq794Xoaq0qpTXXH5zVQTsBAABoHWEKACQA27Y1a0OdZm2o05KSeq2pDDGapwV3HJatq4Zl7PdeXNXfGNe/DvSVJAVsad7Wek3pm6q1FQ36ooXjRnv7/Uflmtg7WX0z+V9bPArVL8XrknzBlp97Wr8UDc/zRGBXAAAAZjSgBYAuzrZtXfJeqX48t1TPflsTdpCSm2zpiQm5HRKkSJKrarVx/ZuGvk3//e53H6xfX28+0mFq1VLVYH/XMLflY0qIPbZtG8OUfplu3XRIdovPtURVCgAA6HyEKQDQxb2zuV6vrTM37GzJ6G4ePXhEjlacW6izBqR12H7chmM+GwOFqtH37zF38579/tsQprgt6ZGjch3rkvTB1vpW+6sg9qyuaNDmGmfIN6Fnsq44KF2Hdg9ddXJG/1QNzaUqBQAAdC7CFADo4l5cU9Pma1Pdln48OE3vntJd757SQxcOSW/X6OOWmHqmfBXo1+zHayoDWritXkt3OI/4HFGYrHMHpunCweaA56aPKrSjNvxjTIie90Ic8TmmV7LcLkt/PTJXXsMvwz1VKUzwAQAAnY8wBQC6sPqArbc2tFyVkpfs0slFKbpnbLZWnVeovx6Zq9HdIjQVpaFarrrNjuWv9zri02j64jLjS5zad89Em9sOy1afdLfj8aoGW3/9omr/9olOFar57FE9kyVJB+R4jEd5LhicpgNyqEoBAACdjy59ANCFvbel3jjqeFyBVz8clKZxBV4NykrqtJHCrmpzv5SvAv0dayt2O8fkWpKm9k2VJGV7XfrLETk687+7HNf97ctq/b8RGcpPcYYtiC2BoK15hjBlRJ5H3fa6f78YmaFKf1AzVlapISidXJSiP43N6cSdAgAAfI8wBQC6sNfWmRu43nJIlg7rkdzJu5HcIcIUf9pAybzVZg7r4VVh2vcfsI/rnaJT+qbo9fXNq2+qv6tOaa15KaJvealfZT5n4DehZ/Nfny7L0s2HZOu3Y7JU7beVk0xxLQAAiB6+EwGALsoXsDVrgzOh6JXm0iHdI3SMpxWhxiL37HFgm55/yndHfPb2qxCTXB5bVa1ddYnXO2VtRYNuWVquOz+t0FZDU9dYE2ok8jG9zGGfx2URpAAAgKjjuxEA6KLmbatXueFv/E/pmypXJx3r2Zep+axteTSqaGCbnt94xGdvI/I8mlrsDFmqG2w9tCKxeqe8tKZGh79Sovs+r9Jdn1Vq/KslWrrDF+1tteg9wxEfj2vPUTQAAIBYRZgCAF1UqCM+p/VzBhKdxVXlDFMCqf00tjBVqe6WA55R+R71yzSfTv1ViIkuj62sVmmCVKe8uaFWl32wW77g92u7621dOHeXtsVohUpdg63FJc4w5dDuXqV7+BYFAADELr5TAYAuqCFo6431zik+BakuHd4jSn/jb9tyGypTGtIHKdlt6cjClvd1qqEqpdHIfK8mG6pTqhpsPbyiOvy97qfaBltPf12tuz+r0CJDWNDR3ttSp0veLVXAWYikrTVBXfxuqXymB6NsyXafTFnXhBBHfAAAAGIFYQoAdBJfwNbDK6p02ls7ddkHpVpb4ZxW01Hmb6tXaX3QsX5K31S5XdE54mP5dshqqHCsB9IGSJKO7e0MQ/Zm6peyt1+NMlenPLqqSrsNPxeR4g/aOv3tnfr5gjLd8WmlJr+5Uw9+URmx91tUUq8L5pQ2q0jZ15LtPl2/pCxie2ivD7aax3Yf05MwBQAAxDbCFADoJLd/UqEbPizX+1vr9cLqWh312nZ9tD0y/SxCHfE5NZpHfAxVKZLUkLanX8pxvUN/gD4wJ0lDcjwtvv7B3bw6qcgZuFT6O7d3ypNfVWvJXvfVlnTjRxV6a2MbxhWF6bOdPp03e5dqGlqvOvnHVzV68qvOr9JpyXuG5rMZSZbGRKlBMgAAQFsRpgBAJ9hZF9Bf9/lAX9Vg6+zZO7V8V3iBim3bem1drc58e6dOfnOH/vFltYL29x+mA0HbMSpYkrqluDQ+ik09Tf1SJCnwXZhyQHaSeqWZ/7d0SgtHfPb265C9U6pU1gnVKbZt62+rzIHFZR/s1uryjqtGWrnbrzP+u1MV/rYf35m+uExLOuHYUVuU1Qf16S6/Y/2InsnyRKl6CgAAoK0IUwCgE7y6ttbYz+L/t3fn4VFUWRvA3+o96ewrBEiAAEIgAQJhCZsEBBVUVMAFXFCcGdRx/WZERUUdh2EcxBlGHXAQxRV3QXQUwiKbCMqmLIFAACEJIUln6U7v9f2BCQlVnXQnnaSX9/c8eTRV1VW3Od23U6fvPbfCKuKGb0uRZ5DeVMo5UWnHjd+W4o6NZdhw1oIdxVY8vMOAB7YZ4HBeuMD2YivOm6WJg8nJOqja8SZVrl4KcHFkiiAILqf6NDXFp9aAOA0myoxOqbSJePVg649O2VZsxREXCZNKq4iZG0pRbWt5UudklR3Xf3Me5Rb5RMrVyTroVdJY25zA7RvLfGLJ5K1FFjhlmj+GU3yIiIjIDzCZQkTUBj454XqKx3mzE1O+OY+CKtejFqwOEYv2VWH458XYIDM14p2jJty7tRwOp4jVPriKDyA/zceuCIeojq37fXr3UMkx/WPVSI9pfIpPfa5Gp/ynDUanLHcxKqXWIYMdf9xqgCi2rBjsQ9sNKK6Rfy5Tuobg7bExeHVUtOz+4honbt9QCks7F6TdLLMkMgBczuKzRERE5AeYTCEiamWnq+3YUdz4VJ6zJieu+995nDVKRwzsKLZg9OpzeP6nStmVT2qtyr+wNO6ak9JkSrRWwMh2/sZfbpqPWZMCCBdHUIxJ0uKBfmGoHUCTHKbEkhFREAT3R9QMjNNgQmfpc620ilgt82/jLUUmh+y//aU+K6iRTPnyxL5SKzbKJNQAYGJnLZaNjoZSIeC6riF4NCNM9rhdJTYs+bnt6sjI+U7mOSSEKNAnSn75ayIiIiJfwr9YiIha2WeNjEqp72S1A9d9cx5jk7QoNDlQaHLgrNGBsyb3R1O4GgEzKTmkfetQOO1QmE5INpvVyZJtz2VF4p4+epSanUiLVkOj9Lzdjw2IwLe/lki2f3vajNt76T0+nzvezjPCjTqwAIBndlciI0bTrCWAX3WRiBnVQYM3x8Y2+Pd6YmAE9pfasO6MNHGx4rARj2aEeZSo8pYik0N2OtTojtp2aQ8RERGRpzgyhYiolX103P3REEcr7Fh2yIg1J83YXWLzKJHSmHaf4lNzCoIorQtj0aTIHt8lTIUBcZpmJVIAYFC8Bv1kpgZtLrTA2grTW+xOEW8eMUm2CwAiNdLn4BSBuzaVNTq1S06RyYFPZRJmYSoBb+fEIuSSOilKhYDXx8QgNUIpecwZkwP7y9yr1eNtW1xM8WG9FCIiIvIXTKYQEbWiPIMNB2RuWIcmaJAZ534dkEsJAKZ3D0GoTJHRS0VohHa/SXW1LLJZIx2Z4i1XyCy1XGUTGyxb7C3/O23GGZmirhO66LDi8hjIDQoqtTgx+otzWH64usFqTI357yEj5OrXzuwViiit/Ed6lFaB+YMjZfd9fUq66lNb+M5FMmUUkylERETkJ5hMISJqRR+7mHYzs2coPpkQh7Roz2db9otRY/3keCwbE4OProiVXbWlvqu76Jo9wsNbFNVHZbe3ZjJlfGf5FYDW/+r9BMIbh+ULz959mR45nXR4KjNCdn+lTcSjOyowYW2JbNKtvhq7iDeOSK+jEIA/pMnXRqmVk6SFVjo4Bf877TvJlOQwJbqGc/YxERER+QcmU4iIWokoivjkuHTqh0YBXJMSgmitAp9PjJOdgiEnVCXgL1kR2HRNPAbFawAAIzpo8emEWISrXSdLpnRr3yk+AKAw5stut8jUTPGWIQkaRMj8u6w7490EQn6FXXaFpZQwJcb9NjrmofQwTE52vbzz7hIbLl99Dk/vqoDRxdLJq/JNKJNZjWhSsq7JJIRercDlMqM+9pbacEam6HFrKqiy42S19JqjOSqFiIiI/AiTKURErWRfqQ35ldKbxvGddXVTMhJClFh9ZTxGdNA0OCZep0BGjBpXdtHhrsv0+PvQSOy5MRH39wuH6pI5I0MTtfhsYhwiZGpzRGgEjE1yfRPfVpQy03wc2k5wKlqvbWqFILvM7sFyu1cTCHKjRQBg1mV6KH+LlSAIeG10dKMjkRwi8K+fqzHs83PYUdwwOeMURZeFZ+/t2/iolFpXdpFPqn3TxqNTXNVLYTKFiIiI/AnH0xIRtRJXhWendW94U9tJr8SXV8bhvNkJk11Eh1AltB5Oyxkcr8EXE+Nw/TfnYbBerL/x5MAIj8/VGuRqptj1qa1+3fGddVh9UposyD3jnVV9auwi3j0qTaZoFBfqmNQXrlbgq6vi8efvDfiwkaLEp6sdmPLNebwxJgaTUkJ+a68FeTKr3wyMU2NYgkayXc7ELjpgh3T7/07X4K7erbPCkRxXyRTWSyEiIiJ/wpEpRBR0thZZcPP6Ukz55rzsNBxvcIoiPjshPXeYSrhwU3sJQRAQH6JESriq2cmPgXEa/HBDIh7oF4Zbe4TivXEx+F2ftrtJdsleDYX5rGSzI6R7q196XCf5kS/rvFQ35dMTpgbJq1pTuoUgTiedvhWlVWDZmBh8NiEW3cJdT++yOIDbN5bhvd8SNS5HpaS5v7Rxkl6JgTJFjzcXWlDtYmqRt4miKFsvpVekCh1D3ZvuRkREROQLODKFiILKTyVWTP76fN3vm85a4BCB6amhjTzKc9uLrbLLGl+drEOoqvXy2AkhSjyXJb9yS3txVS/Fru/R6tfupFciLVqFg+UNR3VsPmuBzSlCLbfMjgeWN1J4tjFjO+mwfUoiFu2rwj9/rpJdocchAvduNWBfqQ0bZWqyJIUqPK6Hc2UXHfacb1jo1uIANp614JqU1q+tc7TCjqIa6ZPlFB8iIiLyNxyZQkRBZfGBKsm2+bsrYHO6tzStu1yNeJna3btJG3+gdJFMcYS2/sgUALhCZnRKpReWSN5WZMFP56Ur8PSLUWOIG1NvQlQC5g2KwJbrEjA80fXxSw/JJ2zu6RPmcTLoKplRUUDbreqzpYhTfIiIiCgwMJlCREHD7hSxWeYb/rMmJ1YXuK5h4SmrQ8TnMueL0SowtlPw3TQqjPLLIttDW79mCtA6SyQXVNlx58Yy2X2ze+vdnnoDAL2j1Fh7VRzu8aBuSahKwJ1NjH6Rkx6jRme9dDrNN6fNcHg5oShHbooPAIzq4F7dFyIiIiJfwWQKEQWNH0usqLTJ3zC+dlC+JkVzbDxrQblFep3ruupaPK3EHymqpSNTRIUGTl3nNrn+sESN7NLRza2bYrA4cdO6UpSYpdNVwtUCpnb3fLqMQhDw92GR+FP/cLeOv7VHKKK1nn+EC4KAK2VGp5w3O7G7pGUjdZriFEVsKZReIz1GjRiZ+jJEREREvozJFCIKGhtkRqXU2l1i89rNpKspPjcG4RQfQH5kijO0OyC0zQ20WiFgjMw0kl/K7Tjr4RLJVoeI2zaU4ojMyjoAcH+/MISpm/fRKggCnsyMwIIhTde8+UNa8wsLX5XcPlN9fim3o8wiTUCN6shRKUREROR/mEwhoqCx4UzjN4v/8cLolEPlNqw+KZ3ikxSqQHYjdTEClijK1kxxtkHx2fqucDXVp4nXRH2iKOLB7QZsKZJPuk3orMWjGe6NLGnMnL5heG1UNFwt6jSxiw49IqWr8rhrZActwlTSk3/dyskUV1N8WHyWiIiI/BGTKUQUFAwWJ36UKRZa3+cnajweqVBfpdWJ2zaUwSxzihu6hULhQR2NQCFYSyDYKyXbHWFtm0zxRt2UF/dV4f1j8qOO0mPUeOPyGKi8NI3rlh6heDsnBlqZwTsPpYe16NxapYAcmdo9hw12nKiUH3HjDXLJFKUAZCcymUJERET+h8kUIgoKmwstaKq+pl0Elh9u3ugUURRx75ZyHHNxM3pLjyCd4lMtX3y2rUemdNIrkRalkmzf9NsSyXLMdhFHDDZ8daoGz/1Ygb/uka4EBVwYdbRqfGyzp/e4cnVyCD6bEIfu4RcyKjol8HxWBIZ7IflwVbJ8XZfWGp1id4rYLrOSz8A4NSI0/FOEiIiI/I/0L0siogC00c3pHCuOmPB//SMQIjMNQkIUoTr3NZTlP+Knc9UYXWrFaJlSFhmxagwq1gLFHjY6ACiq82S3t3UyBbgwOuWgoWGyrNIm4odzVozooEWVzYkP8034+pQZhw12nDE60NT6NmEqAauuiEOSzAo53pDdQYvvr0/Er0YHorWKZhWdlTOhsxYKAZIE49enanBv35aNfJGzt9SGKpniz5ziQ0RERP6KyRQiCniiKCK3keKz9ZVZnPjouAm392q6wGfIgQegOf02ACAbQLarh5gBHHevrcHCGdYTkNYibVXjO+vwr5+lI4/eOmLEx8dN+Ci/BtV295cHVgrAm2NjkB7T/Pol7tAoBXSP8O7HdaxOiaEJGuwoblj/ZXuxFQaLE1FeStrUYr0UIiIiCjQcW0tEAe94pQOnq6WFTOSmfQDAf36phig2flOtqDpYl0ghzzjVURDVMW1+3WEJGtnCqx8er8GKIyaPEikA8I9hUS5rsfiDq2SWSHaITRfldThFfHLchOd+rMCXJ2uafK8A8skUjQIYkhCERZmJiIgoIDCZQkQBb8NZ+ZvDR/qHo3+sdFTBQYPd5TfptVTnN3ulbcHIGdYbaIdivBqlgDFJ3hkJ8UC/MMzq3fzliX2BqyWS18isRlXL4RQxa1MZ7t5cjpf2V2PmhjL8cZuh0YSKxSHi+2Lp+ykrQYNQFf8MISIiIv/Ev2KIKOBtOCO9kRMAjE3SYk6afH2I1w4aGz2n0vCTN5oWlGydbmq3a7taItkdAoDUCCVeGBKJZwdHeK9R7aRnpBo9ZKYPfVFgdrnK0Uv7q7D6ZMN97xw1YeFe+eK8ALCrxCq7whWn+BAREZE/Y80UIgpoNqeILTKjTAbEqRGrU+L6biF4encFztU0LODxzWkzjlfaXdaqcJTtbpX2BjKntiOsKXfCmnxHu7VhvMySwHIGxqkxIFaN7hEqdA9XITVSha5hKujcKUzsR65K1mGJTB2ZOVvKsW1KAiLqPd3tRRYscJE0+dveKvSKVOGG7tJVq1gvhYiIiAIRkylEFNB2nbPK1sLI+W26h1Yp4K7L9PjbJTeJIoClB6uxcFiU5LGCtRwh5hOS7StqpmCB8ALWT05AJJd7laFol+k99XUOU2FUBw22FFkl+/QqAdNTQ3BX77BWLyrrK2b31uP1Q9WSkSMlZifu3VKOlaMuTGUqszhxz+bKRpcXv3drOVLCVRgUf7EOyskqOz45bpIcG6oSMCiO9VKIiIjIf/GvfSIKaBtcrOIzttPF6R539dZDLvfxzlETDBbpkjPWUvlRKT86+uOtnAREatWAoOSP5Mc3RnUsGh6FbuEXlzJOi1LhH8MiceimDlicHR00iRQASAlX4YUhkbL71p+xYHmeGaIIPPh9Nc6YZObq1GN2ALfmluKM8cJxn5+owajV55BfKX3csAQNNErfeD0QERERNQdHphBRQNsoszKJXiVgSL1vzxNClLixeyjeP9bwG3SjXcTyw0Y82j+8wfa8EzsRJ3Ot6A5ZSIsOnhtxf9UrSo1dNyRib6kNcToFUsKUEHwk0dMe7rpMj/W/WvD1ael75fm9JuxNUGNdkc2tcxXXOHHz+lIMilPjzTzpiJRa3ioETERERNReODKFiAJWucWJn85LbwJHdtRKvhW/t698Idqlh6phrjdNSBRFWEt/lBxXI2pxRZ+BLWwxtRWVQsDgeA26hquCOpECAIIg4N8jo9AxVPongdUJfFIknyCM1sr/ux0oszWaSInSCLilh7S2ChEREZE/YTKFiALWprNmyJV4yJH5Vjw9Ro1xMsVJz9U4sSr/4o3hrnMW9MF+yXF56Iv+Cf69VC4Fr1idEv8ZFQ1300qJIQpsn5LodkHfWt3DlVh9ZRwSQpRNH0xERETkw5hMIaKAJbckMgDkuLgBfKBfuOz2JT9Xw/Fb5c0vDh1FoqJUelB0ZvMaSeQjxiTp8GC6/Ait+gQAy0ZHo2OoEssvj0HvKPdmDE9PDcHm6xKQEcvCs0REROT/mEwhooAkiiI2yhSf7axXooeL5Y5Hd9Sgf6x0SsOxSju+Om1GmdmB0qJdso9NSR7asgYT+YAnBkZgYFzjdX8ezQjHmKQLBZwjNQp8MD4WMVrXf07oVQJeGxWNZaNjEK7mnx1EREQUGPhXDREFpGNVTvxqlK4iktNJ67JGhiAIeLCf/Dfz/zpQhXePmjBQcUB2vzJmcPMbS+QjNEoB/x0dA71K/j0yPFGDuQMbjuDqGq7COzkxkMuTZMSosfnaeNZIISIiooDDZAoRBaTNhVbZ7ePqLYks59quIUgJk9Zz2FViw4v7qzBE/bNkn10VDWdo12a1k8jXpEaq8OIw6XLJ0VoBr4+OhkohTbRkd9DirbExiNRc2KdRAPf1DcO6yfHoEckVroiIiCjwcGlkIgo4NQ7gzaPSZV4VAjC6Y+MFM1UKAff3C8Ofvq+Q7Ku22jE4QppMEaMHAUG+IgwFllt6hOKM0YEX9lQBAGK1At4fH4vOYa7/bLg6OQT7pmpxrNKObuFKxOpYZJaIiIgCF0emEFHA+cdxDY5VOSXbM+PUiG6ktkOtGT1DZWtA9FEeR5iiRrLdEcXisxRYBEHAnwZE4Ofro/FmfzN+vC4aQxKaXrknSqvA4HgNEylEREQU8JhMIaKA8vlJC1YXy397Pr27e3UbQlUK3NNHuszxELV8vRRH5CD3G0jkR+J0CvQNd0Kn5MgrIiIiovqYTCGigFFQZcefdhll92XGqXHnZdIEiSv39NEj5JIbSJfJFI5MISIiIiIKKkymEJFfKKiy4w/flaHH+4UYt+Yclh2sRo1drNtvc4qYvbkMVTZR8thwtYDlY2Kg8eDb9TidEjN7NhzJMkQlTaY4Q5IhauM9eCZEREREROTvmEwhIp8miiLeOWrEyM/P4YP8Gpw3O/HjeRv+vLMC/T8uwj8PVKHK5sQLP1Vid4lN9hwvDY9CtwjP623f1y8MtQuX6GBGhipPcow9ilN8iIiIiIiCDVfzISKfdd7swIPbDFh7SroyDwCcq3Himd2VeGl/FSqs0hEpAHBrj1BMS3WvVsqluoarcF1KCD4rqMFA1SGoBIfkGEckp/gQEREREQUbjkwhIp/0v9M1GP7ZOZeJlPpcJVJ6RKjw92GRLWrHI/3DoVWyXgoREREREV3EkSlE1G6qbE4UmRwoMjlRXONAkcmB4honjlbY8b/TTSdRGqNRAMsvj0aYumU54/QYNZaNjkHE3p8l+0Qo4Ijs36LzExERERGR/2EyhYhalcUhYs3JGuwusaLY5ERRjQPFvyVNjHb5ESXeMK9/KPrHarxyruu6hiDsxEHA1HC7M7w3oArzyjWIiIiIiMh/MJlCRK3GZHdi6rel2F5s9cr54nQKvJwdhTC1gH/sq8LWIvnzjox24J7LdF65JgAI1jIoTSck2x0sPktEREREFJSYTCGiVjN3Z4XXEilXdtHhXyOikBCiBABcnqTD98UWLNpXhXVnLHXHpUUp8XQvEwTB/WWQm6I0/CS7nSv5EBEREREFJyZTiKhVfJhvwso8U9MHNkGvErBgaCRu6xkqSZAMS9Tiowla/FJmw+ZCC2J1CoxPEFBWVNXi69anrPhRdjtX8iEiIiIiCk5MphCR1x2tsOHh7YZmPz5cLaBDqBJjk7S4t28YuoY33lX1jVGjb4waAGA2m1HW7CvLkxuZIipC4Azv4+UrERERERGRP2AyhSjICaYCqEs2QLCVe+V8NqeIrYeNeEDjBC6p/6oUgFitAmEaAWEqAWFqBcLUCoSrBYSpa38XoFXWG4FS/NuPmxR2OzoYKhDqiIRa5Z0uTlm+U7LNEdkfUKi9cn4iIiIiIvIvTKYQBTFVyUaE/jgDgqPl03Fq6QA8pATQ2CI3TgDW3368TAcgHABKvX/u+hxRnOJDRERERBSsFO3dACJqP7rDT3k1kRJMuJIPEREREVHwYjKFKEgJlhIoK39u72b4La7kQ0REREQUvJhMIQpSysr97d0Ev2WPHg4xtGt7N4OIiIiIiNoJa6YQBSllxb72boLfEaGAI2YYTAOWtndTiIiIiIioHTGZQhSk5JIpokKDqrEHAIX7XcM/9lXi1V+MsvtuTg3BX4dGNbeJzWI2m3H27FkkJSVBp9N59dyiQgeo9F49JxERERER+R8mU4iClKJSmkxxhKdB1CW6fY53jhrx/M9mSNZABpAWrcK84QkQVYL0ga1IdJphV5ogamIharybTCEiIiIiIgKYTCEKCL9W2/H9OSt2Flux85wV52oc6BOtxrODI5ARK010wGaA0lQg2eyM6O/2NbcUWvDQNoPsvmitgLfHxiKkjRMpREREREREbYHJFCI/ZHOK+Ph4Ddb/asbOc1b8anRIjimqsWDH2hK8Nioa13cLbbBPWSFffNYR6V4y5ViFDbdtKIVdlO5TK4C3c2KRGsnuhYiIiIiIAhPvdoj8jNku4ubcUmw6a2n6WAcwa1M58irs+HP/cAjChZEiSpkpPoB7yZQyswPT15XCYJXJpAD4Z3YURnbQNnkeIiIiIiIif8WlkYn8iMMpYvbmMrcSKfUt2FOF2ZvLUfPbUBK5kSmioIQjPK3R81gdImZuKMPxKulIGAB4NCMMt/ZkgVYiIiIiIgpsTKYQ+QlRFPHoDgO+PGVu1uM/OVGDSV+XoMjkkF3Jxxl2GaAMafQcL+2vwvZiq+y+KV1D8GRmRLPaRkRERERE5E+YTCHyE3/bW4U380xNHherdf22/um8DdesKYDCeFSyr6kpPqeq7Xj5QJXsvsHxarw2KhoKgQVniYiIiIgo8LFmCpEfeOOwEQv3yicyIjQCbuwWgmGJWgxN0CAlTIkVR0z40/cGOGTKmsTbDkKAdIejiZV8ntpVAbPM7J7OeiXeG8eVe4iIiIiIKHi0yciU9PR0REVFyf5MmjRJcrzFYsHChQuRmZmJxMRE9O7dGw8++CBKSkraorlEPuWLgho8usMguy9EKeCj8bFYnB2Nm1JD0TVcBUEQcFdvPT6dEItIjTTBkak6JHuuxkamfFdowRcF0ulFAoC3c2KQEKJ067kQEREREREFgjYbmRIREYE5c+ZIticnJzf43el04tZbb0Vubi6ysrJw7bXXIj8/HytXrsTmzZuxfv16xMXFtVWzidrVlkIL7tlcJjOOBFAKwBuXR2NoovzKOWOSdMidHI+b1pciv/LikJJM1UHJsU5RwL9Pd8WsCBG6S0aY2J0i5u40yF7j9l6hGBincfv5EBERERERBYI2S6ZERkbi8ccfb/K49957D7m5uZg6dSpef/31uqVc33jjDTzyyCP4y1/+gpdffrmVW0vU/s4aHZi5oRRWp/z+f46IwlXJjReM7RGpxvrJCbhjYxm+K7ywApBcMiXP0RWP/+TE2yfO4Z2cWHSPuNg1vHnEiIPldsljIjQCnhrEgrNERERERBR8fK4A7cqVKwEATz/9dF0iBQBmzZqFrl274qOPPkJNTU17NY+ozTz/UyUqrHJjUoBnBkVgpptLEEdrFfhkQizmD4pAnNqKvqp8yTE/2fsAAA6W23H5mnP45vSFKT1lZgde2FMpe965AyIQp+P0HiIiIiIiCj5tNjLFarXi3XffRVFREcLDw5GZmYnBgwc3OMZsNmP37t3o2bOnZPqPIAgYO3YsVqxYgT179iA7O7utmk7U5g6U2fDBMfmVe/6QpsdD6WEenU+tEPBQRjjuSjwM1W5pFdmfbGl1/19pFXHz+lLMHRiOYpMT5RZpQueySBXu6eNeMoeIiIiIiCjQtFkypbi4GPfdd1+DbZmZmVi+fDm6desGADhx4gScTie6d+8ue47a7fn5+U0mU8xmabFMX2W1Whv8l3xPW8foqZ2VsnVSJnXW4OkMLSwWS7POG1m1R3Z77ciUWiKABXvkVw8CgGcHhsBhtUBmcZ92x/eT/2CsfB9j5F8YL//BWPkHxsl/MFb+w1djpdPpPH5MmyRTZsyYgeHDhyMtLQ16vR7Hjh3DK6+8glWrVuHaa6/F9u3bER4ejsrKC9MJIiMjZc8TEXGhPkPtcY05e/YsHA5fvNVzrbi4uL2bQE1oixh9X67ApiLpm1mrEHFvxwqc+dXQ7HOnFO+Q3b7nkmRKY0bH2JFqL8bp081uRpvg+8l/MFa+jzHyL4yX/2Cs/APj5D8YK//hS7FSKpUuB3Q0pk2SKXPnzm3we0ZGBpYuXQoAWLVqFd566y3cf//9Xr1mUlKSV8/XmqxWK4qLi5GYmAiNhiuj+KK2ipHDKeK1nysAmTEfc/qEYlCPlq1kFVV4XLLNpkvG+JR4fFzQdHZYowD+nh2HLuG+WyuF7yf/wVj5PsbIvzBe/oOx8g+Mk/9grPxHIMWqzab5yJk1axZWrVqFnTt34v77768beVJRUSF7fO2IlNrjGtOcYTrtTaPR+GW7g0lrx+i9o0YcNEgTKXE6BR4ZEAWdpgU1o502qIyHpNujBuD1zDhkHTLiyR8qYJeveQsAuK9vGHrH+0etFL6f/Adj5fsYI//CePkPxso/ME7+g7HyH4EQq3ZdzSc2NhYAYDJdKLTZtWtXKBQKHD8u/fYcQN321NTUtmkgURuqsYt44Sf5OiWPDQhHREsSKQAU1YchOKWjTxyR/SEIAn6fFoYvroxDvE7+Oh1CFHikf3iL2kBERERERBQI2jWZsnv3bgCoW7knJCQEgwYNwtGjR3Hq1KkGx4qiiI0bN0Kv12PgwIFt3lai1vbawWqcMUlHpaRGKHHnZS0fDaKs2Ce73RHRv+7/R3TQYvO1CciKVzc4RgCwcFgUwtU+t5o6ERERERFRm2v1O6O8vLy6kSeXbp8/fz4AYOrUqXXb77jjDgDAc889B1G8ON9gxYoVKCgowLRp0xASEtK6jSZqY+fNDizeLz8q5ZlBkVArhBZfw2UyJTKjwe9JeiW+vCoezwyKQK9IFYYmaPDfMdG4rivfd0REREREREAb1Ez55JNP8OqrryI7OxtdunRBaGgojh07hnXr1sFms+GRRx7BiBEj6o6/9dZb8dlnn+Hjjz/GyZMnMWLECBw/fhxr1qxBSkoK5s2b19pNJmpzf99bhSqbtFjJ0AQNrknxzlxCZeUByTanLgmiNkGyXasU8HBGOB7O4LQeIiIiIiKiS7V6MmXUqFHIy8vD/v37sWPHDphMJsTGxuKKK67A7NmzkZOT0+B4hUKB9957D4sXL8aqVavw6quvIjo6GrfddhvmzZuHuLiWrWZC5Gt2nbPijcNG2X3PDY6AILR8VApEh2wyxRGRIXMwERERERERNabVkykjR47EyJEjPXqMVqvF3LlzJUsqEwWabUUW3LSuVHYFnWtSdBiaqPXKdRTGfAgOacLGEdlf5mgiIiIiIiJqTLsujUwUzDaeMePW3DLUOKSZFJUAPDOo6SXA3eW6XgqTKURERERERJ5iMoUCg+iEYDnn9dPaHCJyz1jw6fFq5FdYkXz0GB4dEIl+MeqmH9yIDWfMeHCbAZEiEClTBnpWr1D01JYC5hZdpo6y7HvZ7fVX8iEiIiIiIiL3MJlCfk97bDE0J16Bwnq+Vc4//bcfhAEQAexp+TmnAJgS28gBZQByW36dxjg1cRB1Sa17ESIiIiIiogDEZAr5NfWZD6E78mx7N8MvOSL7A94obktERERERBRkZCYYEPkJpx3Kwy+0dyv8Fqf4EBERERERNQ+TKeS3Cg5/CK35ZHs3w2/Z48e2dxOIiIiIiIj8EpMp5Jc+ya+G8uji9m6G37Im3QhHjGdLlhMREREREdEFrJlCfkUURby0vxp7fv4Cd0UdlezPd3TBf2qme+16agFIi1FjQLQSv5QYsbtC6bVzA8CYjlqM66QF0Ea1SwQFHBHpcMSOZr0UIiIiIiKiZmIyhfyGzSni4e0GvHPUiO3Rr8se87zx93jLfL3Lc4SqBKSEKZEcrkKHEAWqbSLKLU6UW50oM1/4r90J9IlS4abUUExPDUWUVgGz2YzU06exvzIOf91vavFz6axX4plBERiVGgpri89GREREREREbYnJFHKpwupEldWJTnolhHYexWC2i7gltxQbz1owRr0Lw9X7JMecQ0fcPf5OzBQ1qHGIMNtF1DhEABeSFynhSsRqFS16Lg/0DUFkiBqP7axo1uN7RqrwcHoYpqWGQq3gyBAiIiIiIiJ/xGQK1RFFEYcMdnx9yoyvT9dgd4kNADAgVo23c2LQJaz9Xi7P/liBjWctAIAn9PKjUvR9HkJGfFirt+X3aWHQqwU8sM0Ap+jeYzJi1Hi0fzgmJ+ugZBKFiIiIiIjIrzGZEuREUcS2YivWnqzB16fNKKhySI7ZW2rDTetKsf6aeISq2r5m8aFyG5YdMgIABql+xgTNdskxTk0c7Cm3tVmbZvbUI0ylwB+3laPKJs2oxGoVSNIr0TtKhempoRjfSdvuo3uIiIiIiIjIO5hMCWJGmxO35Jbhu0JLk8ceNNgxd2cF/jUiug1adpEoinjihwr8NlsHj4fKj0qxdpsDKEPbsGXAlG4hGJ6owffnrLA7RSTplegYeuFHq2TihIiIiIiIKFAxmeLD7E4R24qsOGKwoWekCqM7ar06ReTp3ZVuJVJqrcwzYVQHLaaltl3S4qtT5rrpPb2V+bhemys5RlRFwJJyd5u1qb7EUCWu6xrSLtcmIiIiIiKi9sFkig9RmAvhqKnCT+et2HTWgi2FFlTYnHX7k0KUuKF7CCalhCBM1bKkyoEyG3YfK0d/D18Bb+wUkK2LbpP6KTYn8M7uUvRXXZh69Hjof6EQpFNqLCl3A+qoVm8PEREREREREcBkis8oMAko3vlPTLK/ifEAxgNAuMyBhb/9tFA2gL0xzXzw3pZf311f6QDoXO8XFboLU3yIiIiIiIiI2kjbVxMlWSKAvEpp8VdqnLXLbRC1Ce3dDCIiIiIiIgoiHJniI7qFijBqmNvyhCioYOn+x/ZuBhEREREREQUZ3r37kG7hDIcnbJ2mQwxNbu9mEBERERERUZDh3bsP6R6ubO8m+A1HRAZq0v7W3s0gIiIiIiKiIMRpPj4kNPkG/LWkJ5JClciM16B7uAqKeumuX6sd2HjWgl0lFtRb5KfFcpKaXu74h3NWrDhilN036zI9hiRoWtQGk03EznNWbCm0oLBGWjtGqxAwf3AEorQKOPU94IgaBAhMPhEREREREVHbYzLFh9gjM3Hf1dl1vzt++6mVCODm3sB4swPv5Jmw45wVJpsTKoUAlQAoFAIgilh3xgKndAVhWZ31SryQnQCbuvFBSgM7A2+YyvH2UZNkX+5RJXZlJCBU5dlAJ1EU8dN5G944YsSnx2tQ43Dd6HmZEdCnhsPm0RWIiIiIiIiIvI/JFD8Up1PioYxwPORi/7enzZi1qQxGe9MZlReHRSK8iURKrYXDIvFdoQUnqxuOHDljcuDVX4z4v/5yazlfVG1zYl+pDT+WWLG7xIofS2w4Y2p6BaPkMCXu7xvmVhuJiIiIiIiIWhuTKQFoQhcdvr46DjetL0WhyfV8oOu66nBVcojb5w1VKfDs4EjcualMsm/x/irM7BmKDqENp97U2EUsP1yN94+ZcMhgd3vETH1/GxoJnUrw/IFERERERERErYAFaANURqwG6ycnoF+MWnZ/hEbAwqFRHp/3uq46DJOpj2K0i3jhp8oG20rNDkz6ugTzdlXil3LPEymxWgX+NSIKV3uQ8CEiIiIiIiJqbUymBLBOeiW+vjoO4ztpJfv+OiRSMorEHYIg4IUhkbL73jlqwoGyC1VNzhgduPqr8/jpvOdVTrITNfjvmGgcvKkDbu+l9/jxRERERERERK2J03wCXLhagQ/Gx2LZISPePGJEuFrA79LCcFMTq/c0ZlC8BtO7h+DD4zUNtosAnvyhAi8Nj8SUb0rxq7Hpeii1IjQCbkkNxazeevSOkh9NQ0REREREROQLmEwJAiqFgHv7huFeLxZxfWpQBFafrIH5knzJd4UWjF1Tgipb43N6VALQL0aNQfEaDE/U4OpkncerARERERERERG1ByZTqFm6hKlwf79w/GNflWSfq0RKSpgSv08Lw6A4NTJiNQhhUVkiIiIiIiLyQ0ymULM9lB6Gt/OMKK5xvWJQrbRoFT6dENesOi1EREREREREvoTzKqjZwtQKPJkZ0eRxQxM0+OqqeCZSiIiIiIiIKCAwmUItMqNHqMvllwFgfCctPp0QiygtX2pEREREREQUGHiHSy2iVAh4IUt+dMoN3ULw3rhY6NV8mREREREREVHg4F0utdiYJB0e6NdwpaDf9dHj9dHR0ChZZJaIiIiIiIgCCwvQklc8OzgC13UNwYEyGwbEqjEgTtPeTSIiIiIiIiJqFUymkFcIgoBB8RoMimcShYiIiIiIiAIbp/kQEREREREREXmAyRQiIiIiIiIiIg8wmUJERERERERE5AEmU4iIiIiIiIiIPMBkChERERERERGRB5hMISIiIiIiIiLyAJMpREREREREREQeYDKFiIiIiIiIiMgDTKYQEREREREREXmAyRQiIiIiIiIiIg8wmUJERERERERE5AEmU4iIiIiIiIiIPMBkChERERERERGRB5hMISIiIiIiIiLyAJMpREREREREREQeYDKFiIiIiIiIiMgDTKYQEREREREREXmAyRQiIiIiIiIiIg8wmUJERERERERE5AEmU4iIiIiIiIiIPMBkChERERERERGRB5hMISIiIiIiIiLyAJMpPkKpVLZ3E6gJjJH/YKz8B2Pl+xgj/8J4+Q/Gyj8wTv6DsfIfgRIrwWAwiO3dCCIiIiIiIiIif8GRKUREREREREREHmAyhYiIiIiIiIjIA0ymEBERERERERF5gMkUIiIiIiIiIiIPMJlCREREREREROQBJlOIiIiIiIiIiDzAZAoRERERERERkQeYTCEiIiIiIiIi8kBQJVPOnj2LV199Fddffz369euH+Ph49OrVC7fddht2794t+5jKyko88cQT6NevHxISEpCeno6nnnoK1dXVkmN37NiBJ598EmPGjEG3bt2QmJiIrKwsPPPMMzAYDF5pT1MsFgsWLlyIzMxMJCYmonfv3njwwQdRUlIiOdZkMmHJkiWYPXs2srKyEB0djaioKJw8ebJZ1/YGxqihkydPIioqyuXPggULmtUGb2CspAwGA+bNm4eBAwciISEBqampuP3223Ho0KFmXd9bfC1WZrMZTzzxBK666ir07t0biYmJ6NWrFyZOnIh33nkHNpvN4+fIvi+wYuTLfR/AeMlh/+derOS8/PLLda/tXbt2efwc/b3/AxinS/lyH8hYSbH/cz9W6enpLl/XkyZN8vg5Op1OLF26FNnZ2ejQoQNSU1Nx9913o6CgQPb4pUuX4t5770V2djZiY2MRFRWFLVu2eHzdWoLBYBCb/Wg/M3/+fLz88svo1q0bRo4cibi4OOTn52Pt2rUQRRH//e9/ccMNN9QdbzQaceWVV+LAgQPIyclBRkYG9u/fjw0bNiAzMxNfffUVdDpd3fG9evVCaWkphg0bhoyMDAiCgK1bt2L//v3o2rUrvv32WyQkJDS7PU1xOp2YNm0acnNzkZWVhREjRiA/Px9ffvklUlJSsH79esTFxdUdf/LkSfTv3x8A0KVLF1RXV6O8vBz79u1DSkpKS/6pm40xko9Rv379ZDuYkSNHYtSoUZ7+M3sFY9UwVmVlZbjiiiuQn5+PIUOGICsrC8XFxVi9ejVUKhVWr16NwYMHt/BfvXl8LValpaXo27cvMjMz0aNHD8TFxcFgMGDdunU4ffo0cnJy8PHHH0OhcC/fz74vcGPki30fwHix/2t+rC518OBBjB07FiqVCkajEevWrUNWVpbbzy8Q+j+AcfKnPpCxYv9XqzmxSk9PR0VFBebMmSNpb3JyMmbMmOHRc3zggQewcuVK9OnTBxMmTEBhYSE+//xz6PV6rF+/HqmpqQ2Oj4qKAgB06NABoiiiuLgYa9asaf77yWAwiMHys3LlSvHLL7+UbP/qq69EtVotRkVFicXFxXXb//znP4sAxIceeqjB8Q899JAIQHz66acbbJ8/f7546NChBtvKy8vFu+++WwQgzp49u0Xtaern3//+twhAnDp1qlheXl63/aWXXhIBiHfeeWeD43/99Vfxs88+E0+cOCEaDAZx3LhxIgBx3759jJGPxGjfvn0iAPGWW25pt5gwVu7F6p577hEBiPfdd1+D7d9++62oVCrF3r17i2VlZYyVwSCWlZWJ586dk7Tn/Pnz4siRI0UA4qpVq1otVuz7fD9Gvtz3MV7s/1oSq/o/JSUlYv/+/cXBgweL06dPFwGI69at8+j5BUL/xzj5Vx/IWDWMFfs/z2LVpUsXsUuXLl55fqtXrxYBiNnZ2Q0+Az/66CMRgJiTkyN5zKpVq8QjR46IBoNBnDVrlghAXLNmTbPbEFQjUxpzww03YMOGDdi4cSMGDhwIURSRlpaGqqoqHDlyBHq9vu5Yo9GIyy67DHFxcdi7d2+T5y4qKkLv3r3Rp08f7Nixo1ntcceECRPwww8/YP/+/UhOTq7bLooiBg4ciJKSEhw7dgwhISGyj7/xxhuRm5vb7t9OuBKMMar9ZuKWW27Ba6+95tY1fEEwxqpv374oLCzEqVOnEBYW1uBcM2bMwNq1a7F69WqMHj3areu3FV+L1X/+8x/MnTsXCxYskP3WQg77vsCLkb/2fUBwxov9n5Q7sVqwYAFefvllbN68Gf/85z/x/vvve/wteqD3f0Bwxslf+8BgjBX7P6nGYpWeng4AOHDgQIufw+zZs/Hxxx9j7dq1GDFiRIN9kydPxtatW3HgwAF06dJF9vEPP/wwVqxY0aKRKUFVM6UxarUaAKBUKgEA+fn5KCwsxNChQxu8mABAr9dj6NChKCgowK+//urxuZvTnqaYzWbs3r0bPXv2bPDGBwBBEDB27FgYjUbs2bPH7Tb4mmCOUVFREV5//XUsWrQIK1euxIkTJ9xuZ3sIxlgVFxcjNjZW8kEKoO4P1O+++87tNrcVX4qV0+lEbm4uACAtLc2tx7DvC+wY+VvfBwRnvNj/NX3uS+3duxeLFi3CY489ht69ezer/cHQ/wHBHSd/6wODMVbs/5o+96WsViveffddLFq0CMuWLWt2bcOtW7dCr9dj2LBhkn3jxo0DAGzbtq1Z53aXqlXP7idOnz6NTZs2oUOHDujbty+ACy8oAOjevbvsY7p3747c3Fzk5+ejc+fOjZ7/nXfeAQDk5OQ0uz1NOXHiBJxOZ6PtBS48r+zsbLfO6UuCPUYbN27Exo0b634XBAHTpk3D4sWLJR1eewvWWMXGxqKkpATV1dWSD9Tawn61/w6+or1jZbVasWjRIoiiiPLycmzevBl5eXmYMWMGxowZ49ZzYN8nFUgx8qe+DwjeeLH/k2osVhaLBXPmzEF6ejoefPDBZj+HQO//AMbJn/rAYI0V+z+ppj6riouLcd999zXYlpmZieXLl6Nbt25uPQej0YiioiKkpaXJJm3qx6o1BX0yxWaz4fe//z0sFgvmz59fF4zKykoAQGRkpOzjIiIiGhznyv79+7Fw4ULEx8e79eZ21Z6meKu9viiYYxQaGoo//elPmDRpErp16wZRFLFv3z48//zz+PDDD1FTU4O3337breu3hWCO1fjx4/Huu+9i4cKFeP755+u27969G9988w0AoKKiwq3rtwVfiJXVasXChQvrfhcEAX/84x/xzDPPuP082PdJBUKM/K3vA4I7Xuz/GmoqVn/961+Rn5+PTZs2eTTK8lKB3P8BwR0nf+sDgzlW7P8aaipWM2bMwPDhw5GWlga9Xo9jx47hlVdewapVq3Dttddi+/btCA8Pb/J51Lajtl3NbW9LBXUyxel04t5778X27dtxxx134Oabb/bq+QsKCnDTTTfB4XBg+fLliI2NbVF7vvzyS8n8svZe0aC1BXuM4uPj8eSTTzbYNmbMGGRlZWHMmDFYs2YN9u7diwEDBjTr/N4U7LF64oknkJubiyVLlmDXrl0YPHgwiouL8cUXX+Cyyy7DL7/84vZKGq3NV2IVFhYGg8EAp9OJwsJC/O9//8Nzzz2HXbt24cMPP6z7IGTfF3wx8qe+D2C82P9d1FSsfvjhByxZsgRz5851a+pVMPZ/AOPkT31gsMeK/d9F7nxWzZ07t8HvGRkZWLp0KQBg1apVeOutt3D//fcDALZs2YKtW7c2OD49PR2TJ0/2artbImiTKU6nE/fddx8++ugjTJ8+HYsXL26wv/YPDleZxKayYQUFBZg8eTJKS0uxcuXKJosONdUeAFi7di3ef/99yfZRo0a1uL2+iDFyLTQ0FDfddBP+8pe/YOfOne3+YcpYAZ06dcKGDRuwYMECrF+/Hj/++CM6deqEJ554AsnJybjrrrsaLKXXXnwtVgCgUCjQqVMn3H333YiNjcWdd96JRYsW4dlnnwXAvo8xusjX+j6A8QLY/9VqKlZ2ux1z5sxB37598fDDD7vV5mDr/wDGqTG+1gcyVuz/ajXns6q+WbNmYdWqVdi5c2ddMmXr1q0NRlsCwC233ILJkyc3OfKkrfq/oEym1GblPvjgA0ydOhWvvfaaJGNYuyb18ePHZc9Ru/3StauBiy+m4uJivPnmm7jyyitb3B4AeO2111xW9O7atSsUCkWz2uuLGKOm1WZ7TSaTW8e3FsbqoqSkJCxZskRy/IIFCwDA7ZWEWouvxUrO2LFjAaDBNxHs+xij+nyl7wMYr/rY/zUdq+rq6rr5+/Hx8bLXuOKKKwBcqDkwefLkoOr/AMbJHb7SBzJWF7H/a/lnldzr+vHHH8fjjz8ue7xer0eHDh1w8uRJOBwOyfSutur/gi6ZUv/FdMMNN2Dp0qWyc+tSU1PRsWNH7Ny5E0ajUbI81M6dO5GSkiIpwFP/xfTGG29g0qRJXmlPU0JCQjBo0CDs2rULp06dkizltXHjRuj1+nZ/M7uDMXIvRrWVry+tNt6WGKumY+VwOPDpp59CpVLh2muv9bgt3uJrsXKlqKgIwMVK8E1h3xd8MfKFvg9gvNj/XeRurLRaLW677TbZfdu3b0d+fj6uuuoqxMXFufX6DqT+D2Cc/KkPZKzY/9Xy1mdVc17XI0aMwCeffILvv/9esjRy7Up2rV182zcmcLWR2uFNH3zwAaZMmYJly5a5vNESBAG33XYbqqur8eKLLzbY9+KLL6K6uhp33HFHg+21L6aioiIsX74c11xzjdfa447a9jz33HMQRbFu+4oVK1BQUIBp06bVrYnuqxijhjHat29fg+NqrV69Gu+//z6ioqIwfvz4ZrenJRirhrGy2WyoqamRtGnevHk4evQofve736Fjx47Nbk9L+FqsDh8+LPuNmslkqpsjXvtNkjvY910UKDHy5b4PYLzY/13kSaxCQkKwZMkS2Z8hQ4YAAB555BEsWbIEGRkZbj2/QOj/AMbJn/pAxor9Xy1PP6vy8vJkP6vy8vIwf/58AMDUqVPdfn617XnhhRdgtVrrtq9btw5bt25FTk5OqycdBYPBIH2nBqgFCxZg4cKFCAsLwx/+8AfZF9OkSZPq3mxGoxETJ07Ezz//jJycHPTv3x/79u3Dhg0bkJmZibVr1zZ4M6Wnp+P06dPIyspyuRRU/aFKnranKU6nE9OmTUNubi6ysrIwYsQIHD9+HGvWrEFycjJyc3Mlc/bmzZuH0tJSAMCmTZtQWFiIa6+9ti4befvtt2P48OFuXd8bGKOGMZo0aRIKCgqQlZWFpKQkOBwO7N+/Hzt27IBWq8WKFStw9dVXu3Vtb2OsGsbqzJkzGD58OMaOHYuUlBRYrVZs2LABeXl5mDhxIlauXAmtVuvWtb3NF2P16quvYtiwYUhOTkZ4eDjOnj2L9evXo6ysDMOHD8enn37q9g0A+77Ai5Ev930A48X+r/mxcmXOnDl4//33sW7dOmRlZbn9/AKh/wMYJ3/qAxkr9n+1mvtZlZ2djS5duiA0NBTHjh3DunXrYLPZ8Mgjj+Dpp5/26Dk+8MADWLlyJfr06YMJEyagqKgIn332GfR6PdatW4cePXo0OH7x4sXIy8sDAOzatQvHjh3DuHHjkJCQUPfv4UmB26BKptS+qRrzyiuvYMaMGXW/V1RU4G9/+xvWrFmD4uJiJCYmYsqUKXjsscckyzZFRUU12QaDwdCi9jTFYrFg8eLFWLVqFc6cOYPo6GhMnDgR8+bNq3uR1Ff7JvDW9VuKMWoYo5UrV2L16tU4fPgwSktL4XQ60bFjR4wePRr3338/evXq5fZ1vY2xahirqqoq/N///R927tyJoqIiqNVq9OnTBzNnzsTMmTPbtZK7r8Vqz549ePPNN/HDDz/g7NmzMBqNiIiIQN++fXHjjTdi5syZUKk8m4XKvi+wYuTLfR/AeLH/u8jTWDXVTk9v/AD/7/8Axsmf+kDGiv1fLU9jtXXrVixfvhz79+9HSUkJTCYTYmNjMWjQIMyePdtlQqYxTqcTy5Ytw1tvvYXjx49Dr9fj8ssvx1NPPYVu3bpJjp80aRK2bdvm8nyPPfaYW8m6WkGVTCEiIiIiIiIiaqmgqplCRERERERERNRSTKYQEREREREREXmAyRQiIiIiIiIiIg8wmUJERERERERE5AEmU4iIiIiIiIiIPMBkChERERERERGRB5hMISIiIiIiIiLyAJMpREREREREREQeYDKFiIiIiIiIiMgDTKYQEREREREREXmAyRQiIiIiIiIiIg8wmUJERERERERE5IH/BwB14CwsuI07AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(hisse[\"Close\"],label=\"Hisse Fiyatı\")\n",
    "plt.plot(hisse[\"Hedef\"],label=\"Hedef Fiyat\",color=\"orange\")\n",
    "plt.plot(yeni[\"Hedef\"].loc[\"2024-08-26\":],color=\"orange\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
